# Configuration of MCQA with Cisco Certifications

control_output: true

# Dictionary with the model paths and the corresponding model names
model_paths:
  #Llama-3.2-11B-Vision-instruct : "vllm:unsloth/Llama-3.2-11B-Vision-Instruct"
  #Molmo-72B-0924: "vllm:allenai/Molmo-72B-0924"
  # Molmo-7B-D-0924: "vllm:allenai/Molmo-7B-D-0924"
  # Phi-3-vision-128k-instruct: "vllm:microsoft/Phi-3-vision-128k-instruct"
  # OpenAI GPT-4o: "openai:gpt-4o-2024-05-13"
  # Anthropic Claude 3.5 Sonnet: "anthropic:claude-3-5-sonnet-20240620"
  # TODO: Lägg till våra två språkmodeller; Llama 3.1 8b och Deepseek R1 på Llama 3.1 8b
  # Llama-3.1-8B-Instruct : "https://llm-server.tail004934.ts.net"


# Set the model parameters here
model_parameters:
  temperature: 0.7
  max_output_tokens: 10

# Sampling rate determines how often a question is asked again if the answer format is wrong
max_sampling_rate: 1

# Set to 1 if you don't want to shuffle
num_of_shuffles: 1

# Set the number of questions to be asked
number_of_questions:  15 

# Turn on/off tracking of results and prints
track_results: true
print_results: true

# Dataset name
dataset_name: "350-701-CCNP-VISION"

# Date format
date_format: "%Y_%m_%d_%H_%M"

# Set output path
output_path: "./results/{number_of_questions}_questions_5_Shot_HELM_{dataset_name}/"

# Set output file name
output_evaluation: "{output_path}llm_5_Shot_{dataset_name}.pkl"

# Filename output evaluation detailed
output_evaluation_detailed: "./results/{number_of_questions}_questions_5_Shot_HELM_{dataset_name}/llm_prob_result_detailed_{dataset_name}_5_Shot.pkl"

# Set filename of json file
output_evaluation_json: "./results/{number_of_questions}_questions_5_Shot_HELM_{dataset_name}/llm_prob_result_{dataset_name}_5_Shot.json"

# Create folder for results if not exists
create_results_folder: true

# Set the questions bank here
questions_bank: "./data/350-701-CCNP_only_images_15.parquet"

# Set the prompt template here
prompt_template: "LLAMA31_INSTRUCT_CCNA_5_SHOT_OPENAI"
