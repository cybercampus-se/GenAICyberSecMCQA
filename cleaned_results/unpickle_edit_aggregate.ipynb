{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T17:56:11.603176Z",
     "start_time": "2025-03-18T17:56:11.599096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import pickle\n",
    "import argparse\n",
    "import re\n",
    "import os"
   ],
   "id": "6adf86deb51f19a6",
   "outputs": [],
   "execution_count": 508
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T17:56:11.652947Z",
     "start_time": "2025-03-18T17:56:11.647324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def improved_extract_answer(answer):\n",
    "    \"\"\"Extracts the correct answers from the provided answer string.\n",
    "\n",
    "    Args:\n",
    "        answer: The answer string to extract the correct answers from.\n",
    "\n",
    "    Returns:\n",
    "        A list of correct answers.\n",
    "    \"\"\"\n",
    "    # Remove reasoning sections enclosed in <think> tags\n",
    "    answer = re.sub(r\"<think>.*?</think>\", \"\", answer, flags=re.DOTALL).strip()\n",
    "\n",
    "    # Special case 1: Extract all \"[X]\" patterns in the entire text\n",
    "    bracketed_letters = re.findall(r\"\\[([A-J])\\]\", answer)\n",
    "    if len(bracketed_letters) > 1:\n",
    "        return sorted(set(bracketed_letters))\n",
    "\n",
    "    # Special case 2: \"Answer :[A, B, C]\" format (comma-separated list in one bracket)\n",
    "    if re.search(r\"Answer\\s*:\\s*\\[\", answer, re.IGNORECASE):\n",
    "        brackets_with_commas = re.search(r\"\\[(.*?)\\]\", answer)\n",
    "        if brackets_with_commas:\n",
    "            content = brackets_with_commas.group(1)\n",
    "            letters = re.findall(r\"([A-J])\", content)\n",
    "            if letters:\n",
    "                return sorted(set(letters))\n",
    "\n",
    "    # Find the answer section using regular pattern\n",
    "    pattern = re.compile(\n",
    "        r\"(?:answer is|answer:)\\s*\"  # Match indicators like \"answer is\" or \"answer:\"\n",
    "        r\"(.+?)\"  # Capture everything after the indicator\n",
    "        r\"(?:\\.|\\:|\\n|$)\",  # Until a period, colon, newline, or end of string\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    match = pattern.search(answer)\n",
    "    if not match:\n",
    "        return []\n",
    "\n",
    "    answer_section = match.group(1).strip()\n",
    "\n",
    "    # Handle special case with 'not'\n",
    "    if \"not\" in answer_section.lower():\n",
    "        not_matches = re.findall(r\"not\\s+[\\[\\(\\*]?([A-J])[\\]\\)\\*]?\", answer_section, re.IGNORECASE)\n",
    "        all_matches = re.findall(r\"([A-J])\", answer_section)\n",
    "\n",
    "        # Filter out 'not' letters\n",
    "        return sorted(set([letter for letter in all_matches if letter not in not_matches]))\n",
    "\n",
    "    # Extract all letters directly\n",
    "    all_letters = re.findall(r\"([A-J])\", answer_section)\n",
    "\n",
    "    return sorted(set(all_letters))  # Remove duplicates and return sorted list\n",
    "\n"
   ],
   "id": "c1b1c507fd990ad",
   "outputs": [],
   "execution_count": 509
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T17:56:11.706025Z",
     "start_time": "2025-03-18T17:56:11.700308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def their_extract_answer(answer):\n",
    "    \"\"\"Extracts the correct answers from the provided answer string.\n",
    "\n",
    "    Args:\n",
    "        answer: The answer string to extract the correct answers from.\n",
    "\n",
    "    Returns:\n",
    "        A list of correct answers.\n",
    "    \"\"\"\n",
    "\n",
    "    # Cleaning the input by removing some non-relevant characters\n",
    "    answer_proc = re.sub(r'[\\s\\n.,]', '', answer)\n",
    "\n",
    "    # Define regex patterns for different cases\n",
    "    pattern_single_letters = re.compile(r'^[A-J]+$')\n",
    "    #pattern1 = re.compile(r\"answer is \\(?([A-J]+)\\)?\", re.IGNORECASE)\n",
    "    pattern1 = re.compile(r\"answer is \\[?([A-J]+)\\]?\", re.IGNORECASE)\n",
    "    pattern2 = re.compile(r'.*[aA]nswer:\\s*([A-J]+)', re.IGNORECASE)\n",
    "\n",
    "    if re.match(pattern_single_letters, answer_proc):\n",
    "        return list(answer_proc)\n",
    "    else:\n",
    "        # Find matches using the first regex pattern\n",
    "        #drop , from answer\n",
    "\n",
    "        match1 = pattern1.findall(answer)\n",
    "\n",
    "        # Find matches using the second regex pattern\n",
    "        match2 = pattern2.findall(answer)\n",
    "\n",
    "        # Combine results from both patterns\n",
    "        results = match1 + match2\n",
    "\n",
    "        # Flatten the list and remove duplicates\n",
    "        combined_results = []\n",
    "        for result in results:\n",
    "            combined_results.extend(list(result))\n",
    "\n",
    "        return list(set(combined_results))"
   ],
   "id": "e8e579cca0509289",
   "outputs": [],
   "execution_count": 510
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T17:56:11.759947Z",
     "start_time": "2025-03-18T17:56:11.753656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_function(function_to_test):\n",
    "    \"\"\"Test the improved_extract_answer function with various cases.\"\"\"\n",
    "    test_cases = [\n",
    "        # Previously correct cases\n",
    "        (\"The answer is ABCDE.\", ['A', 'B', 'C', 'D', 'E']),\n",
    "        (\"The best answer is C, E.\", ['C', 'E']),\n",
    "        (\"The best answer is [DE]. The access and distribution layers must be on the same device\", ['D', 'E']),\n",
    "        (\"Answer:[A, B, C]\", ['A', 'B', 'C']),\n",
    "        (\"The best answer is A, and not B.\", ['A']),\n",
    "        (\"Answer: A and B:\", ['A', 'B']),\n",
    "        (\"The best answer is *A*\", ['A']),\n",
    "        (\"The best answer is (A)\", ['A']),\n",
    "\n",
    "        # Previously incorrect cases\n",
    "        (\"The best answer is A, and B.\", ['A', 'B']),\n",
    "        (\"The best answer is (A), (B), and (C)\", ['A', 'B', 'C']),\n",
    "        (\"Answer: [A], [B], and [C]:\", ['A', 'B', 'C']),\n",
    "        (\"Answer: A, B, and C:\", ['A', 'B', 'C']),\n",
    "        (\"Answer: A, B, C:\", ['A', 'B', 'C']),\n",
    "\n",
    "        # Think case\n",
    "        (\"\"\"\n",
    "<think>\n",
    "Okay, so I have this question about the ip route command in Cisco IOS. I'm a bit new to this, but I'll try to work through it step by step. The question is asking which two statements are true about the command: ip route 172.16.3.0 255.255.255.0 192.168.2.4.\n",
    "So the true statements are A and E.\n",
    "</think>\n",
    "\n",
    "The best answer is A and E.\n",
    "\"\"\", ['A','E'])\n",
    "    ]\n",
    "\n",
    "    passed_all_tests = True\n",
    "    for input_text, expected_output in test_cases:\n",
    "        result = function_to_test(input_text)\n",
    "        print(f\"{input_text} : {result} {'✓' if result == expected_output else '✗'}\")\n",
    "        if result != expected_output:\n",
    "            passed_all_tests = False\n",
    "\n",
    "    if passed_all_tests:\n",
    "        print(\"All tests passed\")\n",
    "    else:\n",
    "        print(\"Some tests failed\")"
   ],
   "id": "45ac9f42df6f6c46",
   "outputs": [],
   "execution_count": 511
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T17:56:11.814637Z",
     "start_time": "2025-03-18T17:56:11.810951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Improved extracted answer function\")\n",
    "test_function(improved_extract_answer)"
   ],
   "id": "bcd4d35bed5b2794",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved extracted answer function\n",
      "The answer is ABCDE. : ['A', 'B', 'C', 'D', 'E'] ✓\n",
      "The best answer is C, E. : ['C', 'E'] ✓\n",
      "The best answer is [DE]. The access and distribution layers must be on the same device : ['D', 'E'] ✓\n",
      "Answer:[A, B, C] : ['A', 'B', 'C'] ✓\n",
      "The best answer is A, and not B. : ['A'] ✓\n",
      "Answer: A and B: : ['A', 'B'] ✓\n",
      "The best answer is *A* : ['A'] ✓\n",
      "The best answer is (A) : ['A'] ✓\n",
      "The best answer is A, and B. : ['A', 'B'] ✓\n",
      "The best answer is (A), (B), and (C) : ['A', 'B', 'C'] ✓\n",
      "Answer: [A], [B], and [C]: : ['A', 'B', 'C'] ✓\n",
      "Answer: A, B, and C: : ['A', 'B', 'C'] ✓\n",
      "Answer: A, B, C: : ['A', 'B', 'C'] ✓\n",
      "\n",
      "<think>\n",
      "Okay, so I have this question about the ip route command in Cisco IOS. I'm a bit new to this, but I'll try to work through it step by step. The question is asking which two statements are true about the command: ip route 172.16.3.0 255.255.255.0 192.168.2.4.\n",
      "So the true statements are A and E.\n",
      "</think>\n",
      "\n",
      "The best answer is A and E.\n",
      " : ['A', 'E'] ✓\n",
      "All tests passed\n"
     ]
    }
   ],
   "execution_count": 512
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T17:56:11.869471Z",
     "start_time": "2025-03-18T17:56:11.863608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Their extracted answer function\")\n",
    "test_function(their_extract_answer)"
   ],
   "id": "a70fff581ea255da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Their extracted answer function\n",
      "The answer is ABCDE. : ['D', 'C', 'E', 'B', 'A'] ✗\n",
      "The best answer is C, E. : ['C'] ✗\n",
      "The best answer is [DE]. The access and distribution layers must be on the same device : ['D', 'E'] ✓\n",
      "Answer:[A, B, C] : [] ✗\n",
      "The best answer is A, and not B. : ['A'] ✓\n",
      "Answer: A and B: : ['A'] ✗\n",
      "The best answer is *A* : [] ✗\n",
      "The best answer is (A) : [] ✗\n",
      "The best answer is A, and B. : ['A'] ✗\n",
      "The best answer is (A), (B), and (C) : [] ✗\n",
      "Answer: [A], [B], and [C]: : [] ✗\n",
      "Answer: A, B, and C: : ['A'] ✗\n",
      "Answer: A, B, C: : ['A'] ✗\n",
      "\n",
      "<think>\n",
      "Okay, so I have this question about the ip route command in Cisco IOS. I'm a bit new to this, but I'll try to work through it step by step. The question is asking which two statements are true about the command: ip route 172.16.3.0 255.255.255.0 192.168.2.4.\n",
      "So the true statements are A and E.\n",
      "</think>\n",
      "\n",
      "The best answer is A and E.\n",
      " : ['A'] ✗\n",
      "Some tests failed\n"
     ]
    }
   ],
   "execution_count": 513
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T17:56:11.918574Z",
     "start_time": "2025-03-18T17:56:11.913353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_value(value):\n",
    "    \"\"\"\n",
    "    Modify this function to define how you want to process the values.\n",
    "    \"\"\"\n",
    "    return value * 2  # Example: Modify as per your requirements\n",
    "\n",
    "def process_pkl(input_file, output_file, llm_answer_column, temperature, exam, prompt_engineering):\n",
    "    # Load the DataFrame\n",
    "    with open(input_file, \"rb\") as f:\n",
    "        df = pickle.load(f)\n",
    "\n",
    "    # Ensure input column exists before processing\n",
    "    if llm_answer_column not in df.columns:\n",
    "        raise ValueError(f\"Column '{llm_answer_column}' not found in the DataFrame.\")\n",
    "\n",
    "    improved_extracted_answer_column = \"Improved_Extracted_Answer_Column\"\n",
    "    their_extracted_answer_column = \"Their_Extracted_Answer_Column\"\n",
    "\n",
    "    # Apply functions to the llm answer column and save results in the new columns\n",
    "    df[improved_extracted_answer_column] = df[llm_answer_column].apply(improved_extract_answer)\n",
    "    df[their_extracted_answer_column] = df[llm_answer_column].apply(their_extract_answer)\n",
    "\n",
    "    # Add new columns with constant values\n",
    "    df[\"Temperature\"] = temperature\n",
    "    df[\"Exam\"] = exam\n",
    "    df[\"Prompt_Engineering\"] = prompt_engineering\n",
    "    df[\"Differ\"] = df[their_extracted_answer_column] != df[improved_extracted_answer_column]\n",
    "\n",
    "    # Define columns to keep\n",
    "    selected_columns = [\"Exam\",\n",
    "                        \"QuestionIndex\",\n",
    "                        \"NumberOfChoices\",\n",
    "                        \"Model\",\n",
    "                        \"SamplingIndex\",\n",
    "                        \"Temperature\",\n",
    "                        \"Prompt_Engineering\",\n",
    "                        llm_answer_column,\n",
    "                        \"Exam_Answers\",\n",
    "                        improved_extracted_answer_column,\n",
    "                        their_extracted_answer_column,\n",
    "                        \"Differ\"]\n",
    "\n",
    "    # Select only the specified columns\n",
    "    df_selected = df[selected_columns]\n",
    "\n",
    "    # Save the modified DataFrame as a .pkl file\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        pickle.dump(df_selected, f)\n",
    "\n",
    "    print(f\"Processed file saved as: {output_file}\")"
   ],
   "id": "8db911583c92e183",
   "outputs": [],
   "execution_count": 514
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T17:56:11.963452Z",
     "start_time": "2025-03-18T17:56:11.960688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def batch_process_pkl(input_dir, output_dir, llm_answer_column, temperature, exam, prompt_engineering):\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Get all .pkl files in the input directory\n",
    "    pkl_files = glob.glob(os.path.join(input_dir, \"*.pkl\"))\n",
    "\n",
    "    if not pkl_files:\n",
    "        print(f\"No .pkl files found in {input_dir}.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(pkl_files)} .pkl files in {input_dir}. Processing...\")\n",
    "\n",
    "    # Loop through each file and process it\n",
    "    for input_file in pkl_files:\n",
    "        # Generate output file path\n",
    "        filename = os.path.basename(input_file)\n",
    "        output_file = os.path.join(output_dir, f\"processed_{filename}\")\n",
    "\n",
    "        # Process and save\n",
    "        process_pkl(input_file, output_file, llm_answer_column, temperature, exam, prompt_engineering)"
   ],
   "id": "30326691339cb54b",
   "outputs": [],
   "execution_count": 515
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T17:56:46.936369Z",
     "start_time": "2025-03-18T17:56:12.007181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# CCNA\n",
    "batch_process_pkl(\n",
    "    input_dir=\"./exam/201-301-ccna/0_shot/t00/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    llm_answer_column=\"LLM_Answer\",\n",
    "    temperature=0.0,\n",
    "    exam=\"CCNA-201-301\",\n",
    "    prompt_engineering=\"0_shot\"\n",
    ")\n",
    "\n",
    "batch_process_pkl(\n",
    "    input_dir=\"./exam/201-301-ccna/0_shot/t07/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    llm_answer_column=\"LLM_Answer\",\n",
    "    temperature=0.7,\n",
    "    exam=\"CCNA-201-301\",\n",
    "    prompt_engineering=\"0_shot\"\n",
    ")\n",
    "\n",
    "batch_process_pkl(\n",
    "    input_dir=\"./exam/201-301-ccna/5_shot/t00/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    llm_answer_column=\"LLM_Answer\",\n",
    "    temperature=0.0,\n",
    "    exam=\"CCNA-201-301\",\n",
    "    prompt_engineering=\"5_shot\"\n",
    ")\n",
    "\n",
    "batch_process_pkl(\n",
    "    input_dir=\"./exam/201-301-ccna/5_shot/t07/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    llm_answer_column=\"LLM_Answer\",\n",
    "    temperature=0.7,\n",
    "    exam=\"CCNA-201-301\",\n",
    "    prompt_engineering=\"5_shot\"\n",
    ")\n",
    "\n"
   ],
   "id": "a2f8251192d40550",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 .pkl files in ./exam/201-301-ccna/0_shot/t00/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0853_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1528_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1111_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1027_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1525_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0938_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0810_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1523_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1527_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1527_shuffled_2.pkl\n",
      "Found 10 .pkl files in ./exam/201-301-ccna/0_shot/t07/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1220_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1501_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1146_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1116_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1252_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1501_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1503_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1320_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1504_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1502_shuffled_2.pkl\n",
      "Found 10 .pkl files in ./exam/201-301-ccna/5_shot/t00/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1306_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1529_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1333_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1532_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1530_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1426_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1530_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1447_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1357_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1532_shuffled_4.pkl\n",
      "Found 10 .pkl files in ./exam/201-301-ccna/5_shot/t07/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1506_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1439_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1505_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1507_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1458_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1340_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1508_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1419_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1359_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1505_shuffled_0.pkl\n"
     ]
    }
   ],
   "execution_count": 516
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T17:57:10.441175Z",
     "start_time": "2025-03-18T17:56:46.950874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# CCNP\n",
    "batch_process_pkl(\n",
    "    input_dir=\"./exam/350-701-ccnp/0_shot/t00/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    llm_answer_column=\"LLM_Answer\",\n",
    "    temperature=0.0,\n",
    "    exam=\"CCNP-350-701\",\n",
    "    prompt_engineering=\"0_shot\"\n",
    ")\n",
    "\n",
    "batch_process_pkl(\n",
    "    input_dir=\"./exam/350-701-ccnp/0_shot/t07/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    llm_answer_column=\"LLM_Answer\",\n",
    "    temperature=0.7,\n",
    "    exam=\"CCNP-350-701\",\n",
    "    prompt_engineering=\"0_shot\"\n",
    ")\n",
    "\n",
    "batch_process_pkl(\n",
    "    input_dir=\"./exam/350-701-ccnp/5_shot/t00/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    llm_answer_column=\"LLM_Answer\",\n",
    "    temperature=0.0,\n",
    "    exam=\"CCNP-350-701\",\n",
    "    prompt_engineering=\"5_shot\"\n",
    ")\n",
    "\n",
    "batch_process_pkl(\n",
    "    input_dir=\"./exam/350-701-ccnp/5_shot/t07/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    llm_answer_column=\"LLM_Answer\",\n",
    "    temperature=0.7,\n",
    "    exam=\"CCNP-350-701\",\n",
    "    prompt_engineering=\"5_shot\"\n",
    ")\n"
   ],
   "id": "8e0084c662bf58e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 .pkl files in ./exam/350-701-ccnp/0_shot/t00/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1518_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1519_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0109_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0133_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250205_2330_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0033_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1518_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1519_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1518_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0002_shuffled_1.pkl\n",
      "Found 10 .pkl files in ./exam/350-701-ccnp/0_shot/t07/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1457_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0911_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0739_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1457_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1456_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1457_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1456_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0848_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0825_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0802_shuffled_1.pkl\n",
      "Found 10 .pkl files in ./exam/350-701-ccnp/5_shot/t00/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1520_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0247_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0306_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0150_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1521_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1519_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0227_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0208_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1520_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1520_shuffled_2.pkl\n",
      "Found 10 .pkl files in ./exam/350-701-ccnp/5_shot/t07/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1006_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1042_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1500_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0930_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0947_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1459_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1024_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1458_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1459_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1458_shuffled_1.pkl\n"
     ]
    }
   ],
   "execution_count": 517
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-03-18T17:57:10.455073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MMLU\n",
    "batch_process_pkl(\n",
    "    input_dir=\"./exam/mmlu_computer_security/0_shot/t00/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    llm_answer_column=\"LLM_Answer\",\n",
    "    temperature=0.0,\n",
    "    exam=\"MMLU-Computer-Security\",\n",
    "    prompt_engineering=\"0_shot\"\n",
    ")\n",
    "\n",
    "batch_process_pkl(\n",
    "    input_dir=\"./exam/mmlu_computer_security/0_shot/t07/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    llm_answer_column=\"LLM_Answer\",\n",
    "    temperature=0.7,\n",
    "    exam=\"MMLU-Computer-Security\",\n",
    "    prompt_engineering=\"0_shot\"\n",
    ")\n",
    "\n",
    "batch_process_pkl(\n",
    "    input_dir=\"./exam/mmlu_computer_security/5_shot/t00/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    llm_answer_column=\"LLM_Answer\",\n",
    "    temperature=0.0,\n",
    "    exam=\"MMLU-Computer-Security\",\n",
    "    prompt_engineering=\"5_shot\"\n",
    ")\n",
    "\n",
    "batch_process_pkl(\n",
    "    input_dir=\"./exam/mmlu_computer_security/5_shot/t07/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    llm_answer_column=\"LLM_Answer\",\n",
    "    temperature=0.7,\n",
    "    exam=\"MMLU-Computer-Security\",\n",
    "    prompt_engineering=\"5_shot\"\n",
    ")\n"
   ],
   "id": "2c34745206a6ff93",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 .pkl files in ./exam/mmlu_computer_security/0_shot/t00/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1506_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1450_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250207_0042_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250207_0249_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250207_0203_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1459_shuffled_3.pkl\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T17:24:26.414138Z",
     "start_time": "2025-03-18T17:24:19.138410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MMLU\n",
    "batch_process_pkl(\n",
    "    input_dir=\"./exam/mmlu_pro/0_shot/t00/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    llm_answer_column=\"LLM_Answer\",\n",
    "    temperature=0.0,\n",
    "    exam=\"MMLU-PRO-Computer-Security\",\n",
    "    prompt_engineering=\"0_shot\"\n",
    ")\n",
    "\n",
    "# batch_process_pkl(\n",
    "#     input_dir=\"./exam/mmlu_pro/0_shot/t07/\",\n",
    "#     output_dir=\"./processed_results/\",\n",
    "#     llm_answer_column=\"LLM_Answer\",\n",
    "#     temperature=0.7,\n",
    "#     exam=\"MMLU-PRO-Computer-Security\",\n",
    "#     prompt_engineering=\"0_shot\"\n",
    "# )\n",
    "\n",
    "batch_process_pkl(\n",
    "    input_dir=\"./exam/mmlu_pro/1_shot_cot/t00/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    llm_answer_column=\"LLM_Answer\",\n",
    "    temperature=0.0,\n",
    "    exam=\"MMLU-PRO-Computer-Security\",\n",
    "    prompt_engineering=\"1_shot_cot\"\n",
    ")\n",
    "\n",
    "# batch_process_pkl(\n",
    "#     input_dir=\"./exam/mmlu_pro/1_shot_cot/t07/\",\n",
    "#     output_dir=\"./processed_results/\",\n",
    "#     llm_answer_column=\"LLM_Answer\",\n",
    "#     temperature=0.7,\n",
    "#     exam=\"MMLU-PRO-Computer-Security\",\n",
    "#     prompt_engineering=\"1_shot_cot\"\n",
    "# )\n",
    "\n",
    "batch_process_pkl(\n",
    "    input_dir=\"./exam/mmlu_pro/5_shot_cot/t00/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    llm_answer_column=\"LLM_Answer\",\n",
    "    temperature=0.0,\n",
    "    exam=\"MMLU-PRO-Computer-Security\",\n",
    "    prompt_engineering=\"5_shot_cot\"\n",
    ")\n",
    "\n",
    "# batch_process_pkl(\n",
    "#     input_dir=\"./exam/mmlu_pro/5_shot_cot/t07/\",\n",
    "#     output_dir=\"./processed_results/\",\n",
    "#     llm_answer_column=\"LLM_Answer\",\n",
    "#     temperature=0.7,\n",
    "#     exam=\"MMLU-PRO-Computer-Security\",\n",
    "#     prompt_engineering=\"5_shot_cot\"\n",
    "# )\n"
   ],
   "id": "61abb105c3e25875",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 .pkl files in ./exam/mmlu_pro/0_shot/t00/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_0417_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_0330_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250315_2009_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250315_2008_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_0309_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_0441_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250315_2006_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_0354_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250315_2007_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250315_2006_shuffled_1.pkl\n",
      "No .pkl files found in ./exam/mmlu_pro/0_shot/t07/.\n",
      "Found 10 .pkl files in ./exam/mmlu_pro/1_shot_cot/t00/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1221_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1316_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1338_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1222_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1222_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1252_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1221_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1327_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1304_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1221_shuffled_0.pkl\n",
      "No .pkl files found in ./exam/mmlu_pro/1_shot_cot/t07/.\n",
      "No .pkl files found in ./exam/mmlu_pro/5_shot_cot/t00/.\n",
      "No .pkl files found in ./exam/mmlu_pro/5_shot_cot/t07/.\n"
     ]
    }
   ],
   "execution_count": 483
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T17:24:26.420516Z",
     "start_time": "2025-03-18T17:24:26.417242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def convert_pkl_to_parquet(folder_path):\n",
    "    \"\"\"\n",
    "    Converts all .pkl files in the specified folder to .parquet format.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(f\"Error: The folder '{folder_path}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    converted_files = 0\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".pkl\"):\n",
    "            pkl_path = os.path.join(folder_path, filename)\n",
    "            parquet_path = pkl_path.replace(\".pkl\", \".parquet\")\n",
    "\n",
    "            try:\n",
    "                # Load the pickle file\n",
    "                df = pd.read_pickle(pkl_path)\n",
    "\n",
    "                # Convert to Parquet\n",
    "                df.to_parquet(parquet_path, index=False)\n",
    "\n",
    "                print(f\"Converted: {filename} → {os.path.basename(parquet_path)}\")\n",
    "                converted_files += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to convert {filename}: {e}\")\n",
    "\n",
    "    if converted_files == 0:\n",
    "        print(\"No .pkl files found in the folder.\")\n",
    "    else:\n",
    "        print(f\"Conversion complete: {converted_files} file(s) converted.\")\n"
   ],
   "id": "e8c67127ba4a9ff9",
   "outputs": [],
   "execution_count": 484
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T17:24:26.759506Z",
     "start_time": "2025-03-18T17:24:26.469442Z"
    }
   },
   "cell_type": "code",
   "source": "convert_pkl_to_parquet(\"./processed_results/\")\n",
   "id": "d869ad93874c6bf2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1519_shuffled_4.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1519_shuffled_4.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250315_2008_shuffled_3.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250315_2008_shuffled_3.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1530_shuffled_1.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1530_shuffled_1.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1508_shuffled_4.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1508_shuffled_4.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0848_shuffled_3.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0848_shuffled_3.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1532_shuffled_3.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1532_shuffled_3.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1501_shuffled_1.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1501_shuffled_1.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1359_shuffled_1.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1359_shuffled_1.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1448_shuffled_1.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1448_shuffled_1.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0739_shuffled_0.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0739_shuffled_0.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1507_shuffled_3.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1507_shuffled_3.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1519_shuffled_3.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1519_shuffled_3.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1447_shuffled_4.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1447_shuffled_4.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0133_shuffled_4.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0133_shuffled_4.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1340_shuffled_0.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1340_shuffled_0.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1457_shuffled_4.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1457_shuffled_4.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1527_shuffled_3.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1527_shuffled_3.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0428_shuffled_2.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0428_shuffled_2.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0947_shuffled_1.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0947_shuffled_1.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0938_shuffled_2.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0938_shuffled_2.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1523_shuffled_0.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1523_shuffled_0.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1006_shuffled_2.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1006_shuffled_2.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0930_shuffled_0.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0930_shuffled_0.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1327_shuffled_3.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1327_shuffled_3.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1450_shuffled_2.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1450_shuffled_2.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_0441_shuffled_4.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_0441_shuffled_4.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1116_shuffled_0.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1116_shuffled_0.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1221_shuffled_1.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1221_shuffled_1.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1506_shuffled_2.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1506_shuffled_2.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0911_shuffled_4.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0911_shuffled_4.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1507_shuffled_3.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1507_shuffled_3.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1519_shuffled_0.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1519_shuffled_0.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1456_shuffled_1.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1456_shuffled_1.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250205_2330_shuffled_0.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250205_2330_shuffled_0.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1525_shuffled_1.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1525_shuffled_1.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1434_shuffled_2.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1434_shuffled_2.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_shuffled_0.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_shuffled_0.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1426_shuffled_3.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1426_shuffled_3.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1502_shuffled_2.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1502_shuffled_2.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1252_shuffled_3.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1252_shuffled_3.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1506_shuffled_4.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1506_shuffled_4.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1436_shuffled_0.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1436_shuffled_0.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1500_shuffled_4.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1500_shuffled_4.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_shuffled_4.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_shuffled_4.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1252_shuffled_0.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1252_shuffled_0.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1528_shuffled_4.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1528_shuffled_4.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_0330_shuffled_1.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_0330_shuffled_1.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1504_shuffled_4.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1504_shuffled_4.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1440_shuffled_3.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1440_shuffled_3.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1456_shuffled_0.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1456_shuffled_0.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0207_shuffled_1.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0207_shuffled_1.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1306_shuffled_0.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1306_shuffled_0.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0133_shuffled_0.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0133_shuffled_0.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_0354_shuffled_2.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_0354_shuffled_2.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1518_shuffled_0.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1518_shuffled_0.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_shuffled_1.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_shuffled_1.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0825_shuffled_2.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0825_shuffled_2.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1520_shuffled_3.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1520_shuffled_3.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0247_shuffled_3.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0247_shuffled_3.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1357_shuffled_2.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1357_shuffled_2.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1439_shuffled_3.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1439_shuffled_3.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1042_shuffled_4.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1042_shuffled_4.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1457_shuffled_3.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1457_shuffled_3.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0413_shuffled_1.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0413_shuffled_1.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0310_shuffled_3.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0310_shuffled_3.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1447_shuffled_0.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1447_shuffled_0.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1527_shuffled_2.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1527_shuffled_2.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1338_shuffled_4.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1338_shuffled_4.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_0309_shuffled_0.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_0309_shuffled_0.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0359_shuffled_0.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0359_shuffled_0.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0002_shuffled_1.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0002_shuffled_1.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1521_shuffled_4.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1521_shuffled_4.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1459_shuffled_3.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1459_shuffled_3.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1459_shuffled_3.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1459_shuffled_3.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250207_0203_shuffled_3.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250207_0203_shuffled_3.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1316_shuffled_2.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1316_shuffled_2.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1458_shuffled_4.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1458_shuffled_4.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1520_shuffled_2.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1520_shuffled_2.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1222_shuffled_4.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1222_shuffled_4.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1503_shuffled_3.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1503_shuffled_3.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0342_shuffled_4.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0342_shuffled_4.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1520_shuffled_1.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1520_shuffled_1.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0150_shuffled_0.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0150_shuffled_0.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1506_shuffled_0.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1506_shuffled_0.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1146_shuffled_1.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1146_shuffled_1.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1333_shuffled_1.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1333_shuffled_1.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1444_shuffled_1.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1444_shuffled_1.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250207_0042_shuffled_1.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250207_0042_shuffled_1.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1304_shuffled_1.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1304_shuffled_1.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1448_shuffled_3.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1448_shuffled_3.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1532_shuffled_4.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1532_shuffled_4.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1457_shuffled_2.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1457_shuffled_2.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1220_shuffled_2.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1220_shuffled_2.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1448_shuffled_2.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1448_shuffled_2.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1505_shuffled_0.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1505_shuffled_0.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1447_shuffled_4.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1447_shuffled_4.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1505_shuffled_1.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1505_shuffled_1.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1320_shuffled_4.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1320_shuffled_4.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0810_shuffled_0.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0810_shuffled_0.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_0417_shuffled_3.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_0417_shuffled_3.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250207_0128_shuffled_2.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250207_0128_shuffled_2.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1221_shuffled_2.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1221_shuffled_2.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1518_shuffled_1.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1518_shuffled_1.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1507_shuffled_2.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1507_shuffled_2.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0306_shuffled_4.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0306_shuffled_4.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1507_shuffled_4.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1507_shuffled_4.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0227_shuffled_2.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0227_shuffled_2.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0208_shuffled_1.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0208_shuffled_1.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1222_shuffled_3.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1222_shuffled_3.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250315_2006_shuffled_1.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250315_2006_shuffled_1.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1506_shuffled_1.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1506_shuffled_1.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_shuffled_3.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_shuffled_3.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1024_shuffled_3.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1024_shuffled_3.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250315_2009_shuffled_4.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250315_2009_shuffled_4.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1449_shuffled_4.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1449_shuffled_4.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1501_shuffled_0.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1501_shuffled_0.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_shuffled_2.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_shuffled_2.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1530_shuffled_2.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1530_shuffled_2.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0802_shuffled_1.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0802_shuffled_1.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0443_shuffled_3.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0443_shuffled_3.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1458_shuffled_0.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1458_shuffled_0.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0109_shuffled_3.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0109_shuffled_3.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250315_2006_shuffled_0.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250315_2006_shuffled_0.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1459_shuffled_2.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1459_shuffled_2.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1221_shuffled_0.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1221_shuffled_0.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250315_2007_shuffled_2.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250315_2007_shuffled_2.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0458_shuffled_4.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0458_shuffled_4.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1518_shuffled_2.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1518_shuffled_2.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1419_shuffled_2.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1419_shuffled_2.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250207_0249_shuffled_4.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250207_0249_shuffled_4.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0033_shuffled_2.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0033_shuffled_2.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1458_shuffled_1.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1458_shuffled_1.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1111_shuffled_4.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1111_shuffled_4.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0853_shuffled_1.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0853_shuffled_1.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1529_shuffled_0.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1529_shuffled_0.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1428_shuffled_1.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1428_shuffled_1.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250207_0007_shuffled_0.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250207_0007_shuffled_0.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1027_shuffled_3.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1027_shuffled_3.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1422_shuffled_0.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1422_shuffled_0.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0239_shuffled_2.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0239_shuffled_2.parquet\n",
      "Conversion complete: 140 file(s) converted.\n"
     ]
    }
   ],
   "execution_count": 485
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T17:24:26.775951Z",
     "start_time": "2025-03-18T17:24:26.773575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compare_answers(answer_llm, answer_exam):\n",
    "    \"\"\"Compares the extracted correct answers with the answers in answer_exam.\n",
    "\n",
    "    Keyword arguments:\n",
    "    answerLLM -- the list of answers extracted from the LLM answer\n",
    "    answer_exam -- list of answers from the exam\n",
    "    \"\"\"\n",
    "    # Convert answer_exam_list from letters to numbers\n",
    "    answerLLM = [ord(answer) - 65 for answer in answer_llm]\n",
    "\n",
    "    # Get number of correct answers in the exam\n",
    "    num_of_correct_exam_answers = len(answer_exam)\n",
    "\n",
    "    # Convert both lists to sets for efficient comparison\n",
    "    answer_LLM_set = set(answerLLM)\n",
    "    answer_exam_set = set(answer_exam)\n",
    "\n",
    "    # Calculate the count of matching answers\n",
    "    number_of_correct_llm_answers = len(answer_LLM_set.intersection(answer_exam_set))\n",
    "\n",
    "    #Calculate the number of incorrect answers\n",
    "    number_of_incorrect_llm_answers = len(answer_LLM_set.difference(answer_exam_set))\n",
    "\n",
    "    # Check if the number of answers given by the LLM is greater than the number of correct answers\n",
    "    too_many_answ_given = False\n",
    "    if len(answer_LLM_set) > num_of_correct_exam_answers:\n",
    "        too_many_answ_given = True\n",
    "\n",
    "    # Return a dictionary with the matching count and the number of correct answers\n",
    "    return number_of_correct_llm_answers, too_many_answ_given, number_of_incorrect_llm_answers"
   ],
   "id": "9d7d1643fb43932c",
   "outputs": [],
   "execution_count": 486
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T17:24:26.844424Z",
     "start_time": "2025-03-18T17:24:26.842168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluation_sampling(fn_extractor, full_llm_answer, exam_answers):\n",
    "    \"\"\"Analyse the answer given by the LLM and compare it with the exam answers.\n",
    "\n",
    "    Keyword arguments:\n",
    "    fn_extractor -- the function that extracts the answer(s) from the llm_answer\n",
    "    llm_answer -- the answer string given by the LLM\n",
    "    exam_Answers -- the list of answers from the exam\n",
    "    \"\"\"\n",
    "    num_of_correct_answer = len(exam_answers)\n",
    "\n",
    "    llm_answers = fn_extractor(full_llm_answer)\n",
    "    if llm_answers is not None:\n",
    "        num_of_correct_llm_Answers, too_many_answ, number_of_incorrect_llm_answers = compare_answers(llm_answers, exam_answers)\n",
    "        if num_of_correct_llm_Answers == num_of_correct_answer and too_many_answ == False:\n",
    "            answered_correctly = True\n",
    "        else:\n",
    "            answered_correctly = False\n",
    "        return num_of_correct_llm_Answers, llm_answers, too_many_answ, answered_correctly, number_of_incorrect_llm_answers\n",
    "    else:\n",
    "         return -1"
   ],
   "id": "337cb534d0eadd",
   "outputs": [],
   "execution_count": 487
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T17:49:57.409803Z",
     "start_time": "2025-03-18T17:49:57.403749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluation(llm_output_dataframe):\n",
    "\n",
    "    # Compute the number of total questions for each model\n",
    "    number_of_questions = llm_output_dataframe.groupby(['Model','Prompt_Engineering', 'Temperature', 'Exam'])['QuestionIndex'].count()\n",
    "\n",
    "    #Number of fully correct answers given by the LLM\n",
    "    correctly_answered = llm_output_dataframe.groupby(['Model', 'Prompt_Engineering', 'Temperature', 'Exam'])['Answered_Correctly'].sum()\n",
    "\n",
    "    #Number of incorrect answers given by the LLM\n",
    "    incorrectly_answered = number_of_questions - correctly_answered\n",
    "\n",
    "    #Amount of correct answers in the exam\n",
    "    amount_correct_exam_answers = llm_output_dataframe.groupby(['Model', 'Prompt_Engineering', 'Temperature', 'Exam'])['NumberOfCorrectExamAnswers'].sum()\n",
    "\n",
    "    #Amount of correct answers given by the LLM even if not fully correct\n",
    "    amount_correct_llm_answers = llm_output_dataframe.groupby(['Model', 'Prompt_Engineering', 'Temperature', 'Exam'])['NumberOfCorrectLLMAnswers'].sum()\n",
    "\n",
    "    # Calculate Partial Credits\n",
    "    llm_output_dataframe['Partial_Credit'] = llm_output_dataframe.apply(\n",
    "        lambda row: max(0, row['NumberOfCorrectLLMAnswers'] / row['NumberOfCorrectExamAnswers'] -\n",
    "                        (row['NumberOfIncorrectLLMAnswers'] /row['NumberOfCorrectExamAnswers'])), axis=1)\n",
    "\n",
    "    # Aggregate Partial Credit for each model\n",
    "    partial_credit_sum = llm_output_dataframe.groupby(['Model', 'Prompt_Engineering', 'Temperature', 'Exam'])['Partial_Credit'].sum()\n",
    "\n",
    "    #Calculation of Accuracy and Recall and f1 score\n",
    "    accuracy = correctly_answered / number_of_questions\n",
    "    accuracy_partial = partial_credit_sum / number_of_questions\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Number of Questions': number_of_questions,\n",
    "        'Correctly Answered': correctly_answered,\n",
    "        'Incorrectly Answered': incorrectly_answered,\n",
    "        'Accuracy': accuracy,\n",
    "        'Accuracy Partial': accuracy_partial,\n",
    "        'Total Partial Credit': partial_credit_sum\n",
    "    })\n",
    "\n",
    "    results_df = results_df.reset_index()\n",
    "\n",
    "    return results_df"
   ],
   "id": "a85e80c9501754c6",
   "outputs": [],
   "execution_count": 502
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T17:50:01.474333Z",
     "start_time": "2025-03-18T17:50:01.470006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_model_statistics_their(df):\n",
    "    \"\"\"\n",
    "    Calculates statistics for each model in the DataFrame.\n",
    "\n",
    "    Args:\n",
    "    df (DataFrame): Input DataFrame containing evaluation metrics for different models.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: New DataFrame containing calculated statistics for each model.\n",
    "    \"\"\"\n",
    "    model_stats = []\n",
    "    for model, group_df in df.groupby(['Model']):\n",
    "        model_stat = {\n",
    "            'Model': model,\n",
    "            'Accuracy Mean': group_df['Accuracy'].mean(),\n",
    "            'Accuracy Max': group_df['Accuracy'].max(),\n",
    "            'Accuracy Min': group_df['Accuracy'].min(),\n",
    "            'Accuracy STD': group_df['Accuracy'].std(),\n",
    "            'Accuracy Partial Mean': group_df['Accuracy Partial'].mean(),\n",
    "            'Accuracy Partial Max': group_df['Accuracy Partial'].max(),\n",
    "            'Accuracy Partial Min': group_df['Accuracy Partial'].min(),\n",
    "            'Accuracy Partial STD': group_df['Accuracy Partial'].std()\n",
    "        }\n",
    "        model_stats.append(model_stat)\n",
    "\n",
    "    return pd.DataFrame(model_stats)"
   ],
   "id": "9f3e753a04fdd0b7",
   "outputs": [],
   "execution_count": 503
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T17:50:04.790752Z",
     "start_time": "2025-03-18T17:50:04.786373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_model_statistics(df):\n",
    "    \"\"\"\n",
    "    Calculates statistics for each model in the DataFrame.\n",
    "\n",
    "    Args:\n",
    "    df (DataFrame): Input DataFrame containing evaluation metrics for different models.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: New DataFrame containing calculated statistics for each model, prompt engineering, and temperature.\n",
    "    \"\"\"\n",
    "    stats_df = df.groupby(['Model', 'Prompt_Engineering', 'Temperature', 'Exam']).agg(\n",
    "        Accuracy_Mean=('Accuracy', 'mean'),\n",
    "        Accuracy_Max=('Accuracy', 'max'),\n",
    "        Accuracy_Min=('Accuracy', 'min'),\n",
    "        Accuracy_STD=('Accuracy', 'std'),\n",
    "        Accuracy_Partial_Mean=('Accuracy Partial', 'mean'),\n",
    "        Accuracy_Partial_Max=('Accuracy Partial', 'max'),\n",
    "        Accuracy_Partial_Min=('Accuracy Partial', 'min'),\n",
    "        Accuracy_Partial_STD=('Accuracy Partial', 'std')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Replace NaN STD values with 0 (for groups with only one value)\n",
    "    stats_df.fillna(0, inplace=True)\n",
    "\n",
    "    return stats_df\n"
   ],
   "id": "754f0deaffefddb4",
   "outputs": [],
   "execution_count": 504
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T17:50:09.336525Z",
     "start_time": "2025-03-18T17:50:09.326931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def produce_statistics_from_batch(input_dir = \"./processed_results/\"):\n",
    "    # Get all .pkl files in the input directory\n",
    "    pkl_files = glob.glob(os.path.join(input_dir, \"*.pkl\"))\n",
    "\n",
    "    if not pkl_files:\n",
    "        print(f\"No .pkl files found in {input_dir}.\")\n",
    "        # return\n",
    "\n",
    "    print(f\"Found {len(pkl_files)} .pkl files in {input_dir}. Processing...\")\n",
    "\n",
    "    #Create a dataframe with the size of NUM_OF_SHUFFLES which contains the dataframe llm_exam_result\n",
    "    shuffled_evaluation_df = pd.DataFrame(columns=['Number of Questions', 'Correctly Answered', 'Incorrectly Answered', 'Accuracy', 'Accuracy Partial'])\n",
    "\n",
    "    # pickle_path = \"./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1523_shuffled_0.pkl\"\n",
    "    # pickles = [pickle_path,]\n",
    "\n",
    "    for pickle in pkl_files:\n",
    "        llm_exam_result = pd.DataFrame(columns = [\n",
    "            \"Model\",\n",
    "            \"Prompt_Engineering\",\n",
    "            \"Temperature\",\n",
    "            \"Exam\",\n",
    "            \"QuestionIndex\",\n",
    "            \"SamplingIndex\",\n",
    "            # \"Improved_Extracted_Answer_Column\",\n",
    "            # \"Their_Extracted_Answer_Column\",\n",
    "            # \"Differ\",\n",
    "            \"NumberOfChoices\",\n",
    "            \"NumberOfCorrectLLMAnswers\",\n",
    "            \"NumberOfIncorrectLLMAnswers\",\n",
    "            \"NumberOfCorrectExamAnswers\",\n",
    "            \"Ratio\",\n",
    "            \"LLM_Answer\",\n",
    "            \"Exam_Answers\",\n",
    "            \"Answered_Correctly\",\n",
    "            \"Too_Many_answers\"\n",
    "        ])\n",
    "        result_from_exam = pd.read_pickle(pickle)\n",
    "        for index_question, row in result_from_exam.iterrows():\n",
    "            num_of_correct_answer = len(row[\"Exam_Answers\"])\n",
    "            # num_of_choices = row[\"NumberOfChoices\"] # TODO: Do not need. Remove\n",
    "            # extracted_answer = row[\"Improved_Extracted_Answer\"]\n",
    "\n",
    "            num_of_correct_llm_answer, answerLLm, too_many_answers, answered_correctly, number_of_incorrect_llm_answers = evaluation_sampling(improved_extract_answer, row[\"LLM_Answer\"],row[\"Exam_Answers\"])\n",
    "\n",
    "            new_row = pd.DataFrame({\n",
    "                \"Model\": [row[\"Model\"]], # M\n",
    "                \"Prompt_Engineering\": [row[\"Prompt_Engineering\"]],\n",
    "                \"Temperature\": [row[\"Temperature\"]],\n",
    "                \"Exam\": [row[\"Exam\"]],\n",
    "                \"QuestionIndex\": [row[\"QuestionIndex\"]], # M\n",
    "                \"SamplingIndex\": [row[\"SamplingIndex\"]],\n",
    "                # \"Improved_Extracted_Answer\" : row[\"Improved_Extracted_Answer\"],\n",
    "                # \"Their_Extracted_Answer\": row[\"Their_Extracted_Answer\"],\n",
    "                # \"Differ\": row[\"Differ],\n",
    "                \"NumberOfChoices\": row[\"NumberOfChoices\"],\n",
    "                \"NumberOfIncorrectLLMAnswers\": number_of_incorrect_llm_answers, # M\n",
    "                \"NumberOfCorrectLLMAnswers\": [num_of_correct_llm_answer], # M\n",
    "                \"NumberOfCorrectExamAnswers\": [num_of_correct_answer], # M\n",
    "                \"Ratio\": [num_of_correct_llm_answer/num_of_correct_answer],\n",
    "                \"LLM_Answer\": [row[\"LLM_Answer\"]],\n",
    "                \"Exam_Answers\": [row[\"Exam_Answers\"]],\n",
    "                \"Answered_Correctly\" : [answered_correctly], # M\n",
    "                \"Too_Many_answers\": [too_many_answers]})\n",
    "\n",
    "            if llm_exam_result.empty:\n",
    "                llm_exam_result = new_row  # Directly assign instead of concatenating\n",
    "            else:\n",
    "                llm_exam_result = pd.concat([llm_exam_result, new_row], ignore_index=True)\n",
    "\n",
    "        evaluation_df = evaluation(llm_exam_result)\n",
    "        #Concat the evaluation dataframe to the complete dataframe\n",
    "\n",
    "        if shuffled_evaluation_df.empty:\n",
    "            shuffled_evaluation_df = evaluation_df  # Directly assign instead of concatenating\n",
    "        else:\n",
    "            shuffled_evaluation_df = pd.concat([shuffled_evaluation_df, evaluation_df], ignore_index=True)\n",
    "\n",
    "\n",
    "    print(shuffled_evaluation_df)\n",
    "    model_statistics = calculate_model_statistics(shuffled_evaluation_df)\n",
    "    print(model_statistics)"
   ],
   "id": "7aaa830e62a476c2",
   "outputs": [],
   "execution_count": 506
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T17:50:23.916876Z",
     "start_time": "2025-03-18T17:50:16.897748Z"
    }
   },
   "cell_type": "code",
   "source": "produce_statistics_from_batch()",
   "id": "c61f795b561422e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 140 .pkl files in ./processed_results/. Processing...\n",
      "                                        Model Prompt_Engineering  Temperature  \\\n",
      "0            meta-llama/Llama-3.1-8B-Instruct             0_shot          0.0   \n",
      "1            meta-llama/Llama-3.1-8B-Instruct             0_shot          0.0   \n",
      "2            meta-llama/Llama-3.1-8B-Instruct             5_shot          0.0   \n",
      "3            meta-llama/Llama-3.1-8B-Instruct             5_shot          0.7   \n",
      "4    deepseek-ai/DeepSeek-R1-Distill-Llama-8B             0_shot          0.7   \n",
      "..                                        ...                ...          ...   \n",
      "135          meta-llama/Llama-3.1-8B-Instruct             0_shot          0.7   \n",
      "136  deepseek-ai/DeepSeek-R1-Distill-Llama-8B             0_shot          0.0   \n",
      "137  deepseek-ai/DeepSeek-R1-Distill-Llama-8B             0_shot          0.0   \n",
      "138          meta-llama/Llama-3.1-8B-Instruct             0_shot          0.7   \n",
      "139  deepseek-ai/DeepSeek-R1-Distill-Llama-8B             0_shot          0.7   \n",
      "\n",
      "                           Exam  Number of Questions  Correctly Answered  \\\n",
      "0                  CCNP-350-701                  100                  59   \n",
      "1    MMLU-PRO-Computer-Security                   46                  20   \n",
      "2                  CCNA-201-301                  100                  55   \n",
      "3                  CCNA-201-301                  100                  58   \n",
      "4                  CCNP-350-701                  100                  51   \n",
      "..                          ...                  ...                 ...   \n",
      "135      MMLU-Computer-Security                  100                  67   \n",
      "136      MMLU-Computer-Security                  100                  69   \n",
      "137                CCNA-201-301                  100                  56   \n",
      "138      MMLU-Computer-Security                  100                  66   \n",
      "139      MMLU-Computer-Security                  100                  54   \n",
      "\n",
      "     Incorrectly Answered  Accuracy  Accuracy Partial  Total Partial Credit  \n",
      "0                      41  0.590000          0.605000                  60.5  \n",
      "1                      26  0.434783          0.434783                  20.0  \n",
      "2                      45  0.550000          0.550000                  55.0  \n",
      "3                      42  0.580000          0.580000                  58.0  \n",
      "4                      49  0.510000          0.515000                  51.5  \n",
      "..                    ...       ...               ...                   ...  \n",
      "135                    33  0.670000          0.670000                  67.0  \n",
      "136                    31  0.690000          0.690000                  69.0  \n",
      "137                    44  0.560000          0.570000                  57.0  \n",
      "138                    34  0.660000          0.660000                  66.0  \n",
      "139                    46  0.540000          0.540000                  54.0  \n",
      "\n",
      "[140 rows x 10 columns]\n",
      "                                       Model Prompt_Engineering  Temperature  \\\n",
      "0   deepseek-ai/DeepSeek-R1-Distill-Llama-8B             0_shot          0.0   \n",
      "1   deepseek-ai/DeepSeek-R1-Distill-Llama-8B             0_shot          0.0   \n",
      "2   deepseek-ai/DeepSeek-R1-Distill-Llama-8B             0_shot          0.0   \n",
      "3   deepseek-ai/DeepSeek-R1-Distill-Llama-8B             0_shot          0.0   \n",
      "4   deepseek-ai/DeepSeek-R1-Distill-Llama-8B             0_shot          0.7   \n",
      "5   deepseek-ai/DeepSeek-R1-Distill-Llama-8B             0_shot          0.7   \n",
      "6   deepseek-ai/DeepSeek-R1-Distill-Llama-8B             0_shot          0.7   \n",
      "7   deepseek-ai/DeepSeek-R1-Distill-Llama-8B         1_shot_cot          0.0   \n",
      "8   deepseek-ai/DeepSeek-R1-Distill-Llama-8B             5_shot          0.0   \n",
      "9   deepseek-ai/DeepSeek-R1-Distill-Llama-8B             5_shot          0.0   \n",
      "10  deepseek-ai/DeepSeek-R1-Distill-Llama-8B             5_shot          0.0   \n",
      "11  deepseek-ai/DeepSeek-R1-Distill-Llama-8B             5_shot          0.7   \n",
      "12  deepseek-ai/DeepSeek-R1-Distill-Llama-8B             5_shot          0.7   \n",
      "13  deepseek-ai/DeepSeek-R1-Distill-Llama-8B             5_shot          0.7   \n",
      "14          meta-llama/Llama-3.1-8B-Instruct             0_shot          0.0   \n",
      "15          meta-llama/Llama-3.1-8B-Instruct             0_shot          0.0   \n",
      "16          meta-llama/Llama-3.1-8B-Instruct             0_shot          0.0   \n",
      "17          meta-llama/Llama-3.1-8B-Instruct             0_shot          0.0   \n",
      "18          meta-llama/Llama-3.1-8B-Instruct             0_shot          0.7   \n",
      "19          meta-llama/Llama-3.1-8B-Instruct             0_shot          0.7   \n",
      "20          meta-llama/Llama-3.1-8B-Instruct             0_shot          0.7   \n",
      "21          meta-llama/Llama-3.1-8B-Instruct         1_shot_cot          0.0   \n",
      "22          meta-llama/Llama-3.1-8B-Instruct             5_shot          0.0   \n",
      "23          meta-llama/Llama-3.1-8B-Instruct             5_shot          0.0   \n",
      "24          meta-llama/Llama-3.1-8B-Instruct             5_shot          0.0   \n",
      "25          meta-llama/Llama-3.1-8B-Instruct             5_shot          0.7   \n",
      "26          meta-llama/Llama-3.1-8B-Instruct             5_shot          0.7   \n",
      "27          meta-llama/Llama-3.1-8B-Instruct             5_shot          0.7   \n",
      "\n",
      "                          Exam  Accuracy_Mean  Accuracy_Max  Accuracy_Min  \\\n",
      "0                 CCNA-201-301       0.556000      0.590000      0.530000   \n",
      "1                 CCNP-350-701       0.526000      0.550000      0.500000   \n",
      "2       MMLU-Computer-Security       0.632000      0.690000      0.580000   \n",
      "3   MMLU-PRO-Computer-Security       0.313043      0.369565      0.260870   \n",
      "4                 CCNA-201-301       0.502000      0.520000      0.460000   \n",
      "5                 CCNP-350-701       0.492000      0.530000      0.470000   \n",
      "6       MMLU-Computer-Security       0.570000      0.650000      0.540000   \n",
      "7   MMLU-PRO-Computer-Security       0.430435      0.456522      0.369565   \n",
      "8                 CCNA-201-301       0.506000      0.550000      0.480000   \n",
      "9                 CCNP-350-701       0.426000      0.480000      0.400000   \n",
      "10      MMLU-Computer-Security       0.716000      0.730000      0.700000   \n",
      "11                CCNA-201-301       0.470000      0.510000      0.390000   \n",
      "12                CCNP-350-701       0.390000      0.410000      0.360000   \n",
      "13      MMLU-Computer-Security       0.648000      0.690000      0.620000   \n",
      "14                CCNA-201-301       0.576000      0.610000      0.550000   \n",
      "15                CCNP-350-701       0.608000      0.670000      0.560000   \n",
      "16      MMLU-Computer-Security       0.606000      0.630000      0.570000   \n",
      "17  MMLU-PRO-Computer-Security       0.447826      0.500000      0.391304   \n",
      "18                CCNA-201-301       0.570000      0.600000      0.510000   \n",
      "19                CCNP-350-701       0.600000      0.660000      0.540000   \n",
      "20      MMLU-Computer-Security       0.648000      0.670000      0.610000   \n",
      "21  MMLU-PRO-Computer-Security       0.478261      0.543478      0.413043   \n",
      "22                CCNA-201-301       0.564000      0.580000      0.550000   \n",
      "23                CCNP-350-701       0.618000      0.660000      0.590000   \n",
      "24      MMLU-Computer-Security       0.782000      0.810000      0.770000   \n",
      "25                CCNA-201-301       0.568000      0.580000      0.550000   \n",
      "26                CCNP-350-701       0.588000      0.620000      0.570000   \n",
      "27      MMLU-Computer-Security       0.766000      0.790000      0.730000   \n",
      "\n",
      "    Accuracy_STD  Accuracy_Partial_Mean  Accuracy_Partial_Max  \\\n",
      "0       0.021909               0.564000              0.595000   \n",
      "1       0.019494               0.533000              0.560000   \n",
      "2       0.046043               0.632000              0.690000   \n",
      "3       0.052355               0.313043              0.369565   \n",
      "4       0.023875               0.514000              0.530000   \n",
      "5       0.026833               0.503000              0.545000   \n",
      "6       0.045826               0.570000              0.650000   \n",
      "7       0.038888               0.430435              0.456522   \n",
      "8       0.028810               0.510000              0.550000   \n",
      "9       0.032094               0.436000              0.485000   \n",
      "10      0.015166               0.716000              0.730000   \n",
      "11      0.046904               0.478000              0.525000   \n",
      "12      0.018708               0.401000              0.430000   \n",
      "13      0.027749               0.648000              0.690000   \n",
      "14      0.021909               0.576000              0.610000   \n",
      "15      0.049193               0.618000              0.675000   \n",
      "16      0.021909               0.606000              0.630000   \n",
      "17      0.050047               0.447826              0.500000   \n",
      "18      0.035355               0.571000              0.605000   \n",
      "19      0.043012               0.608000              0.665000   \n",
      "20      0.022804               0.648000              0.670000   \n",
      "21      0.055424               0.478261              0.543478   \n",
      "22      0.011402               0.564000              0.580000   \n",
      "23      0.034205               0.618000              0.660000   \n",
      "24      0.017889               0.782000              0.810000   \n",
      "25      0.010954               0.568000              0.580000   \n",
      "26      0.019235               0.590000              0.625000   \n",
      "27      0.023022               0.766000              0.790000   \n",
      "\n",
      "    Accuracy_Partial_Min  Accuracy_Partial_STD  \n",
      "0               0.540000              0.020433  \n",
      "1               0.510000              0.019235  \n",
      "2               0.580000              0.046043  \n",
      "3               0.260870              0.052355  \n",
      "4               0.470000              0.024850  \n",
      "5               0.480000              0.027065  \n",
      "6               0.540000              0.045826  \n",
      "7               0.369565              0.038888  \n",
      "8               0.490000              0.025495  \n",
      "9               0.420000              0.028151  \n",
      "10              0.700000              0.015166  \n",
      "11              0.400000              0.047776  \n",
      "12              0.365000              0.023822  \n",
      "13              0.620000              0.027749  \n",
      "14              0.550000              0.021909  \n",
      "15              0.570000              0.047249  \n",
      "16              0.570000              0.021909  \n",
      "17              0.391304              0.050047  \n",
      "18              0.510000              0.036469  \n",
      "19              0.550000              0.042071  \n",
      "20              0.610000              0.022804  \n",
      "21              0.413043              0.055424  \n",
      "22              0.550000              0.011402  \n",
      "23              0.590000              0.034205  \n",
      "24              0.770000              0.017889  \n",
      "25              0.550000              0.010954  \n",
      "26              0.570000              0.020917  \n",
      "27              0.730000              0.023022  \n"
     ]
    }
   ],
   "execution_count": 507
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
