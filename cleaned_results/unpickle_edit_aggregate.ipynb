{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T06:53:50.093252Z",
     "start_time": "2025-03-19T06:53:49.767371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import pickle\n",
    "import argparse\n",
    "import re\n",
    "import os"
   ],
   "id": "6adf86deb51f19a6",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T06:53:50.110544Z",
     "start_time": "2025-03-19T06:53:50.106273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def improved_extract_answer(answer):\n",
    "    \"\"\"Extracts the correct answers from the provided answer string with improved handling\n",
    "    for final answer statements.\n",
    "    \"\"\"\n",
    "    # Remove reasoning sections enclosed in <think> tags\n",
    "    answer = re.sub(r\"<think>.*?</think>\", \"\", answer, flags=re.DOTALL).strip()\n",
    "\n",
    "    # Check for final answer statement at the end of the text\n",
    "    final_answer = re.search(r\"(?:the\\s+)?answer\\s+is\\s+([A-J](?:\\s*,\\s*[A-J])*)\\s*\\.?\\s*$\",\n",
    "                            answer, re.IGNORECASE)\n",
    "    if final_answer:\n",
    "        letters = re.findall(r\"[A-J]\", final_answer.group(1))\n",
    "        if letters:\n",
    "            return sorted(set(letters))\n",
    "\n",
    "    # Continue with the existing patterns...\n",
    "    # Special case 1: Extract all \"[X]\" patterns in the entire text\n",
    "    bracketed_letters = re.findall(r\"\\[([A-J])\\]\", answer)\n",
    "    if len(bracketed_letters) > 1:\n",
    "        return sorted(set(bracketed_letters))\n",
    "\n",
    "    # Special case 2: \"Answer :[A, B, C]\" format\n",
    "    if re.search(r\"Answer\\s*:\\s*\\[\", answer, re.IGNORECASE):\n",
    "        brackets_with_commas = re.search(r\"\\[(.*?)\\]\", answer)\n",
    "        if brackets_with_commas:\n",
    "            content = brackets_with_commas.group(1)\n",
    "            letters = re.findall(r\"([A-J])\", content)\n",
    "            if letters:\n",
    "                return sorted(set(letters))\n",
    "\n",
    "    # Find the answer section using regular pattern - from last occurrence\n",
    "    answer_sections = list(re.finditer(\n",
    "        r\"(?:answer is|answer:|the correct answer is|therefore,\\s+the\\s+correct\\s+answer\\s+is)\\s*\"\n",
    "        r\"(.+?)\"\n",
    "        r\"(?:\\.|\\:|\\n|$)\",\n",
    "        answer, re.IGNORECASE\n",
    "    ))\n",
    "\n",
    "    # If found, use the last (most recent) answer section\n",
    "    if answer_sections:\n",
    "        last_match = answer_sections[-1]\n",
    "        answer_section = last_match.group(1).strip()\n",
    "\n",
    "        # Handle special case with 'not'\n",
    "        if \"not\" in answer_section.lower():\n",
    "            not_matches = re.findall(r\"not\\s+[\\[\\(\\*]?([A-J])[\\]\\)\\*]?\", answer_section, re.IGNORECASE)\n",
    "            all_matches = re.findall(r\"([A-J])\", answer_section)\n",
    "            return sorted(set([letter for letter in all_matches if letter not in not_matches]))\n",
    "\n",
    "        # Extract all letters directly\n",
    "        all_letters = re.findall(r\"([A-J])\", answer_section)\n",
    "        return sorted(set(all_letters))\n",
    "\n",
    "    return []"
   ],
   "id": "1a71136788db9914",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T06:53:50.185035Z",
     "start_time": "2025-03-19T06:53:50.182172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def improved_extract_answer_PREV_2(answer):\n",
    "    \"\"\"Extracts the correct answers from the provided answer string.\n",
    "\n",
    "    Args:\n",
    "        answer: The answer string to extract the correct answers from.\n",
    "\n",
    "    Returns:\n",
    "        A list of correct answers.\n",
    "    \"\"\"\n",
    "    # Remove reasoning sections enclosed in <think> tags\n",
    "    answer = re.sub(r\"<think>.*?</think>\", \"\", answer, flags=re.DOTALL).strip()\n",
    "\n",
    "    # Special case 1: Extract all \"[X]\" patterns in the entire text\n",
    "    bracketed_letters = re.findall(r\"\\[([A-J])\\]\", answer)\n",
    "    if len(bracketed_letters) > 1:\n",
    "        return sorted(set(bracketed_letters))\n",
    "\n",
    "    # Special case 2: \"Answer :[A, B, C]\" format (comma-separated list in one bracket)\n",
    "    if re.search(r\"Answer\\s*:\\s*\\[\", answer, re.IGNORECASE):\n",
    "        brackets_with_commas = re.search(r\"\\[(.*?)\\]\", answer)\n",
    "        if brackets_with_commas:\n",
    "            content = brackets_with_commas.group(1)\n",
    "            letters = re.findall(r\"([A-J])\", content)\n",
    "            if letters:\n",
    "                return sorted(set(letters))\n",
    "\n",
    "    # Find the answer section using regular pattern\n",
    "    pattern = re.compile(\n",
    "        r\"(?:answer is|answer:)\\s*\"  # Match indicators like \"answer is\" or \"answer:\"\n",
    "        r\"(.+?)\"  # Capture everything after the indicator\n",
    "        r\"(?:\\.|\\:|\\n|$)\",  # Until a period, colon, newline, or end of string\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    match = pattern.search(answer)\n",
    "    if not match:\n",
    "        return []\n",
    "\n",
    "    answer_section = match.group(1).strip()\n",
    "\n",
    "    # Handle special case with 'not'\n",
    "    if \"not\" in answer_section.lower():\n",
    "        not_matches = re.findall(r\"not\\s+[\\[\\(\\*]?([A-J])[\\]\\)\\*]?\", answer_section, re.IGNORECASE)\n",
    "        all_matches = re.findall(r\"([A-J])\", answer_section)\n",
    "\n",
    "        # Filter out 'not' letters\n",
    "        return sorted(set([letter for letter in all_matches if letter not in not_matches]))\n",
    "\n",
    "    # Extract all letters directly\n",
    "    all_letters = re.findall(r\"([A-J])\", answer_section)\n",
    "\n",
    "    return sorted(set(all_letters))  # Remove duplicates and return sorted list\n",
    "\n"
   ],
   "id": "c1b1c507fd990ad",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T06:53:50.237056Z",
     "start_time": "2025-03-19T06:53:50.233305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def improved_extract_answer_PREV(answer):\n",
    "    \"\"\"Extracts the correct answers from the provided answer string.\n",
    "\n",
    "    Args:\n",
    "        answer: The answer string to extract the correct answers from.\n",
    "\n",
    "    Returns:\n",
    "        A list of correct answers.\n",
    "    \"\"\"\n",
    "    # Remove reasoning sections enclosed in <think> tags\n",
    "    answer = re.sub(r\"<think>.*?</think>\", \"\", answer, flags=re.DOTALL).strip()\n",
    "\n",
    "    # Pattern 1: Direct \"answer is X\" pattern\n",
    "    direct_answer = re.search(r\"(?:the\\s+)?answer\\s+is\\s+([A-J](?:\\s*,\\s*[A-J])*)\", answer, re.IGNORECASE)\n",
    "    if direct_answer:\n",
    "        letters = re.findall(r\"[A-J]\", direct_answer.group(1))\n",
    "        if letters:\n",
    "            return sorted(set(letters))\n",
    "\n",
    "    # Pattern 2: \"The answer is ABCDE\" (multiple consecutive letters without spaces)\n",
    "    consecutive_letters = re.search(r\"(?:answer is|answer:)\\s*([A-J]{2,})\", answer, re.IGNORECASE)\n",
    "    if consecutive_letters:\n",
    "        letters = list(consecutive_letters.group(1))\n",
    "        return sorted(set(letters))\n",
    "\n",
    "    # Special case 1: Extract all \"[X]\" patterns in the entire text\n",
    "    bracketed_letters = re.findall(r\"\\[([A-J])\\]\", answer)\n",
    "    if len(bracketed_letters) > 1:\n",
    "        return sorted(set(bracketed_letters))\n",
    "\n",
    "    # Special case 2: \"Answer :[A, B, C]\" format (comma-separated list in one bracket)\n",
    "    if re.search(r\"Answer\\s*:\\s*\\[\", answer, re.IGNORECASE):\n",
    "        brackets_with_commas = re.search(r\"\\[(.*?)\\]\", answer)\n",
    "        if brackets_with_commas:\n",
    "            content = brackets_with_commas.group(1)\n",
    "            letters = re.findall(r\"([A-J])\", content)\n",
    "            if letters:\n",
    "                return sorted(set(letters))\n",
    "\n",
    "    # Find the answer section using regular pattern\n",
    "    pattern = re.compile(\n",
    "        r\"(?:answer is|answer:)\\s*\"  # Match indicators like \"answer is\" or \"answer:\"\n",
    "        r\"(.+?)\"  # Capture everything after the indicator\n",
    "        r\"(?:\\.|\\:|\\n|$|\\\"\\\"\\\"\\\")\",  # Until a period, colon, newline, end of string, or 4 quote marks\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    match = pattern.search(answer)\n",
    "    if not match:\n",
    "        return []\n",
    "\n",
    "    answer_section = match.group(1).strip()\n",
    "\n",
    "    # Handle special case with 'not'\n",
    "    if \"not\" in answer_section.lower():\n",
    "        not_matches = re.findall(r\"not\\s+[\\[\\(\\*]?([A-J])[\\]\\)\\*]?\", answer_section, re.IGNORECASE)\n",
    "        all_matches = re.findall(r\"([A-J])\", answer_section)\n",
    "\n",
    "        # Filter out 'not' letters\n",
    "        return sorted(set([letter for letter in all_matches if letter not in not_matches]))\n",
    "\n",
    "    # Extract all letters directly\n",
    "    all_letters = re.findall(r\"([A-J])\", answer_section)\n",
    "\n",
    "    return sorted(set(all_letters))  # Remove duplicates and return sorted list"
   ],
   "id": "c10644401e1f840e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T06:53:50.285209Z",
     "start_time": "2025-03-19T06:53:50.282593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def their_extract_answer(answer):\n",
    "    \"\"\"Extracts the correct answers from the provided answer string.\n",
    "\n",
    "    Args:\n",
    "        answer: The answer string to extract the correct answers from.\n",
    "\n",
    "    Returns:\n",
    "        A list of correct answers.\n",
    "    \"\"\"\n",
    "\n",
    "    # Cleaning the input by removing some non-relevant characters\n",
    "    answer_proc = re.sub(r'[\\s\\n.,]', '', answer)\n",
    "\n",
    "    # Define regex patterns for different cases\n",
    "    pattern_single_letters = re.compile(r'^[A-J]+$')\n",
    "    #pattern1 = re.compile(r\"answer is \\(?([A-J]+)\\)?\", re.IGNORECASE)\n",
    "    pattern1 = re.compile(r\"answer is \\[?([A-J]+)\\]?\", re.IGNORECASE)\n",
    "    pattern2 = re.compile(r'.*[aA]nswer:\\s*([A-J]+)', re.IGNORECASE)\n",
    "\n",
    "    if re.match(pattern_single_letters, answer_proc):\n",
    "        return list(answer_proc)\n",
    "    else:\n",
    "        # Find matches using the first regex pattern\n",
    "        #drop , from answer\n",
    "\n",
    "        match1 = pattern1.findall(answer)\n",
    "\n",
    "        # Find matches using the second regex pattern\n",
    "        match2 = pattern2.findall(answer)\n",
    "\n",
    "        # Combine results from both patterns\n",
    "        results = match1 + match2\n",
    "\n",
    "        # Flatten the list and remove duplicates\n",
    "        combined_results = []\n",
    "        for result in results:\n",
    "            combined_results.extend(list(result))\n",
    "\n",
    "        return list(set(combined_results))"
   ],
   "id": "e8e579cca0509289",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T06:53:50.350809Z",
     "start_time": "2025-03-19T06:53:50.347024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_function(function_to_test):\n",
    "    \"\"\"Test the improved_extract_answer function with various cases.\"\"\"\n",
    "    test_cases = [\n",
    "        # Previously correct cases\n",
    "        (\"The answer is ABCDE.\", ['A', 'B', 'C', 'D', 'E']),\n",
    "        (\"The best answer is C, E.\", ['C', 'E']),\n",
    "        (\"The best answer is [DE]. The access and distribution layers must be on the same device\", ['D', 'E']),\n",
    "        (\"Answer:[A, B, C]\", ['A', 'B', 'C']),\n",
    "        (\"The best answer is A, and not B.\", ['A']),\n",
    "        (\"Answer: A and B:\", ['A', 'B']),\n",
    "        (\"The best answer is *A*\", ['A']),\n",
    "        (\"The best answer is (A)\", ['A']),\n",
    "\n",
    "        # Previously incorrect cases\n",
    "        (\"The best answer is A, and B.\", ['A', 'B']),\n",
    "        (\"The best answer is (A), (B), and (C)\", ['A', 'B', 'C']),\n",
    "        (\"Answer: [A], [B], and [C]:\", ['A', 'B', 'C']),\n",
    "        (\"Answer: A, B, and C:\", ['A', 'B', 'C']),\n",
    "        (\"Answer: A, B, C:\", ['A', 'B', 'C']),\n",
    "\n",
    "        # New test case\n",
    "        (\"Some text\\n\\nthe answer is B\", ['B']),\n",
    "\n",
    "        # Think case\n",
    "        (\"\"\"\n",
    "<think>\n",
    "Okay, so I have this question about the ip route command in Cisco IOS. I'm a bit new to this, but I'll try to work through it step by step. The question is asking which two statements are true about the command: ip route 172.16.3.0 255.255.255.0 192.168.2.4.\n",
    "So the true statements are A and E.\n",
    "</think>\n",
    "\n",
    "The best answer is A and E.\n",
    "\"\"\", ['A','E']),\n",
    "        (\"\"\"\n",
    "Looking at the options, the question is which one they do NOT provide. So the answer is the one that's not a function of encryption.\n",
    "\n",
    "Integrity is about data integrity, which is separate. So B is not provided by encryption.\n",
    "\n",
    "Wait, but the question is about what they do NOT provide. So the correct answer is B. Integrity.\n",
    "\n",
    "Wait, but I'm a bit confused. Let me think again. Encryption ensures that only authorized people can read the data, so it's about confidentiality. It doesn't ensure that the data hasn't been altered (integrity) or that the system is reliable. So the answer is B. Integrity.\n",
    "</think>\n",
    "\n",
    "The question asks which aspect encryption and decryption do not provide. Encryption focuses on confidentiality, not integrity. Therefore, the correct answer is:\n",
    "\n",
    "B. Integrity\n",
    "\n",
    "the answer is B\"\"\", ['B']),\n",
    "\n",
    "        (\"\"\"<think>\n",
    "Looking at the options, the question is which one they do NOT provide. So the answer is the one that's not a function of encryption.\n",
    "\n",
    "Integrity is about data integrity, which is separate. So B is not provided by encryption.\n",
    "\n",
    "Wait, but the question is about what they do NOT provide. So the correct answer is B. Integrity.\n",
    "\n",
    "Wait, but I'm a bit confused. Let me think again. Encryption ensures that only authorized people can read the data, so it's about confidentiality. It doesn't ensure that the data hasn't been altered (integrity) or that the system is reliable. So the answer is B. Integrity.\n",
    "</think>\n",
    "\n",
    "The question asks which aspect encryption and decryption do not provide. Encryption focuses on confidentiality, not integrity. Therefore, the correct answer is:\n",
    "\n",
    "B. Integrity\n",
    "\n",
    "the answer is B\"\"\", ['B'])\n",
    "    ]\n",
    "\n",
    "    passed_all_tests = True\n",
    "    for input_text, expected_output in test_cases:\n",
    "        result = function_to_test(input_text)\n",
    "        print(f\"{input_text} : {result} {'✓' if result == expected_output else '✗'}\")\n",
    "        if result != expected_output:\n",
    "            passed_all_tests = False\n",
    "\n",
    "    if passed_all_tests:\n",
    "        print(\"All tests passed\")\n",
    "    else:\n",
    "        print(\"Some tests failed\")"
   ],
   "id": "45ac9f42df6f6c46",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T06:53:50.410635Z",
     "start_time": "2025-03-19T06:53:50.405325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "print(\"Previous Improved extracted answer function\")\n",
    "test_function(improved_extract_answer)\n"
   ],
   "id": "b2d9013d9db9f97",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Improved extracted answer function\n",
      "The answer is ABCDE. : ['A', 'B', 'C', 'D', 'E'] ✓\n",
      "The best answer is C, E. : ['C', 'E'] ✓\n",
      "The best answer is [DE]. The access and distribution layers must be on the same device : ['D', 'E'] ✓\n",
      "Answer:[A, B, C] : ['A', 'B', 'C'] ✓\n",
      "The best answer is A, and not B. : ['A'] ✓\n",
      "Answer: A and B: : ['A', 'B'] ✓\n",
      "The best answer is *A* : ['A'] ✓\n",
      "The best answer is (A) : ['A'] ✓\n",
      "The best answer is A, and B. : ['A', 'B'] ✓\n",
      "The best answer is (A), (B), and (C) : ['A', 'B', 'C'] ✓\n",
      "Answer: [A], [B], and [C]: : ['A', 'B', 'C'] ✓\n",
      "Answer: A, B, and C: : ['A', 'B', 'C'] ✓\n",
      "Answer: A, B, C: : ['A', 'B', 'C'] ✓\n",
      "Some text\n",
      "\n",
      "the answer is B : ['B'] ✓\n",
      "\n",
      "<think>\n",
      "Okay, so I have this question about the ip route command in Cisco IOS. I'm a bit new to this, but I'll try to work through it step by step. The question is asking which two statements are true about the command: ip route 172.16.3.0 255.255.255.0 192.168.2.4.\n",
      "So the true statements are A and E.\n",
      "</think>\n",
      "\n",
      "The best answer is A and E.\n",
      " : ['A', 'E'] ✓\n",
      "\n",
      "Looking at the options, the question is which one they do NOT provide. So the answer is the one that's not a function of encryption.\n",
      "\n",
      "Integrity is about data integrity, which is separate. So B is not provided by encryption.\n",
      "\n",
      "Wait, but the question is about what they do NOT provide. So the correct answer is B. Integrity.\n",
      "\n",
      "Wait, but I'm a bit confused. Let me think again. Encryption ensures that only authorized people can read the data, so it's about confidentiality. It doesn't ensure that the data hasn't been altered (integrity) or that the system is reliable. So the answer is B. Integrity.\n",
      "</think>\n",
      "\n",
      "The question asks which aspect encryption and decryption do not provide. Encryption focuses on confidentiality, not integrity. Therefore, the correct answer is:\n",
      "\n",
      "B. Integrity\n",
      "\n",
      "the answer is B : ['B'] ✓\n",
      "<think>\n",
      "Looking at the options, the question is which one they do NOT provide. So the answer is the one that's not a function of encryption.\n",
      "\n",
      "Integrity is about data integrity, which is separate. So B is not provided by encryption.\n",
      "\n",
      "Wait, but the question is about what they do NOT provide. So the correct answer is B. Integrity.\n",
      "\n",
      "Wait, but I'm a bit confused. Let me think again. Encryption ensures that only authorized people can read the data, so it's about confidentiality. It doesn't ensure that the data hasn't been altered (integrity) or that the system is reliable. So the answer is B. Integrity.\n",
      "</think>\n",
      "\n",
      "The question asks which aspect encryption and decryption do not provide. Encryption focuses on confidentiality, not integrity. Therefore, the correct answer is:\n",
      "\n",
      "B. Integrity\n",
      "\n",
      "the answer is B : ['B'] ✓\n",
      "All tests passed\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T06:53:50.463995Z",
     "start_time": "2025-03-19T06:53:50.460288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Prev Improved extracted answer function\")\n",
    "test_function(improved_extract_answer_PREV)"
   ],
   "id": "bcd4d35bed5b2794",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prev Improved extracted answer function\n",
      "The answer is ABCDE. : ['A'] ✗\n",
      "The best answer is C, E. : ['C', 'E'] ✓\n",
      "The best answer is [DE]. The access and distribution layers must be on the same device : ['D', 'E'] ✓\n",
      "Answer:[A, B, C] : ['A', 'B', 'C'] ✓\n",
      "The best answer is A, and not B. : ['A'] ✓\n",
      "Answer: A and B: : ['A', 'B'] ✓\n",
      "The best answer is *A* : ['A'] ✓\n",
      "The best answer is (A) : ['A'] ✓\n",
      "The best answer is A, and B. : ['A'] ✗\n",
      "The best answer is (A), (B), and (C) : ['A', 'B', 'C'] ✓\n",
      "Answer: [A], [B], and [C]: : ['A', 'B', 'C'] ✓\n",
      "Answer: A, B, and C: : ['A', 'B', 'C'] ✓\n",
      "Answer: A, B, C: : ['A', 'B', 'C'] ✓\n",
      "Some text\n",
      "\n",
      "the answer is B : ['B'] ✓\n",
      "\n",
      "<think>\n",
      "Okay, so I have this question about the ip route command in Cisco IOS. I'm a bit new to this, but I'll try to work through it step by step. The question is asking which two statements are true about the command: ip route 172.16.3.0 255.255.255.0 192.168.2.4.\n",
      "So the true statements are A and E.\n",
      "</think>\n",
      "\n",
      "The best answer is A and E.\n",
      " : ['A'] ✗\n",
      "\n",
      "Looking at the options, the question is which one they do NOT provide. So the answer is the one that's not a function of encryption.\n",
      "\n",
      "Integrity is about data integrity, which is separate. So B is not provided by encryption.\n",
      "\n",
      "Wait, but the question is about what they do NOT provide. So the correct answer is B. Integrity.\n",
      "\n",
      "Wait, but I'm a bit confused. Let me think again. Encryption ensures that only authorized people can read the data, so it's about confidentiality. It doesn't ensure that the data hasn't been altered (integrity) or that the system is reliable. So the answer is B. Integrity.\n",
      "</think>\n",
      "\n",
      "The question asks which aspect encryption and decryption do not provide. Encryption focuses on confidentiality, not integrity. Therefore, the correct answer is:\n",
      "\n",
      "B. Integrity\n",
      "\n",
      "the answer is B : ['B'] ✓\n",
      "<think>\n",
      "Looking at the options, the question is which one they do NOT provide. So the answer is the one that's not a function of encryption.\n",
      "\n",
      "Integrity is about data integrity, which is separate. So B is not provided by encryption.\n",
      "\n",
      "Wait, but the question is about what they do NOT provide. So the correct answer is B. Integrity.\n",
      "\n",
      "Wait, but I'm a bit confused. Let me think again. Encryption ensures that only authorized people can read the data, so it's about confidentiality. It doesn't ensure that the data hasn't been altered (integrity) or that the system is reliable. So the answer is B. Integrity.\n",
      "</think>\n",
      "\n",
      "The question asks which aspect encryption and decryption do not provide. Encryption focuses on confidentiality, not integrity. Therefore, the correct answer is:\n",
      "\n",
      "B. Integrity\n",
      "\n",
      "the answer is B : ['B'] ✓\n",
      "Some tests failed\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T06:53:50.516665Z",
     "start_time": "2025-03-19T06:53:50.513035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Prev 2 Improved extracted answer function\")\n",
    "test_function(improved_extract_answer_PREV_2)\n"
   ],
   "id": "baa3d5b978e528a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prev 2 Improved extracted answer function\n",
      "The answer is ABCDE. : ['A', 'B', 'C', 'D', 'E'] ✓\n",
      "The best answer is C, E. : ['C', 'E'] ✓\n",
      "The best answer is [DE]. The access and distribution layers must be on the same device : ['D', 'E'] ✓\n",
      "Answer:[A, B, C] : ['A', 'B', 'C'] ✓\n",
      "The best answer is A, and not B. : ['A'] ✓\n",
      "Answer: A and B: : ['A', 'B'] ✓\n",
      "The best answer is *A* : ['A'] ✓\n",
      "The best answer is (A) : ['A'] ✓\n",
      "The best answer is A, and B. : ['A', 'B'] ✓\n",
      "The best answer is (A), (B), and (C) : ['A', 'B', 'C'] ✓\n",
      "Answer: [A], [B], and [C]: : ['A', 'B', 'C'] ✓\n",
      "Answer: A, B, and C: : ['A', 'B', 'C'] ✓\n",
      "Answer: A, B, C: : ['A', 'B', 'C'] ✓\n",
      "Some text\n",
      "\n",
      "the answer is B : ['B'] ✓\n",
      "\n",
      "<think>\n",
      "Okay, so I have this question about the ip route command in Cisco IOS. I'm a bit new to this, but I'll try to work through it step by step. The question is asking which two statements are true about the command: ip route 172.16.3.0 255.255.255.0 192.168.2.4.\n",
      "So the true statements are A and E.\n",
      "</think>\n",
      "\n",
      "The best answer is A and E.\n",
      " : ['A', 'E'] ✓\n",
      "\n",
      "Looking at the options, the question is which one they do NOT provide. So the answer is the one that's not a function of encryption.\n",
      "\n",
      "Integrity is about data integrity, which is separate. So B is not provided by encryption.\n",
      "\n",
      "Wait, but the question is about what they do NOT provide. So the correct answer is B. Integrity.\n",
      "\n",
      "Wait, but I'm a bit confused. Let me think again. Encryption ensures that only authorized people can read the data, so it's about confidentiality. It doesn't ensure that the data hasn't been altered (integrity) or that the system is reliable. So the answer is B. Integrity.\n",
      "</think>\n",
      "\n",
      "The question asks which aspect encryption and decryption do not provide. Encryption focuses on confidentiality, not integrity. Therefore, the correct answer is:\n",
      "\n",
      "B. Integrity\n",
      "\n",
      "the answer is B : [] ✗\n",
      "<think>\n",
      "Looking at the options, the question is which one they do NOT provide. So the answer is the one that's not a function of encryption.\n",
      "\n",
      "Integrity is about data integrity, which is separate. So B is not provided by encryption.\n",
      "\n",
      "Wait, but the question is about what they do NOT provide. So the correct answer is B. Integrity.\n",
      "\n",
      "Wait, but I'm a bit confused. Let me think again. Encryption ensures that only authorized people can read the data, so it's about confidentiality. It doesn't ensure that the data hasn't been altered (integrity) or that the system is reliable. So the answer is B. Integrity.\n",
      "</think>\n",
      "\n",
      "The question asks which aspect encryption and decryption do not provide. Encryption focuses on confidentiality, not integrity. Therefore, the correct answer is:\n",
      "\n",
      "B. Integrity\n",
      "\n",
      "the answer is B : [] ✗\n",
      "Some tests failed\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T06:53:50.571078Z",
     "start_time": "2025-03-19T06:53:50.564695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Their extracted answer function\")\n",
    "test_function(their_extract_answer)"
   ],
   "id": "a70fff581ea255da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Their extracted answer function\n",
      "The answer is ABCDE. : ['D', 'E', 'C', 'A', 'B'] ✗\n",
      "The best answer is C, E. : ['C'] ✗\n",
      "The best answer is [DE]. The access and distribution layers must be on the same device : ['D', 'E'] ✓\n",
      "Answer:[A, B, C] : [] ✗\n",
      "The best answer is A, and not B. : ['A'] ✓\n",
      "Answer: A and B: : ['A'] ✗\n",
      "The best answer is *A* : [] ✗\n",
      "The best answer is (A) : [] ✗\n",
      "The best answer is A, and B. : ['A'] ✗\n",
      "The best answer is (A), (B), and (C) : [] ✗\n",
      "Answer: [A], [B], and [C]: : [] ✗\n",
      "Answer: A, B, and C: : ['A'] ✗\n",
      "Answer: A, B, C: : ['A'] ✗\n",
      "Some text\n",
      "\n",
      "the answer is B : ['B'] ✓\n",
      "\n",
      "<think>\n",
      "Okay, so I have this question about the ip route command in Cisco IOS. I'm a bit new to this, but I'll try to work through it step by step. The question is asking which two statements are true about the command: ip route 172.16.3.0 255.255.255.0 192.168.2.4.\n",
      "So the true statements are A and E.\n",
      "</think>\n",
      "\n",
      "The best answer is A and E.\n",
      " : ['A'] ✗\n",
      "\n",
      "Looking at the options, the question is which one they do NOT provide. So the answer is the one that's not a function of encryption.\n",
      "\n",
      "Integrity is about data integrity, which is separate. So B is not provided by encryption.\n",
      "\n",
      "Wait, but the question is about what they do NOT provide. So the correct answer is B. Integrity.\n",
      "\n",
      "Wait, but I'm a bit confused. Let me think again. Encryption ensures that only authorized people can read the data, so it's about confidentiality. It doesn't ensure that the data hasn't been altered (integrity) or that the system is reliable. So the answer is B. Integrity.\n",
      "</think>\n",
      "\n",
      "The question asks which aspect encryption and decryption do not provide. Encryption focuses on confidentiality, not integrity. Therefore, the correct answer is:\n",
      "\n",
      "B. Integrity\n",
      "\n",
      "the answer is B : ['B'] ✓\n",
      "<think>\n",
      "Looking at the options, the question is which one they do NOT provide. So the answer is the one that's not a function of encryption.\n",
      "\n",
      "Integrity is about data integrity, which is separate. So B is not provided by encryption.\n",
      "\n",
      "Wait, but the question is about what they do NOT provide. So the correct answer is B. Integrity.\n",
      "\n",
      "Wait, but I'm a bit confused. Let me think again. Encryption ensures that only authorized people can read the data, so it's about confidentiality. It doesn't ensure that the data hasn't been altered (integrity) or that the system is reliable. So the answer is B. Integrity.\n",
      "</think>\n",
      "\n",
      "The question asks which aspect encryption and decryption do not provide. Encryption focuses on confidentiality, not integrity. Therefore, the correct answer is:\n",
      "\n",
      "B. Integrity\n",
      "\n",
      "the answer is B : ['B'] ✓\n",
      "Some tests failed\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T06:53:50.622379Z",
     "start_time": "2025-03-19T06:53:50.618433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_value(value):\n",
    "    \"\"\"\n",
    "    Modify this function to define how you want to process the values.\n",
    "    \"\"\"\n",
    "    return value * 2  # Example: Modify as per your requirements\n",
    "\n",
    "def process_pkl(input_file, output_file, llm_answer_column, temperature, exam, prompt_engineering):\n",
    "    # Load the DataFrame\n",
    "    with open(input_file, \"rb\") as f:\n",
    "        df = pickle.load(f)\n",
    "\n",
    "    # Ensure input column exists before processing\n",
    "    if llm_answer_column not in df.columns:\n",
    "        raise ValueError(f\"Column '{llm_answer_column}' not found in the DataFrame.\")\n",
    "\n",
    "    improved_extracted_answer_column = \"Improved_Extracted_Answer_Column\"\n",
    "    their_extracted_answer_column = \"Their_Extracted_Answer_Column\"\n",
    "\n",
    "    # Apply functions to the llm answer column and save results in the new columns\n",
    "    df[improved_extracted_answer_column] = df[llm_answer_column].apply(improved_extract_answer)\n",
    "    df[their_extracted_answer_column] = df[llm_answer_column].apply(their_extract_answer)\n",
    "\n",
    "    # Add new columns with constant values\n",
    "    df[\"Temperature\"] = temperature\n",
    "    df[\"Exam\"] = exam\n",
    "    df[\"Prompt_Engineering\"] = prompt_engineering\n",
    "    df[\"Differ\"] = df[their_extracted_answer_column] != df[improved_extracted_answer_column]\n",
    "\n",
    "    # Define columns to keep\n",
    "    selected_columns = [\"Exam\",\n",
    "                        \"QuestionIndex\",\n",
    "                        \"NumberOfChoices\",\n",
    "                        \"Model\",\n",
    "                        \"SamplingIndex\",\n",
    "                        \"Temperature\",\n",
    "                        \"Prompt_Engineering\",\n",
    "                        llm_answer_column,\n",
    "                        \"Exam_Answers\",\n",
    "                        improved_extracted_answer_column,\n",
    "                        their_extracted_answer_column,\n",
    "                        \"Differ\"]\n",
    "\n",
    "    # Select only the specified columns\n",
    "    df_selected = df[selected_columns]\n",
    "\n",
    "    # Save the modified DataFrame as a .pkl file\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        pickle.dump(df_selected, f)\n",
    "\n",
    "    print(f\"Processed file saved as: {output_file}\")"
   ],
   "id": "8db911583c92e183",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T06:53:50.669107Z",
     "start_time": "2025-03-19T06:53:50.666232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def batch_process_pkl(input_dir, output_dir, llm_answer_column, temperature, exam, prompt_engineering):\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Get all .pkl files in the input directory\n",
    "    pkl_files = glob.glob(os.path.join(input_dir, \"*.pkl\"))\n",
    "\n",
    "    if not pkl_files:\n",
    "        print(f\"No .pkl files found in {input_dir}.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(pkl_files)} .pkl files in {input_dir}. Processing...\")\n",
    "\n",
    "    # Loop through each file and process it\n",
    "    for input_file in pkl_files:\n",
    "        # Generate output file path\n",
    "        filename = os.path.basename(input_file)\n",
    "        output_file = os.path.join(output_dir, f\"processed_{filename}\")\n",
    "\n",
    "        # Process and save\n",
    "        process_pkl(input_file, output_file, llm_answer_column, temperature, exam, prompt_engineering)"
   ],
   "id": "30326691339cb54b",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T06:54:25.822899Z",
     "start_time": "2025-03-19T06:53:50.716192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# CCNA\n",
    "batch_process_pkl(\n",
    "    input_dir=\"./exam/201-301-ccna/0_shot/t00/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    llm_answer_column=\"LLM_Answer\",\n",
    "    temperature=0.0,\n",
    "    exam=\"CCNA-201-301\",\n",
    "    prompt_engineering=\"0_shot\"\n",
    ")\n",
    "\n",
    "batch_process_pkl(\n",
    "    input_dir=\"./exam/201-301-ccna/0_shot/t07/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    llm_answer_column=\"LLM_Answer\",\n",
    "    temperature=0.7,\n",
    "    exam=\"CCNA-201-301\",\n",
    "    prompt_engineering=\"0_shot\"\n",
    ")\n",
    "\n",
    "batch_process_pkl(\n",
    "    input_dir=\"./exam/201-301-ccna/5_shot/t00/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    llm_answer_column=\"LLM_Answer\",\n",
    "    temperature=0.0,\n",
    "    exam=\"CCNA-201-301\",\n",
    "    prompt_engineering=\"5_shot\"\n",
    ")\n",
    "\n",
    "batch_process_pkl(\n",
    "    input_dir=\"./exam/201-301-ccna/5_shot/t07/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    llm_answer_column=\"LLM_Answer\",\n",
    "    temperature=0.7,\n",
    "    exam=\"CCNA-201-301\",\n",
    "    prompt_engineering=\"5_shot\"\n",
    ")\n",
    "\n"
   ],
   "id": "a2f8251192d40550",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 .pkl files in ./exam/201-301-ccna/0_shot/t00/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0853_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1528_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1111_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1027_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1525_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0938_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0810_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1523_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1527_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1527_shuffled_2.pkl\n",
      "Found 10 .pkl files in ./exam/201-301-ccna/0_shot/t07/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1220_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1501_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1146_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1116_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1252_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1501_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1503_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1320_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1504_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1502_shuffled_2.pkl\n",
      "Found 10 .pkl files in ./exam/201-301-ccna/5_shot/t00/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1306_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1529_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1333_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1532_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1530_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1426_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1530_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1447_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1357_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1532_shuffled_4.pkl\n",
      "Found 10 .pkl files in ./exam/201-301-ccna/5_shot/t07/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1506_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1439_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1505_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1507_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1458_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1340_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1508_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1419_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1359_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1505_shuffled_0.pkl\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T06:54:49.579359Z",
     "start_time": "2025-03-19T06:54:25.829522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# CCNP\n",
    "batch_process_pkl(\n",
    "    input_dir=\"./exam/350-701-ccnp/0_shot/t00/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    llm_answer_column=\"LLM_Answer\",\n",
    "    temperature=0.0,\n",
    "    exam=\"CCNP-350-701\",\n",
    "    prompt_engineering=\"0_shot\"\n",
    ")\n",
    "\n",
    "batch_process_pkl(\n",
    "    input_dir=\"./exam/350-701-ccnp/0_shot/t07/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    llm_answer_column=\"LLM_Answer\",\n",
    "    temperature=0.7,\n",
    "    exam=\"CCNP-350-701\",\n",
    "    prompt_engineering=\"0_shot\"\n",
    ")\n",
    "\n",
    "batch_process_pkl(\n",
    "    input_dir=\"./exam/350-701-ccnp/5_shot/t00/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    llm_answer_column=\"LLM_Answer\",\n",
    "    temperature=0.0,\n",
    "    exam=\"CCNP-350-701\",\n",
    "    prompt_engineering=\"5_shot\"\n",
    ")\n",
    "\n",
    "batch_process_pkl(\n",
    "    input_dir=\"./exam/350-701-ccnp/5_shot/t07/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    llm_answer_column=\"LLM_Answer\",\n",
    "    temperature=0.7,\n",
    "    exam=\"CCNP-350-701\",\n",
    "    prompt_engineering=\"5_shot\"\n",
    ")\n"
   ],
   "id": "8e0084c662bf58e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 .pkl files in ./exam/350-701-ccnp/0_shot/t00/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1518_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1519_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0109_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0133_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250205_2330_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0033_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1518_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1519_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1518_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0002_shuffled_1.pkl\n",
      "Found 10 .pkl files in ./exam/350-701-ccnp/0_shot/t07/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1457_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0911_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0739_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1457_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1456_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1457_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1456_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0848_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0825_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0802_shuffled_1.pkl\n",
      "Found 10 .pkl files in ./exam/350-701-ccnp/5_shot/t00/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1520_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0247_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0306_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0150_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1521_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1519_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0227_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0208_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1520_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1520_shuffled_2.pkl\n",
      "Found 10 .pkl files in ./exam/350-701-ccnp/5_shot/t07/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1006_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1042_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1500_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0930_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0947_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1459_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1024_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1458_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1459_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1458_shuffled_1.pkl\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T06:56:10.875350Z",
     "start_time": "2025-03-19T06:54:49.586391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MMLU\n",
    "batch_process_pkl(\n",
    "    input_dir=\"./exam/mmlu_computer_security/0_shot/t00/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    llm_answer_column=\"LLM_Answer\",\n",
    "    temperature=0.0,\n",
    "    exam=\"MMLU-Computer-Security\",\n",
    "    prompt_engineering=\"0_shot\"\n",
    ")\n",
    "\n",
    "batch_process_pkl(\n",
    "    input_dir=\"./exam/mmlu_computer_security/0_shot/t07/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    llm_answer_column=\"LLM_Answer\",\n",
    "    temperature=0.7,\n",
    "    exam=\"MMLU-Computer-Security\",\n",
    "    prompt_engineering=\"0_shot\"\n",
    ")\n",
    "\n",
    "batch_process_pkl(\n",
    "    input_dir=\"./exam/mmlu_computer_security/5_shot/t00/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    llm_answer_column=\"LLM_Answer\",\n",
    "    temperature=0.0,\n",
    "    exam=\"MMLU-Computer-Security\",\n",
    "    prompt_engineering=\"5_shot\"\n",
    ")\n",
    "\n",
    "batch_process_pkl(\n",
    "    input_dir=\"./exam/mmlu_computer_security/5_shot/t07/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    llm_answer_column=\"LLM_Answer\",\n",
    "    temperature=0.7,\n",
    "    exam=\"MMLU-Computer-Security\",\n",
    "    prompt_engineering=\"5_shot\"\n",
    ")\n"
   ],
   "id": "2c34745206a6ff93",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 .pkl files in ./exam/mmlu_computer_security/0_shot/t00/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1506_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1450_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250207_0042_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250207_0249_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250207_0203_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1459_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250207_0128_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250207_0007_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1444_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1436_shuffled_0.pkl\n",
      "Found 10 .pkl files in ./exam/mmlu_computer_security/0_shot/t07/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0207_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0310_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0342_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1428_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0239_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1440_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1447_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1434_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0133_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1422_shuffled_0.pkl\n",
      "Found 10 .pkl files in ./exam/mmlu_computer_security/5_shot/t00/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1506_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1507_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1506_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1507_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1507_shuffled_2.pkl\n",
      "Found 10 .pkl files in ./exam/mmlu_computer_security/5_shot/t07/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0359_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1448_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1447_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0443_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1449_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1448_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0458_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1448_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0413_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0428_shuffled_2.pkl\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T06:56:19.704192Z",
     "start_time": "2025-03-19T06:56:10.912232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MMLU\n",
    "batch_process_pkl(\n",
    "    input_dir=\"./exam/mmlu_pro/0_shot/t00/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    llm_answer_column=\"LLM_Answer\",\n",
    "    temperature=0.0,\n",
    "    exam=\"MMLU-PRO-Computer-Security\",\n",
    "    prompt_engineering=\"0_shot\"\n",
    ")\n",
    "\n",
    "# batch_process_pkl(\n",
    "#     input_dir=\"./exam/mmlu_pro/0_shot/t07/\",\n",
    "#     output_dir=\"./processed_results/\",\n",
    "#     llm_answer_column=\"LLM_Answer\",\n",
    "#     temperature=0.7,\n",
    "#     exam=\"MMLU-PRO-Computer-Security\",\n",
    "#     prompt_engineering=\"0_shot\"\n",
    "# )\n",
    "\n",
    "batch_process_pkl(\n",
    "    input_dir=\"./exam/mmlu_pro/1_shot_cot/t00/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    llm_answer_column=\"LLM_Answer\",\n",
    "    temperature=0.0,\n",
    "    exam=\"MMLU-PRO-Computer-Security\",\n",
    "    prompt_engineering=\"1_shot_cot\"\n",
    ")\n",
    "\n",
    "# batch_process_pkl(\n",
    "#     input_dir=\"./exam/mmlu_pro/1_shot_cot/t07/\",\n",
    "#     output_dir=\"./processed_results/\",\n",
    "#     llm_answer_column=\"LLM_Answer\",\n",
    "#     temperature=0.7,\n",
    "#     exam=\"MMLU-PRO-Computer-Security\",\n",
    "#     prompt_engineering=\"1_shot_cot\"\n",
    "# )\n",
    "\n",
    "batch_process_pkl(\n",
    "    input_dir=\"./exam/mmlu_pro/5_shot_cot/t00/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    llm_answer_column=\"LLM_Answer\",\n",
    "    temperature=0.0,\n",
    "    exam=\"MMLU-PRO-Computer-Security\",\n",
    "    prompt_engineering=\"5_shot_cot\"\n",
    ")\n",
    "\n",
    "# batch_process_pkl(\n",
    "#     input_dir=\"./exam/mmlu_pro/5_shot_cot/t07/\",:\n",
    "#     output_dir=\"./processed_results/\",\n",
    "#     llm_answer_column=\"LLM_Answer\",\n",
    "#     temperature=0.7,\n",
    "#     exam=\"MMLU-PRO-Computer-Security\",\n",
    "#     prompt_engineering=\"5_shot_cot\"\n",
    "# )\n"
   ],
   "id": "61abb105c3e25875",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 .pkl files in ./exam/mmlu_pro/0_shot/t00/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_0417_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_0330_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250315_2009_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250315_2008_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_0309_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_0441_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250315_2006_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_0354_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250315_2007_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250315_2006_shuffled_1.pkl\n",
      "Found 10 .pkl files in ./exam/mmlu_pro/1_shot_cot/t00/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1221_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1316_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1338_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1222_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1222_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1252_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1221_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1327_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1304_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1221_shuffled_0.pkl\n",
      "Found 10 .pkl files in ./exam/mmlu_pro/5_shot_cot/t00/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1224_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1233_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1226_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1416_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1404_shuffled_1.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1230_shuffled_3.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1228_shuffled_2.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1351_shuffled_0.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1441_shuffled_4.pkl\n",
      "Processed file saved as: ./processed_results/processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1428_shuffled_3.pkl\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T06:56:19.721684Z",
     "start_time": "2025-03-19T06:56:19.718090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def convert_pkl_to_parquet(folder_path):\n",
    "    \"\"\"\n",
    "    Converts all .pkl files in the specified folder to .parquet format.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(f\"Error: The folder '{folder_path}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    converted_files = 0\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".pkl\"):\n",
    "            pkl_path = os.path.join(folder_path, filename)\n",
    "            parquet_path = pkl_path.replace(\".pkl\", \".parquet\")\n",
    "\n",
    "            try:\n",
    "                # Load the pickle file\n",
    "                df = pd.read_pickle(pkl_path)\n",
    "\n",
    "                # Convert to Parquet\n",
    "                df.to_parquet(parquet_path, index=False)\n",
    "\n",
    "                print(f\"Converted: {filename} → {os.path.basename(parquet_path)}\")\n",
    "                converted_files += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to convert {filename}: {e}\")\n",
    "\n",
    "    if converted_files == 0:\n",
    "        print(\"No .pkl files found in the folder.\")\n",
    "    else:\n",
    "        print(f\"Conversion complete: {converted_files} file(s) converted.\")\n"
   ],
   "id": "e8c67127ba4a9ff9",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T06:56:20.129949Z",
     "start_time": "2025-03-19T06:56:19.804552Z"
    }
   },
   "cell_type": "code",
   "source": "convert_pkl_to_parquet(\"./processed_results/\")\n",
   "id": "d869ad93874c6bf2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1519_shuffled_4.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1519_shuffled_4.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250315_2008_shuffled_3.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250315_2008_shuffled_3.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1530_shuffled_1.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1530_shuffled_1.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1508_shuffled_4.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1508_shuffled_4.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0848_shuffled_3.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0848_shuffled_3.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1532_shuffled_3.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1532_shuffled_3.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1501_shuffled_1.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1501_shuffled_1.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1359_shuffled_1.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1359_shuffled_1.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1448_shuffled_1.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1448_shuffled_1.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0739_shuffled_0.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0739_shuffled_0.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1507_shuffled_3.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1507_shuffled_3.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1519_shuffled_3.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1519_shuffled_3.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1447_shuffled_4.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1447_shuffled_4.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0133_shuffled_4.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0133_shuffled_4.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1340_shuffled_0.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1340_shuffled_0.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1457_shuffled_4.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1457_shuffled_4.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1527_shuffled_3.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1527_shuffled_3.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0428_shuffled_2.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0428_shuffled_2.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0947_shuffled_1.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0947_shuffled_1.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0938_shuffled_2.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0938_shuffled_2.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1523_shuffled_0.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1523_shuffled_0.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1224_shuffled_0.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1224_shuffled_0.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1006_shuffled_2.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1006_shuffled_2.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0930_shuffled_0.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0930_shuffled_0.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1327_shuffled_3.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1327_shuffled_3.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1450_shuffled_2.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1450_shuffled_2.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_0441_shuffled_4.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_0441_shuffled_4.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1116_shuffled_0.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1116_shuffled_0.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1221_shuffled_1.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1221_shuffled_1.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1506_shuffled_2.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1506_shuffled_2.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0911_shuffled_4.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0911_shuffled_4.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1507_shuffled_3.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1507_shuffled_3.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1519_shuffled_0.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1519_shuffled_0.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1456_shuffled_1.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1456_shuffled_1.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250205_2330_shuffled_0.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250205_2330_shuffled_0.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1525_shuffled_1.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1525_shuffled_1.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1230_shuffled_3.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1230_shuffled_3.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1434_shuffled_2.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1434_shuffled_2.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_shuffled_0.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_shuffled_0.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1426_shuffled_3.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1426_shuffled_3.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1502_shuffled_2.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1502_shuffled_2.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1252_shuffled_3.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1252_shuffled_3.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1506_shuffled_4.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1506_shuffled_4.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1436_shuffled_0.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1436_shuffled_0.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1500_shuffled_4.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1500_shuffled_4.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1404_shuffled_1.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1404_shuffled_1.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_shuffled_4.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_shuffled_4.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1252_shuffled_0.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1252_shuffled_0.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1528_shuffled_4.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1528_shuffled_4.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_0330_shuffled_1.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_0330_shuffled_1.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1504_shuffled_4.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1504_shuffled_4.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1440_shuffled_3.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1440_shuffled_3.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1456_shuffled_0.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1456_shuffled_0.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0207_shuffled_1.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0207_shuffled_1.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1306_shuffled_0.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1306_shuffled_0.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0133_shuffled_0.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0133_shuffled_0.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_0354_shuffled_2.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_0354_shuffled_2.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1518_shuffled_0.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1518_shuffled_0.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_shuffled_1.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_shuffled_1.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0825_shuffled_2.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0825_shuffled_2.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1520_shuffled_3.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1520_shuffled_3.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0247_shuffled_3.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0247_shuffled_3.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1357_shuffled_2.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1357_shuffled_2.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1439_shuffled_3.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1439_shuffled_3.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1042_shuffled_4.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1042_shuffled_4.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1457_shuffled_3.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1457_shuffled_3.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0413_shuffled_1.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0413_shuffled_1.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0310_shuffled_3.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0310_shuffled_3.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1447_shuffled_0.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1447_shuffled_0.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1527_shuffled_2.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1527_shuffled_2.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1338_shuffled_4.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1338_shuffled_4.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1441_shuffled_4.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1441_shuffled_4.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_0309_shuffled_0.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_0309_shuffled_0.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0359_shuffled_0.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0359_shuffled_0.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0002_shuffled_1.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0002_shuffled_1.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1521_shuffled_4.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1521_shuffled_4.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1459_shuffled_3.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1459_shuffled_3.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1459_shuffled_3.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1459_shuffled_3.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250207_0203_shuffled_3.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250207_0203_shuffled_3.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1316_shuffled_2.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1316_shuffled_2.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1458_shuffled_4.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1458_shuffled_4.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1520_shuffled_2.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1520_shuffled_2.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1222_shuffled_4.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1222_shuffled_4.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1503_shuffled_3.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1503_shuffled_3.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0342_shuffled_4.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0342_shuffled_4.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1520_shuffled_1.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1520_shuffled_1.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0150_shuffled_0.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0150_shuffled_0.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1506_shuffled_0.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1506_shuffled_0.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1351_shuffled_0.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1351_shuffled_0.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1146_shuffled_1.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1146_shuffled_1.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1333_shuffled_1.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1333_shuffled_1.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1444_shuffled_1.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1444_shuffled_1.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250207_0042_shuffled_1.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250207_0042_shuffled_1.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1304_shuffled_1.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1304_shuffled_1.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1448_shuffled_3.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1448_shuffled_3.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1532_shuffled_4.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1532_shuffled_4.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1457_shuffled_2.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1457_shuffled_2.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1220_shuffled_2.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1220_shuffled_2.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1448_shuffled_2.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1448_shuffled_2.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1505_shuffled_0.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1505_shuffled_0.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1447_shuffled_4.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1447_shuffled_4.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1505_shuffled_1.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1505_shuffled_1.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1320_shuffled_4.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1320_shuffled_4.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0810_shuffled_0.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0810_shuffled_0.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_0417_shuffled_3.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_0417_shuffled_3.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250207_0128_shuffled_2.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250207_0128_shuffled_2.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1221_shuffled_2.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1221_shuffled_2.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1428_shuffled_3.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1428_shuffled_3.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1518_shuffled_1.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1518_shuffled_1.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1507_shuffled_2.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1507_shuffled_2.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0306_shuffled_4.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0306_shuffled_4.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1507_shuffled_4.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1507_shuffled_4.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1233_shuffled_4.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1233_shuffled_4.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0227_shuffled_2.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0227_shuffled_2.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0208_shuffled_1.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0208_shuffled_1.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1222_shuffled_3.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1222_shuffled_3.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250315_2006_shuffled_1.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250315_2006_shuffled_1.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1226_shuffled_1.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1226_shuffled_1.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1506_shuffled_1.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250211_1506_shuffled_1.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_shuffled_3.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_shuffled_3.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1024_shuffled_3.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1024_shuffled_3.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250315_2009_shuffled_4.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250315_2009_shuffled_4.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1449_shuffled_4.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1449_shuffled_4.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1501_shuffled_0.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250214_1501_shuffled_0.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1416_shuffled_2.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250316_1416_shuffled_2.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_shuffled_2.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_shuffled_2.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1530_shuffled_2.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1530_shuffled_2.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0802_shuffled_1.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0802_shuffled_1.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0443_shuffled_3.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0443_shuffled_3.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1458_shuffled_0.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1458_shuffled_0.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0109_shuffled_3.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0109_shuffled_3.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250315_2006_shuffled_0.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250315_2006_shuffled_0.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1459_shuffled_2.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1459_shuffled_2.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1221_shuffled_0.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1221_shuffled_0.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250315_2007_shuffled_2.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250315_2007_shuffled_2.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0458_shuffled_4.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0458_shuffled_4.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1518_shuffled_2.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250211_1518_shuffled_2.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1419_shuffled_2.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_1419_shuffled_2.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250207_0249_shuffled_4.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250207_0249_shuffled_4.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0033_shuffled_2.pkl → processed_100_questions_350-701-CCNP_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0033_shuffled_2.parquet\n",
      "Converted: processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1228_shuffled_2.pkl → processed_46_questions_mmlu_pro_Computer_Security_46_meta-llama_Llama-3.1-8B-Instruct_20250316_1228_shuffled_2.parquet\n",
      "Converted: processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1458_shuffled_1.pkl → processed_100_questions_350-701-CCNP_meta-llama_Llama-3.1-8B-Instruct_20250214_1458_shuffled_1.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1111_shuffled_4.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1111_shuffled_4.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0853_shuffled_1.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_0853_shuffled_1.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1529_shuffled_0.pkl → processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1529_shuffled_0.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1428_shuffled_1.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1428_shuffled_1.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250207_0007_shuffled_0.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250207_0007_shuffled_0.parquet\n",
      "Converted: processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1027_shuffled_3.pkl → processed_100_questions_201-301-CCNA_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250206_1027_shuffled_3.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1422_shuffled_0.pkl → processed_100_questions_mmlu_Computer_Security_meta-llama_Llama-3.1-8B-Instruct_20250214_1422_shuffled_0.parquet\n",
      "Converted: processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0239_shuffled_2.pkl → processed_100_questions_mmlu_Computer_Security_deepseek-ai_DeepSeek-R1-Distill-Llama-8B_20250213_0239_shuffled_2.parquet\n",
      "Conversion complete: 150 file(s) converted.\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T06:56:20.139931Z",
     "start_time": "2025-03-19T06:56:20.137243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compare_answers(answer_llm, answer_exam):\n",
    "    \"\"\"Compares the extracted correct answers with the answers in answer_exam.\n",
    "\n",
    "    Keyword arguments:\n",
    "    answerLLM -- the list of answers extracted from the LLM answer\n",
    "    answer_exam -- list of answers from the exam\n",
    "    \"\"\"\n",
    "    # Convert answer_exam_list from letters to numbers\n",
    "    answerLLM = [ord(answer) - 65 for answer in answer_llm]\n",
    "\n",
    "    # Get number of correct answers in the exam\n",
    "    num_of_correct_exam_answers = len(answer_exam)\n",
    "\n",
    "    # Convert both lists to sets for efficient comparison\n",
    "    answer_LLM_set = set(answerLLM)\n",
    "    answer_exam_set = set(answer_exam)\n",
    "\n",
    "    # Calculate the count of matching answers\n",
    "    number_of_correct_llm_answers = len(answer_LLM_set.intersection(answer_exam_set))\n",
    "\n",
    "    #Calculate the number of incorrect answers\n",
    "    number_of_incorrect_llm_answers = len(answer_LLM_set.difference(answer_exam_set))\n",
    "\n",
    "    # Check if the number of answers given by the LLM is greater than the number of correct answers\n",
    "    too_many_answ_given = False\n",
    "    if len(answer_LLM_set) > num_of_correct_exam_answers:\n",
    "        too_many_answ_given = True\n",
    "\n",
    "    # Return a dictionary with the matching count and the number of correct answers\n",
    "    return number_of_correct_llm_answers, too_many_answ_given, number_of_incorrect_llm_answers"
   ],
   "id": "9d7d1643fb43932c",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T06:56:20.185913Z",
     "start_time": "2025-03-19T06:56:20.180472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluation_sampling(fn_extractor, full_llm_answer, exam_answers):\n",
    "    \"\"\"Analyse the answer given by the LLM and compare it with the exam answers.\n",
    "\n",
    "    Keyword arguments:\n",
    "    fn_extractor -- the function that extracts the answer(s) from the llm_answer\n",
    "    llm_answer -- the answer string given by the LLM\n",
    "    exam_Answers -- the list of answers from the exam\n",
    "    \"\"\"\n",
    "    num_of_correct_answer = len(exam_answers)\n",
    "\n",
    "    llm_answers = fn_extractor(full_llm_answer)\n",
    "    if llm_answers is not None:\n",
    "        num_of_correct_llm_Answers, too_many_answ, number_of_incorrect_llm_answers = compare_answers(llm_answers, exam_answers)\n",
    "        if num_of_correct_llm_Answers == num_of_correct_answer and too_many_answ == False:\n",
    "            answered_correctly = True\n",
    "        else:\n",
    "            answered_correctly = False\n",
    "        return num_of_correct_llm_Answers, llm_answers, too_many_answ, answered_correctly, number_of_incorrect_llm_answers\n",
    "    else:\n",
    "         return -1"
   ],
   "id": "337cb534d0eadd",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T06:56:20.238314Z",
     "start_time": "2025-03-19T06:56:20.231441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluation(llm_output_dataframe):\n",
    "\n",
    "    # Compute the number of total questions for each model\n",
    "    number_of_questions = llm_output_dataframe.groupby(['Model','Prompt_Engineering', 'Temperature', 'Exam'])['QuestionIndex'].count()\n",
    "\n",
    "    #Number of fully correct answers given by the LLM\n",
    "    correctly_answered = llm_output_dataframe.groupby(['Model', 'Prompt_Engineering', 'Temperature', 'Exam'])['Answered_Correctly'].sum()\n",
    "\n",
    "    #Number of incorrect answers given by the LLM\n",
    "    incorrectly_answered = number_of_questions - correctly_answered\n",
    "\n",
    "    #Amount of correct answers in the exam\n",
    "    amount_correct_exam_answers = llm_output_dataframe.groupby(['Model', 'Prompt_Engineering', 'Temperature', 'Exam'])['NumberOfCorrectExamAnswers'].sum()\n",
    "\n",
    "    #Amount of correct answers given by the LLM even if not fully correct\n",
    "    amount_correct_llm_answers = llm_output_dataframe.groupby(['Model', 'Prompt_Engineering', 'Temperature', 'Exam'])['NumberOfCorrectLLMAnswers'].sum()\n",
    "\n",
    "    # Calculate Partial Credits\n",
    "    llm_output_dataframe['Partial_Credit'] = llm_output_dataframe.apply(\n",
    "        lambda row: max(0, row['NumberOfCorrectLLMAnswers'] / row['NumberOfCorrectExamAnswers'] -\n",
    "                        (row['NumberOfIncorrectLLMAnswers'] /row['NumberOfCorrectExamAnswers'])), axis=1)\n",
    "\n",
    "    # Aggregate Partial Credit for each model\n",
    "    partial_credit_sum = llm_output_dataframe.groupby(['Model', 'Prompt_Engineering', 'Temperature', 'Exam'])['Partial_Credit'].sum()\n",
    "\n",
    "    #Calculation of Accuracy and Recall and f1 score\n",
    "    accuracy = correctly_answered / number_of_questions\n",
    "    accuracy_partial = partial_credit_sum / number_of_questions\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Number of Questions': number_of_questions,\n",
    "        'Correctly Answered': correctly_answered,\n",
    "        'Incorrectly Answered': incorrectly_answered,\n",
    "        'Accuracy': accuracy,\n",
    "        'Accuracy Partial': accuracy_partial,\n",
    "        'Total Partial Credit': partial_credit_sum\n",
    "    })\n",
    "\n",
    "    results_df = results_df.reset_index()\n",
    "\n",
    "    return results_df"
   ],
   "id": "a85e80c9501754c6",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T06:56:20.292245Z",
     "start_time": "2025-03-19T06:56:20.287355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_model_statistics_their(df):\n",
    "    \"\"\"\n",
    "    Calculates statistics for each model in the DataFrame.\n",
    "\n",
    "    Args:\n",
    "    df (DataFrame): Input DataFrame containing evaluation metrics for different models.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: New DataFrame containing calculated statistics for each model.\n",
    "    \"\"\"\n",
    "    model_stats = []\n",
    "    for model, group_df in df.groupby(['Model']):\n",
    "        model_stat = {\n",
    "            'Model': model,\n",
    "            'Accuracy Mean': group_df['Accuracy'].mean(),\n",
    "            'Accuracy Max': group_df['Accuracy'].max(),\n",
    "            'Accuracy Min': group_df['Accuracy'].min(),\n",
    "            'Accuracy STD': group_df['Accuracy'].std(),\n",
    "            'Accuracy Partial Mean': group_df['Accuracy Partial'].mean(),\n",
    "            'Accuracy Partial Max': group_df['Accuracy Partial'].max(),\n",
    "            'Accuracy Partial Min': group_df['Accuracy Partial'].min(),\n",
    "            'Accuracy Partial STD': group_df['Accuracy Partial'].std()\n",
    "        }\n",
    "        model_stats.append(model_stat)\n",
    "\n",
    "    return pd.DataFrame(model_stats)"
   ],
   "id": "9f3e753a04fdd0b7",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T06:56:20.340038Z",
     "start_time": "2025-03-19T06:56:20.336265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_model_statistics(df):\n",
    "    \"\"\"\n",
    "    Calculates statistics for each model in the DataFrame.\n",
    "\n",
    "    Args:\n",
    "    df (DataFrame): Input DataFrame containing evaluation metrics for different models.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: New DataFrame containing calculated statistics for each model, prompt engineering, and temperature.\n",
    "    \"\"\"\n",
    "    stats_df = df.groupby(['Model', 'Prompt_Engineering', 'Temperature', 'Exam']).agg(\n",
    "        Accuracy_Mean=('Accuracy', 'mean'),\n",
    "        Accuracy_Max=('Accuracy', 'max'),\n",
    "        Accuracy_Min=('Accuracy', 'min'),\n",
    "        Accuracy_STD=('Accuracy', 'std'),\n",
    "        Accuracy_Partial_Mean=('Accuracy Partial', 'mean'),\n",
    "        Accuracy_Partial_Max=('Accuracy Partial', 'max'),\n",
    "        Accuracy_Partial_Min=('Accuracy Partial', 'min'),\n",
    "        Accuracy_Partial_STD=('Accuracy Partial', 'std')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Replace NaN STD values with 0 (for groups with only one value)\n",
    "    stats_df.fillna(0, inplace=True)\n",
    "\n",
    "    return stats_df\n"
   ],
   "id": "754f0deaffefddb4",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T06:56:20.400581Z",
     "start_time": "2025-03-19T06:56:20.392496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def produce_statistics_from_batch(input_dir = \"./processed_results/\"):\n",
    "    # Get all .pkl files in the input directory\n",
    "    pkl_files = glob.glob(os.path.join(input_dir, \"*.pkl\"))\n",
    "\n",
    "    if not pkl_files:\n",
    "        print(f\"No .pkl files found in {input_dir}.\")\n",
    "        # return\n",
    "\n",
    "    print(f\"Found {len(pkl_files)} .pkl files in {input_dir}. Processing...\")\n",
    "\n",
    "    #Create a dataframe with the size of NUM_OF_SHUFFLES which contains the dataframe llm_exam_result\n",
    "    shuffled_evaluation_df = pd.DataFrame(columns=['Number of Questions', 'Correctly Answered', 'Incorrectly Answered', 'Accuracy', 'Accuracy Partial'])\n",
    "\n",
    "    # pickle_path = \"./processed_results/processed_100_questions_201-301-CCNA_meta-llama_Llama-3.1-8B-Instruct_20250211_1523_shuffled_0.pkl\"\n",
    "    # pickles = [pickle_path,]\n",
    "\n",
    "    for pickle in pkl_files:\n",
    "        llm_exam_result = pd.DataFrame(columns = [\n",
    "            \"Model\",\n",
    "            \"Prompt_Engineering\",\n",
    "            \"Temperature\",\n",
    "            \"Exam\",\n",
    "            \"QuestionIndex\",\n",
    "            \"SamplingIndex\",\n",
    "            # \"Improved_Extracted_Answer_Column\",\n",
    "            # \"Their_Extracted_Answer_Column\",\n",
    "            # \"Differ\",\n",
    "            \"NumberOfChoices\",\n",
    "            \"NumberOfCorrectLLMAnswers\",\n",
    "            \"NumberOfIncorrectLLMAnswers\",\n",
    "            \"NumberOfCorrectExamAnswers\",\n",
    "            \"Ratio\",\n",
    "            \"LLM_Answer\",\n",
    "            \"Exam_Answers\",\n",
    "            \"Answered_Correctly\",\n",
    "            \"Too_Many_answers\"\n",
    "        ])\n",
    "        result_from_exam = pd.read_pickle(pickle)\n",
    "        for index_question, row in result_from_exam.iterrows():\n",
    "            num_of_correct_answer = len(row[\"Exam_Answers\"])\n",
    "            # num_of_choices = row[\"NumberOfChoices\"] # TODO: Do not need. Remove\n",
    "            # extracted_answer = row[\"Improved_Extracted_Answer\"]\n",
    "\n",
    "            num_of_correct_llm_answer, answerLLm, too_many_answers, answered_correctly, number_of_incorrect_llm_answers = evaluation_sampling(improved_extract_answer, row[\"LLM_Answer\"],row[\"Exam_Answers\"])\n",
    "\n",
    "            new_row = pd.DataFrame({\n",
    "                \"Model\": [row[\"Model\"]], # M\n",
    "                \"Prompt_Engineering\": [row[\"Prompt_Engineering\"]],\n",
    "                \"Temperature\": [row[\"Temperature\"]],\n",
    "                \"Exam\": [row[\"Exam\"]],\n",
    "                \"QuestionIndex\": [row[\"QuestionIndex\"]], # M\n",
    "                \"SamplingIndex\": [row[\"SamplingIndex\"]],\n",
    "                # \"Improved_Extracted_Answer\" : row[\"Improved_Extracted_Answer\"],\n",
    "                # \"Their_Extracted_Answer\": row[\"Their_Extracted_Answer\"],\n",
    "                # \"Differ\": row[\"Differ],\n",
    "                \"NumberOfChoices\": row[\"NumberOfChoices\"],\n",
    "                \"NumberOfIncorrectLLMAnswers\": number_of_incorrect_llm_answers, # M\n",
    "                \"NumberOfCorrectLLMAnswers\": [num_of_correct_llm_answer], # M\n",
    "                \"NumberOfCorrectExamAnswers\": [num_of_correct_answer], # M\n",
    "                \"Ratio\": [num_of_correct_llm_answer/num_of_correct_answer],\n",
    "                \"LLM_Answer\": [row[\"LLM_Answer\"]],\n",
    "                \"Exam_Answers\": [row[\"Exam_Answers\"]],\n",
    "                \"Answered_Correctly\" : [answered_correctly], # M\n",
    "                \"Too_Many_answers\": [too_many_answers]})\n",
    "\n",
    "            if llm_exam_result.empty:\n",
    "                llm_exam_result = new_row  # Directly assign instead of concatenating\n",
    "            else:\n",
    "                llm_exam_result = pd.concat([llm_exam_result, new_row], ignore_index=True)\n",
    "\n",
    "        evaluation_df = evaluation(llm_exam_result)\n",
    "        #Concat the evaluation dataframe to the complete dataframe\n",
    "\n",
    "        if shuffled_evaluation_df.empty:\n",
    "            shuffled_evaluation_df = evaluation_df  # Directly assign instead of concatenating\n",
    "        else:\n",
    "            shuffled_evaluation_df = pd.concat([shuffled_evaluation_df, evaluation_df], ignore_index=True)\n",
    "\n",
    "\n",
    "    print(shuffled_evaluation_df)\n",
    "    model_statistics = calculate_model_statistics(shuffled_evaluation_df)\n",
    "    print(model_statistics)"
   ],
   "id": "7aaa830e62a476c2",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T06:56:28.325444Z",
     "start_time": "2025-03-19T06:56:20.436922Z"
    }
   },
   "cell_type": "code",
   "source": "produce_statistics_from_batch()",
   "id": "c61f795b561422e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 150 .pkl files in ./processed_results/. Processing...\n",
      "                                        Model Prompt_Engineering  Temperature  \\\n",
      "0            meta-llama/Llama-3.1-8B-Instruct             0_shot          0.0   \n",
      "1            meta-llama/Llama-3.1-8B-Instruct             0_shot          0.0   \n",
      "2            meta-llama/Llama-3.1-8B-Instruct             5_shot          0.0   \n",
      "3            meta-llama/Llama-3.1-8B-Instruct             5_shot          0.7   \n",
      "4    deepseek-ai/DeepSeek-R1-Distill-Llama-8B             0_shot          0.7   \n",
      "..                                        ...                ...          ...   \n",
      "145          meta-llama/Llama-3.1-8B-Instruct             0_shot          0.7   \n",
      "146  deepseek-ai/DeepSeek-R1-Distill-Llama-8B             0_shot          0.0   \n",
      "147  deepseek-ai/DeepSeek-R1-Distill-Llama-8B             0_shot          0.0   \n",
      "148          meta-llama/Llama-3.1-8B-Instruct             0_shot          0.7   \n",
      "149  deepseek-ai/DeepSeek-R1-Distill-Llama-8B             0_shot          0.7   \n",
      "\n",
      "                           Exam  Number of Questions  Correctly Answered  \\\n",
      "0                  CCNP-350-701                  100                  59   \n",
      "1    MMLU-PRO-Computer-Security                   46                  20   \n",
      "2                  CCNA-201-301                  100                  55   \n",
      "3                  CCNA-201-301                  100                  58   \n",
      "4                  CCNP-350-701                  100                  52   \n",
      "..                          ...                  ...                 ...   \n",
      "145      MMLU-Computer-Security                  100                  75   \n",
      "146      MMLU-Computer-Security                  100                  77   \n",
      "147                CCNA-201-301                  100                  55   \n",
      "148      MMLU-Computer-Security                  100                  76   \n",
      "149      MMLU-Computer-Security                  100                  70   \n",
      "\n",
      "     Incorrectly Answered  Accuracy  Accuracy Partial  Total Partial Credit  \n",
      "0                      41  0.590000          0.605000                  60.5  \n",
      "1                      26  0.434783          0.434783                  20.0  \n",
      "2                      45  0.550000          0.550000                  55.0  \n",
      "3                      42  0.580000          0.580000                  58.0  \n",
      "4                      48  0.520000          0.540000                  54.0  \n",
      "..                    ...       ...               ...                   ...  \n",
      "145                    25  0.750000          0.750000                  75.0  \n",
      "146                    23  0.770000          0.770000                  77.0  \n",
      "147                    45  0.550000          0.560000                  56.0  \n",
      "148                    24  0.760000          0.760000                  76.0  \n",
      "149                    30  0.700000          0.700000                  70.0  \n",
      "\n",
      "[150 rows x 10 columns]\n",
      "                                       Model Prompt_Engineering  Temperature  \\\n",
      "0   deepseek-ai/DeepSeek-R1-Distill-Llama-8B             0_shot          0.0   \n",
      "1   deepseek-ai/DeepSeek-R1-Distill-Llama-8B             0_shot          0.0   \n",
      "2   deepseek-ai/DeepSeek-R1-Distill-Llama-8B             0_shot          0.0   \n",
      "3   deepseek-ai/DeepSeek-R1-Distill-Llama-8B             0_shot          0.0   \n",
      "4   deepseek-ai/DeepSeek-R1-Distill-Llama-8B             0_shot          0.7   \n",
      "5   deepseek-ai/DeepSeek-R1-Distill-Llama-8B             0_shot          0.7   \n",
      "6   deepseek-ai/DeepSeek-R1-Distill-Llama-8B             0_shot          0.7   \n",
      "7   deepseek-ai/DeepSeek-R1-Distill-Llama-8B         1_shot_cot          0.0   \n",
      "8   deepseek-ai/DeepSeek-R1-Distill-Llama-8B             5_shot          0.0   \n",
      "9   deepseek-ai/DeepSeek-R1-Distill-Llama-8B             5_shot          0.0   \n",
      "10  deepseek-ai/DeepSeek-R1-Distill-Llama-8B             5_shot          0.0   \n",
      "11  deepseek-ai/DeepSeek-R1-Distill-Llama-8B             5_shot          0.7   \n",
      "12  deepseek-ai/DeepSeek-R1-Distill-Llama-8B             5_shot          0.7   \n",
      "13  deepseek-ai/DeepSeek-R1-Distill-Llama-8B             5_shot          0.7   \n",
      "14  deepseek-ai/DeepSeek-R1-Distill-Llama-8B         5_shot_cot          0.0   \n",
      "15          meta-llama/Llama-3.1-8B-Instruct             0_shot          0.0   \n",
      "16          meta-llama/Llama-3.1-8B-Instruct             0_shot          0.0   \n",
      "17          meta-llama/Llama-3.1-8B-Instruct             0_shot          0.0   \n",
      "18          meta-llama/Llama-3.1-8B-Instruct             0_shot          0.0   \n",
      "19          meta-llama/Llama-3.1-8B-Instruct             0_shot          0.7   \n",
      "20          meta-llama/Llama-3.1-8B-Instruct             0_shot          0.7   \n",
      "21          meta-llama/Llama-3.1-8B-Instruct             0_shot          0.7   \n",
      "22          meta-llama/Llama-3.1-8B-Instruct         1_shot_cot          0.0   \n",
      "23          meta-llama/Llama-3.1-8B-Instruct             5_shot          0.0   \n",
      "24          meta-llama/Llama-3.1-8B-Instruct             5_shot          0.0   \n",
      "25          meta-llama/Llama-3.1-8B-Instruct             5_shot          0.0   \n",
      "26          meta-llama/Llama-3.1-8B-Instruct             5_shot          0.7   \n",
      "27          meta-llama/Llama-3.1-8B-Instruct             5_shot          0.7   \n",
      "28          meta-llama/Llama-3.1-8B-Instruct             5_shot          0.7   \n",
      "29          meta-llama/Llama-3.1-8B-Instruct         5_shot_cot          0.0   \n",
      "\n",
      "                          Exam  Accuracy_Mean  Accuracy_Max  Accuracy_Min  \\\n",
      "0                 CCNA-201-301       0.556000      0.590000      0.520000   \n",
      "1                 CCNP-350-701       0.544000      0.570000      0.520000   \n",
      "2       MMLU-Computer-Security       0.714000      0.770000      0.690000   \n",
      "3   MMLU-PRO-Computer-Security       0.460870      0.500000      0.413043   \n",
      "4                 CCNA-201-301       0.564000      0.590000      0.520000   \n",
      "5                 CCNP-350-701       0.538000      0.560000      0.520000   \n",
      "6       MMLU-Computer-Security       0.726000      0.760000      0.700000   \n",
      "7   MMLU-PRO-Computer-Security       0.460870      0.478261      0.434783   \n",
      "8                 CCNA-201-301       0.510000      0.550000      0.490000   \n",
      "9                 CCNP-350-701       0.426000      0.480000      0.400000   \n",
      "10      MMLU-Computer-Security       0.724000      0.740000      0.710000   \n",
      "11                CCNA-201-301       0.516000      0.560000      0.460000   \n",
      "12                CCNP-350-701       0.430000      0.450000      0.410000   \n",
      "13      MMLU-Computer-Security       0.710000      0.730000      0.690000   \n",
      "14  MMLU-PRO-Computer-Security       0.456522      0.500000      0.413043   \n",
      "15                CCNA-201-301       0.576000      0.610000      0.550000   \n",
      "16                CCNP-350-701       0.608000      0.670000      0.560000   \n",
      "17      MMLU-Computer-Security       0.784000      0.810000      0.760000   \n",
      "18  MMLU-PRO-Computer-Security       0.452174      0.521739      0.391304   \n",
      "19                CCNA-201-301       0.570000      0.600000      0.510000   \n",
      "20                CCNP-350-701       0.600000      0.660000      0.540000   \n",
      "21      MMLU-Computer-Security       0.748000      0.760000      0.720000   \n",
      "22  MMLU-PRO-Computer-Security       0.478261      0.543478      0.413043   \n",
      "23                CCNA-201-301       0.564000      0.580000      0.550000   \n",
      "24                CCNP-350-701       0.618000      0.660000      0.590000   \n",
      "25      MMLU-Computer-Security       0.782000      0.810000      0.770000   \n",
      "26                CCNA-201-301       0.568000      0.580000      0.550000   \n",
      "27                CCNP-350-701       0.588000      0.620000      0.570000   \n",
      "28      MMLU-Computer-Security       0.766000      0.790000      0.730000   \n",
      "29  MMLU-PRO-Computer-Security       0.430435      0.543478      0.369565   \n",
      "\n",
      "    Accuracy_STD  Accuracy_Partial_Mean  Accuracy_Partial_Max  \\\n",
      "0       0.028810               0.565000              0.600000   \n",
      "1       0.018166               0.549000              0.575000   \n",
      "2       0.033615               0.714000              0.770000   \n",
      "3       0.038888               0.460870              0.500000   \n",
      "4       0.029665               0.576000              0.605000   \n",
      "5       0.016432               0.552000              0.570000   \n",
      "6       0.021909               0.726000              0.760000   \n",
      "7       0.023814               0.460870              0.478261   \n",
      "8       0.025495               0.514000              0.550000   \n",
      "9       0.032094               0.436000              0.485000   \n",
      "10      0.015166               0.724000              0.740000   \n",
      "11      0.038471               0.525000              0.565000   \n",
      "12      0.015811               0.439000              0.455000   \n",
      "13      0.018708               0.710000              0.730000   \n",
      "14      0.034373               0.456522              0.500000   \n",
      "15      0.021909               0.576000              0.610000   \n",
      "16      0.049193               0.618000              0.675000   \n",
      "17      0.018166               0.784000              0.810000   \n",
      "18      0.056270               0.452174              0.521739   \n",
      "19      0.035355               0.571000              0.605000   \n",
      "20      0.043012               0.608000              0.665000   \n",
      "21      0.016432               0.748000              0.760000   \n",
      "22      0.055424               0.478261              0.543478   \n",
      "23      0.011402               0.564000              0.580000   \n",
      "24      0.034205               0.618000              0.660000   \n",
      "25      0.017889               0.782000              0.810000   \n",
      "26      0.010954               0.568000              0.580000   \n",
      "27      0.019235               0.590000              0.625000   \n",
      "28      0.023022               0.766000              0.790000   \n",
      "29      0.084755               0.430435              0.543478   \n",
      "\n",
      "    Accuracy_Partial_Min  Accuracy_Partial_STD  \n",
      "0               0.530000              0.027839  \n",
      "1               0.530000              0.016733  \n",
      "2               0.690000              0.033615  \n",
      "3               0.413043              0.038888  \n",
      "4               0.530000              0.029665  \n",
      "5               0.540000              0.012550  \n",
      "6               0.700000              0.021909  \n",
      "7               0.434783              0.023814  \n",
      "8               0.490000              0.023022  \n",
      "9               0.420000              0.028151  \n",
      "10              0.710000              0.015166  \n",
      "11              0.480000              0.033541  \n",
      "12              0.415000              0.018166  \n",
      "13              0.690000              0.018708  \n",
      "14              0.413043              0.034373  \n",
      "15              0.550000              0.021909  \n",
      "16              0.570000              0.047249  \n",
      "17              0.760000              0.018166  \n",
      "18              0.391304              0.056270  \n",
      "19              0.510000              0.036469  \n",
      "20              0.550000              0.042071  \n",
      "21              0.720000              0.016432  \n",
      "22              0.413043              0.055424  \n",
      "23              0.550000              0.011402  \n",
      "24              0.590000              0.034205  \n",
      "25              0.770000              0.017889  \n",
      "26              0.550000              0.010954  \n",
      "27              0.570000              0.020917  \n",
      "28              0.730000              0.023022  \n",
      "29              0.369565              0.084755  \n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T06:56:28.336674Z",
     "start_time": "2025-03-19T06:56:28.334470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "longer_test_case = \"\"\"Okay, so I have this question about computer security, and I need to figure out the correct answer. Let me read it again carefully.\n",
    "\n",
    "The question is: \"Encryption and decryption provide secrecy, or confidentiality, but not...\" Then it gives options from A to H, and I need to choose which one they don't provide.\n",
    "\n",
    "Hmm, I remember that encryption and decryption are methods used to protect data. They convert data into a code to prevent unauthorized access. So, what do they provide? I think they provide confidentiality, which means only authorized people can access the data. So, the question is asking which of the options they don't provide.\n",
    "\n",
    "Looking at the options:\n",
    "\n",
    "A. Privacy\n",
    "B. Integrity\n",
    "C. Security\n",
    "D. Reliability\n",
    "E. Confidentiality\n",
    "F. All of the above\n",
    "G. Authentication\n",
    "H. Anonymity\n",
    "\n",
    "Wait, the question says they provide confidentiality, so E is something they do provide. So the answer can't be E. The question is asking what they do NOT provide.\n",
    "\n",
    "Now, let's think about each option.\n",
    "\n",
    "Privacy is about ensuring that personal data is not disclosed. Encryption can help with privacy, but I'm not sure if it's the only thing. Maybe, but I think the question is more about what encryption doesn't provide.\n",
    "\n",
    "Integrity is about ensuring data hasn't been altered. Encryption doesn't directly provide integrity. Integrity is more about data verification, often done with hashing or digital signatures, not just encryption.\n",
    "\n",
    "Security is a broad term that includes various aspects like confidentiality, integrity, and availability. So encryption contributes to security but doesn't cover all aspects.\n",
    "\n",
    "Reliability is about ensuring systems work as expected. Encryption doesn't directly ensure reliability, though it does protect data.\n",
    "\n",
    "Confidentiality is provided, so E is out.\n",
    "\n",
    "Authentication is about verifying identity, which encryption can help with, like using certificates or passwords.\n",
    "\n",
    "Anonymity is about not being identifiable. Encryption can help with anonymous communication, but I'm not sure if it's the primary function. Maybe it's not something encryption inherently provides.\n",
    "\n",
    "Wait, the question is about what encryption and decryption do NOT provide. So the options are A to H, and the correct answer is the one they don't provide.\n",
    "\n",
    "So, let's go through each:\n",
    "\n",
    "A. Privacy: Encryption can contribute to privacy, but maybe not directly. Or perhaps it's not the primary function.\n",
    "\n",
    "B. Integrity: No, encryption doesn't provide integrity. Integrity is about data correctness, which is handled by other methods.\n",
    "\n",
    "C. Security: Encryption is part of security, but it's not the whole thing.\n",
    "\n",
    "D. Reliability: No, encryption doesn't ensure systems are reliable.\n",
    "\n",
    "E. Confidentiality: They do provide this, so it's not the answer.\n",
    "\n",
    "F. All of the above: No, because they don't provide all, so F is incorrect.\n",
    "\n",
    "G. Authentication: They can help with authentication, so not the answer.\n",
    "\n",
    "H. Anonymity: Maybe encryption can help with anonymity, but I'm not sure if it's a primary function. Or perhaps it's not something encryption alone provides.\n",
    "\n",
    "Wait, the question is about what they do NOT provide. So the correct answer is the one they don't provide.\n",
    "\n",
    "I think the key here is that encryption and decryption primarily provide confidentiality, not the other aspects. So the options they don't provide would be the ones not related to confidentiality.\n",
    "\n",
    "Looking at the options, the question is which one they do NOT provide. So the answer is the one that's not a function of encryption.\n",
    "\n",
    "Integrity is about data integrity, which is separate. So B is not provided by encryption.\n",
    "\n",
    "Wait, but the question is about what they do NOT provide. So the correct answer is B. Integrity.\n",
    "\n",
    "Wait, but I'm a bit confused. Let me think again. Encryption ensures that only authorized people can read the data, so it's about confidentiality. It doesn't ensure that the data hasn't been altered (integrity) or that the system is reliable. So the answer is B. Integrity.\n",
    "</think>\n",
    "\n",
    "The question asks which aspect encryption and decryption do not provide. Encryption focuses on confidentiality, not integrity. Therefore, the correct answer is:\n",
    "\n",
    "B. Integrity\n",
    "\n",
    "the answer is B\"\"\""
   ],
   "id": "84bbc1e02f14b500",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T06:56:28.388454Z",
     "start_time": "2025-03-19T06:56:28.384881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "longer_test_case_2 = \"\"\"<think>Okay, so I have this question about computer security, and I need to figure out the correct answer. Let me read it again carefully.\n",
    "\n",
    "The question is: \"Encryption and decryption provide secrecy, or confidentiality, but not...\" Then it gives options from A to H, and I need to choose which one they don't provide.\n",
    "\n",
    "Hmm, I remember that encryption and decryption are methods used to protect data. They convert data into a code to prevent unauthorized access. So, what do they provide? I think they provide confidentiality, which means only authorized people can access the data. So, the question is asking which of the options they don't provide.\n",
    "\n",
    "Looking at the options:\n",
    "\n",
    "A. Privacy\n",
    "B. Integrity\n",
    "C. Security\n",
    "D. Reliability\n",
    "E. Confidentiality\n",
    "F. All of the above\n",
    "G. Authentication\n",
    "H. Anonymity\n",
    "\n",
    "Wait, the question says they provide confidentiality, so E is something they do provide. So the answer can't be E. The question is asking what they do NOT provide.\n",
    "\n",
    "Now, let's think about each option.\n",
    "\n",
    "Privacy is about ensuring that personal data is not disclosed. Encryption can help with privacy, but I'm not sure if it's the only thing. Maybe, but I think the question is more about what encryption doesn't provide.\n",
    "\n",
    "Integrity is about ensuring data hasn't been altered. Encryption doesn't directly provide integrity. Integrity is more about data verification, often done with hashing or digital signatures, not just encryption.\n",
    "\n",
    "Security is a broad term that includes various aspects like confidentiality, integrity, and availability. So encryption contributes to security but doesn't cover all aspects.\n",
    "\n",
    "Reliability is about ensuring systems work as expected. Encryption doesn't directly ensure reliability, though it does protect data.\n",
    "\n",
    "Confidentiality is provided, so E is out.\n",
    "\n",
    "Authentication is about verifying identity, which encryption can help with, like using certificates or passwords.\n",
    "\n",
    "Anonymity is about not being identifiable. Encryption can help with anonymous communication, but I'm not sure if it's the primary function. Maybe it's not something encryption inherently provides.\n",
    "\n",
    "Wait, the question is about what encryption and decryption do NOT provide. So the options are A to H, and the correct answer is the one they don't provide.\n",
    "\n",
    "So, let's go through each:\n",
    "\n",
    "A. Privacy: Encryption can contribute to privacy, but maybe not directly. Or perhaps it's not the primary function.\n",
    "\n",
    "B. Integrity: No, encryption doesn't provide integrity. Integrity is about data correctness, which is handled by other methods.\n",
    "\n",
    "C. Security: Encryption is part of security, but it's not the whole thing.\n",
    "\n",
    "D. Reliability: No, encryption doesn't ensure systems are reliable.\n",
    "\n",
    "E. Confidentiality: They do provide this, so it's not the answer.\n",
    "\n",
    "F. All of the above: No, because they don't provide all, so F is incorrect.\n",
    "\n",
    "G. Authentication: They can help with authentication, so not the answer.\n",
    "\n",
    "H. Anonymity: Maybe encryption can help with anonymity, but I'm not sure if it's a primary function. Or perhaps it's not something encryption alone provides.\n",
    "\n",
    "Wait, the question is about what they do NOT provide. So the correct answer is the one they don't provide.\n",
    "\n",
    "I think the key here is that encryption and decryption primarily provide confidentiality, not the other aspects. So the options they don't provide would be the ones not related to confidentiality.\n",
    "\n",
    "Looking at the options, the question is which one they do NOT provide. So the answer is the one that's not a function of encryption.\n",
    "\n",
    "Integrity is about data integrity, which is separate. So B is not provided by encryption.\n",
    "\n",
    "Wait, but the question is about what they do NOT provide. So the correct answer is B. Integrity.\n",
    "\n",
    "Wait, but I'm a bit confused. Let me think again. Encryption ensures that only authorized people can read the data, so it's about confidentiality. It doesn't ensure that the data hasn't been altered (integrity) or that the system is reliable. So the answer is B. Integrity.\n",
    "</think>\n",
    "\n",
    "The question asks which aspect encryption and decryption do not provide. Encryption focuses on confidentiality, not integrity. Therefore, the correct answer is:\n",
    "\n",
    "B. Integrity\n",
    "\n",
    "the answer is B\"\"\"\n"
   ],
   "id": "e9ba6cdb366ee05e",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T06:57:10.835435Z",
     "start_time": "2025-03-19T06:57:10.832673Z"
    }
   },
   "cell_type": "code",
   "source": "improved_extract_answer(longer_test_case)\n",
   "id": "467c2efecf6f58b7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T06:56:28.498334Z",
     "start_time": "2025-03-19T06:56:28.492166Z"
    }
   },
   "cell_type": "code",
   "source": "their_extract_answer(longer_test_case)\n",
   "id": "5db0efb971225ca9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T06:56:28.553880Z",
     "start_time": "2025-03-19T06:56:28.548654Z"
    }
   },
   "cell_type": "code",
   "source": "improved_extract_answer_PREV(longer_test_case)\n",
   "id": "5c84b1a807a5785a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
