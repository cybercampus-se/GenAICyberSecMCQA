{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "import pandas as pd\n",
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain import PromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.embeddings import LlamaCppEmbeddings\n",
    "from langchain_community.embeddings.sentence_transformer import (SentenceTransformerEmbeddings)\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"You are an assistant tasked with summarizing text. \n",
    "The following text is containing information of the page with heading, important points, the complete text and a picture description if any. \n",
    "{content_of_pdf}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOK_PDF = '/home/iai/sb7059/git/llm_test/data/Book/industrial-cybersecurity-efficiently-monitor-the-cybersecurity-posture-of-your-ics-environment_compress.pdf'\n",
    "PATH = '/home/iai/sb7059/git/llm_test/data/Book/Images'\n",
    "#BOOK_PDF = '/home/iai/sb7059/git/llm_test/data/Book/fdgth-06-1321485.pdf'\n",
    "#BOOK_PDF = '/home/iai/sb7059/git/llm_test/data/Book/smeggitt.pdf'\n",
    "WORKSPACE_DIC = \"/hkfs/work/workspace_haic/scratch/sb7059-llm_models_jeremy\"\n",
    "\n",
    "MODEL_PATH = { #\"Mixtral-8x-7b\": WORKSPACE_DIC + \"/Mixtral/mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf\",\n",
    "               #\"Phi-2\": WORKSPACE_DIC + \"/Phi/Phi2/phi-2.Q4_K_M.gguf\",\n",
    "               \"Llama2-70b\": WORKSPACE_DIC + \"/Llama/Llama2/llama-2-70b.Q5_K_M.gguf\",\n",
    "                \"Phi-3-medium-128k\": WORKSPACE_DIC + \"/Phi/Phi3/Phi-3-mini-4k-instruct-q4.gguf\",\n",
    "               #\"LLama-3-70b\": WORKSPACE_DIC + \"/Llama/LLama3/Meta-Llama-3-70B-Instruct-v2.Q4_K_M.gguf\",\n",
    "               #\"Mixtral-8x22b\": WORKSPACE_DIC + \"/Mixtral/Mixtral-8x22b-Instruct\",\n",
    "               #\"Mixtral-8x-22b\": WORKSPACE_DIC + \"/Mixtral/Mixtral-8x22B-Instruct-v0.1.Q4_K_M-00001-of-00002.gguf\",\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tables_to_string(page):\n",
    "    \"\"\"\n",
    "    Extracts all tables from a given page and concatenates them into a single string.\n",
    "\n",
    "    Parameters:\n",
    "    - page: The page object from which to extract tables.\n",
    "\n",
    "    Returns:\n",
    "    - A string containing all tables extracted from the page.\n",
    "    \"\"\"\n",
    "    content_of_pdf = \"\"\n",
    "    tabs = page.find_tables()  # detect the tables\n",
    "    for i, tab in enumerate(tabs):  # iterate over all tables\n",
    "        df = tab.to_pandas()\n",
    "        # Add the table to a string to be used in the prompt\n",
    "        content_of_pdf += df.to_string()\n",
    "    return content_of_pdf\n",
    "\n",
    "def extract_and_save_images(page, doc, PATH):\n",
    "    \"\"\"\n",
    "    Extracts all images from a given page and saves them to a specified path.\n",
    "\n",
    "    Parameters:\n",
    "    - page: The page object from which to extract images.\n",
    "    - doc: The document object containing the page.\n",
    "    - PATH: The file path where images will be saved.\n",
    "    \"\"\"\n",
    "    for i in page.get_images(full=True):\n",
    "        xref = i[0]\n",
    "        image = fitz.Pixmap(doc, xref)\n",
    "        with open(f'{PATH}/image_{xref}.png', 'wb') as f:\n",
    "            f.write(image.tobytes())\n",
    "\n",
    "def extract_spans_from_blocks(block_dict):\n",
    "    # Initialize an empty list to store row data\n",
    "    rows = []\n",
    "    \n",
    "    # Iterate through each page and its blocks\n",
    "    for page_num, blocks in block_dict.items():\n",
    "        for block in blocks:\n",
    "            # Check if the block is of type 0 (text)\n",
    "            if block['type'] == 0:\n",
    "                for line in block['lines']:\n",
    "                    for span in line['spans']:\n",
    "                        # Extract bounding box and other span properties\n",
    "                        xmin, ymin, xmax, ymax = list(span['bbox'])\n",
    "                        font_size = span['size']\n",
    "                        text = unidecode(span['text'])\n",
    "                        span_font = span['font']\n",
    "                        is_bold = \"bold\" in span_font.lower()\n",
    "                        \n",
    "                        # Ensure the text is not just whitespace\n",
    "                        if text.replace(\" \", \"\"):\n",
    "                            rows.append((xmin, ymin, xmax, ymax, text, is_bold, span_font, font_size, page_num))\n",
    "    \n",
    "    # Create a DataFrame from the rows\n",
    "    span_df = pd.DataFrame(rows, columns=['xmin', 'ymin', 'xmax', 'ymax', 'text', 'is_bold', 'span_font', 'font_size', 'page_num'])\n",
    "    return span_df\n",
    "\n",
    "def get_title(span_df):\n",
    "    title_page = span_df[span_df['page_num'] == 1]\n",
    "    unique_font_sizes_title = title_page['font_size'].unique()\n",
    "    title = \"\"\n",
    "    for index, row in title_page.iterrows():\n",
    "        #Check if the row is bold and if the font size is the greatest font size\n",
    "        if row['font_size'] == max(unique_font_sizes_title): \n",
    "            title += row['text']\n",
    "    return title\n",
    "\n",
    "def extract_toc_as_df(pdf_path):\n",
    "    # Open the PDF\n",
    "    doc = fitz.open(pdf_path)\n",
    "    \n",
    "    # Extract the table of contents\n",
    "    toc = doc.get_toc()\n",
    "    \n",
    "    # Close the document\n",
    "    doc.close()\n",
    "    \n",
    "    # Convert TOC to DataFrame\n",
    "    toc_df = pd.DataFrame(toc, columns=['Level', 'Title', 'Page'])\n",
    "    \n",
    "    return toc_df\n",
    "\n",
    "def extract_pdf_content(pdf_path, start_page, end_page):\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    pdf_content = []\n",
    "    block_dict = {}\n",
    "    for page_number in range(start_page-1, end_page):\n",
    "        page = pdf_document[page_number]\n",
    "        file_dict = page.get_text('dict') # Get the page dictionary\n",
    "        block = file_dict['blocks'] # Get the block information\n",
    "        block_dict[page_number] = block\n",
    "\n",
    "        page_content = page.get_text()\n",
    "        pdf_content.append(page_content)\n",
    "\n",
    "        # Extract images from the page\n",
    "        extract_and_save_images(page, pdf_document, PATH)\n",
    "\n",
    "        # Extract tables from the page\n",
    "        pdf_content.append(extract_tables_to_string(page))\n",
    "\n",
    "    pdf_content = (analyse_content(extract_spans_from_blocks(block_dict),page))\n",
    "    \n",
    "    return pdf_content\n",
    "\n",
    "\n",
    "def analyse_content(span_df, page):\n",
    "    # Initialize lists to hold categorized content\n",
    "    site_header = []\n",
    "    headers = []\n",
    "    important_texts = []\n",
    "    picture_descriptions = []\n",
    "    page_content = []\n",
    "\n",
    "    # Calculate font size and font type statistics\n",
    "    font_size_counts = span_df['font_size'].value_counts()\n",
    "    unique_font_sizes = span_df['font_size'].unique()\n",
    "\n",
    "    # Define thresholds\n",
    "    site_header_threshold = page.rect.height * 0.07\n",
    "    # Iterate through each row in the DataFrame\n",
    "    for index, row in span_df.iterrows():\n",
    "        text = row['text']\n",
    "        font_size = row['font_size']\n",
    "        is_bold = row['is_bold']\n",
    "        ymin = row['ymin']\n",
    "        \n",
    "        # Site Header - typically at the top of the page\n",
    "        if ymin < site_header_threshold:\n",
    "            site_header.append(text)\n",
    "\n",
    "        # Determine if text is a header or subheader based on font size and boldness\n",
    "        elif is_bold and font_size > font_size_counts.idxmax():\n",
    "            headers.append(text)\n",
    "\n",
    "        # Bold text that is not categorized as headers or subheaders\n",
    "        elif is_bold and font_size == font_size_counts.idxmax():\n",
    "            important_texts.append(text)\n",
    "\n",
    "        # Check for figure descriptions\n",
    "        elif \"figure\" in text.lower() or \"fig.\" in text.lower() or \"image\" in text.lower():\n",
    "            picture_descriptions.append(text)\n",
    "\n",
    "        page_content.append(text)\n",
    "    \n",
    "    #Fromat the page_content to a string\n",
    "    page_content = \" \".join(page_content)\n",
    "\n",
    "        # Store results in a dictionary\n",
    "    data = {\n",
    "        \"site_title\": site_header,\n",
    "        \"headers\": headers,\n",
    "        \"important_texts\": important_texts,\n",
    "        \"picture_descriptions\": picture_descriptions,\n",
    "        \"page_content\": page_content\n",
    "    }\n",
    "\n",
    "    formatted_string = (\n",
    "    \"Site Title:\\n\"\n",
    "    f\"  - {data['site_title']}\\n\\n\"\n",
    "    \n",
    "    \"Headers:\\n\"\n",
    "    \"  - \" + \"\\n  - \".join(data['headers']) + \"\\n\\n\"\n",
    "    \n",
    "    \"Important Texts:\\n\"\n",
    "    \"  - \" + \"\\n  - \".join(data['important_texts']) + \"\\n\\n\"\n",
    "    \n",
    "    \"Picture Descriptions:\\n\"\n",
    "    \"  - \" + \"\\n  - \".join(data['picture_descriptions']) + \"\\n\\n\"\n",
    "    \n",
    "    \"Page Content:\\n\"\n",
    "    f\"  {data['page_content']}\\n\")\n",
    "\n",
    "    \n",
    "    return formatted_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = extract_pdf_content(BOOK_PDF, 22, 24)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = WORKSPACE_DIC + \"/Phi/Phi3/Phi-3-mini-4k-instruct-q4.gguf\"\n",
    "llm = LlamaCpp(\n",
    "    model_path= model_path,\n",
    "    n_gpu_layers=-1,\n",
    "    n_batch=4096,\n",
    "    n_ctx=4096,\n",
    "    temperature=1,\n",
    "    top_p=1,\n",
    "    max_tokens = 4000,\n",
    "    #callback_manager=callback_manager,\n",
    "    verbose=True,  # Verbose is required to pass to the callback manager\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site Title:\n",
      "  - []\n",
      "\n",
      "Headers:\n",
      "  - Section 1:\n",
      "\n",
      "  - ICS Cybersecurity \n",
      "  - Fundamentals\n",
      "  - 1\n",
      "  - Introduction and \n",
      "  - Recap of First \n",
      "  - Edition\n",
      "\n",
      "Important Texts:\n",
      "  - Industrial Control System\n",
      "  - ICS\n",
      "\n",
      "Picture Descriptions:\n",
      "  - \n",
      "\n",
      "Page Content:\n",
      "  Section 1:\n",
      " ICS Cybersecurity  Fundamentals In part one, we will briefly recap the first edition of the book to outline what was covered  and to point out the content that is still very relevant and that will be built upon in this  second edition. The remainder of part one will be dedicated to discussions around a  revised IDMZ architecture, resulting from many deployments, experience in the field,  practice, and feedback. Part one will conclude with a deep dive into how to design for  security, architecture that allows all the tools, techniques, and activities discussed in the  rest of the book to be implemented effectively and easily. This section comprises the following chapters: *\t  Chapter 1 ,  Introduction and Recap of the First Edition *\t  Chapter 2 ,  A Modern Look at the Industrial Control System Architecture *\t  Chapter 3, The Industrial Demilitarized Zone *\t  Chapter 4, Designing the ICS Architecture with Security in Mind 1 Introduction and  Recap of First  Edition Welcome to the second edition of  Industrial Cybersecurity . Over the next 24 chapters, we  will discuss the next logical steps after building a secure  Industrial Control System  ( ICS )  environment and defining a comprehensive set of policies, procedures, and standards,  discussed in detail in the first edition.  We are going to start off this second edition with a brief recap of topics and material  that were covered in the first edition of  Industrial Cybersecurity . This has mainly been  added to get you up to speed with the terminologies, technologies, and principles that are  expanded upon throughout the rest of this book. The remainder of the book concentrates  on security monitoring and verification of the ICS security posture and the various tools,  techniques, and activities involved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7349.21 ms\n",
      "llama_print_timings:      sample time =     311.91 ms /  1433 runs   (    0.22 ms per token,  4594.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =      98.34 ms /   520 tokens (    0.19 ms per token,  5287.94 tokens per second)\n",
      "llama_print_timings:        eval time =    8794.29 ms /  1432 runs   (    6.14 ms per token,   162.83 tokens per second)\n",
      "llama_print_timings:       total time =   11070.69 ms /  1952 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  In order for all these topics to be effectively implemented within your own organization, we will  start with a high-level overview and analysis of an Industrial Control System (ICS)  architecture that is designed from the ground up in compliance with security principles as outlined by  ISO/IEC TR15443:2018 , the ISA/ISA99 standards, NIST SP-800-82 Revision 2, and other similar guidelines. Our goal is to provide you a solid foundation upon which all  security activities can be performed more easily in your organization. The main sections of this first chapter are as follows: *\t  1. Introduction *\t   2. A Modern Look at the Industrial Control System Architecture (ICS) *\t   3. The Industrial Demilitarized Zone (IDMZ)*  â€¢   Note that while there is a great deal of variation in how ICSs are deployed, it has been our experience that most architectures exhibit certain common characteristics and design patterns regardless of vendor or system type. A large portion of this section will cover the basic principles underlying modern industrial  control systems architecture , which we believe apply to almost all deployments. Our aim is not just to discuss a few examples, but also to present an architecture that reflects many experiences and insights gained over years of working in ICS environments . To make it easier for you to relate what we will be covering to your own organization, Figure 1 shows the high-level diagram depicting the relationship between our proposed architecture model , ISO/IEC TR15443:2018 , and other similar security guidelines. This figure represents a simple yet comprehensive ICS architecture that can serve as an excellent starting point for implementing security measures .  Figure 1 The high-level Industrial Control System Architecture (ICS) diagram based on the proposed IDMZ model. Source: [Source](https://i30.photobucket.com/albums/r552/cyber_cpt42/Industry%2BControl+System%2BArchitecture%2BDesign%2Band%2BSecurity%2F7157963.jpg) *\t  4. Designing the ICS Architecture with Security in Mind The security of an industrial control system is largely determined by its architecture . There are a number of design patterns and best practices that can be followed to ensure you achieve your desired level of security . The key factors that should always come into play when considering new deployments or modifications, especially those involving critical infrastructure elements such as electricity generation , transportation systems , water treatment plants  , etc. are: *  1. How will the system perform in a secure state ? This means how does it behave once it is properly configured and protected by security controls ? In our opinion, this question should be at the top of your priority list when considering changes to any ICS architecture . If you can answer \"yes\" to these questions: * Is the environment adequately segmented (e.g., demilitarized zones ) such that each component only interacts with components it needs to function properly?  * Do all system interactions happen in a controlled manner using standard mechanisms like VPNs, firewalls, and similar controls ? This will help ensure proper monitoring can occur without disruption or interference from malicious parties . It also ensures that critical infrastructure elements (e.g., control networks ) are isolated from less secure systems such as business applications , network management devices , etc.. * Is it easy for an administrator to understand what is happening in the system ?  For example, can you view real-time events on a dashboard without having access privileges beyond those assigned by your role or position within your organization? If so then this means there are no hidden back doors where someone could go undetected because they know how everything works internally . Furthermore , if administrators have strong knowledge about their roles and responsibilities as well as general awareness regarding security controls implemented across all layers of an ICS ecosystem (e.g., firewalls ) then implementing additional policies like two factor authentication becomes much simpler since users already know what they should do when prompted by such mechanisms . It is also important that any changes made within your environment are documented properly so administrators can easily identify how things were configured prior to implementation which allows them quickly revert back if needed without having guesswork involved during troubleshooting procedures later on downstream after an issue has occurred due solely because something wasn't done according 2\n",
      "- [Answer]: This page is dedicated to the second edition of Industrial Cybersecurity, focusing specifically on Fundamentals and revisiting the first edition. The content explores a revised Industrial Control System (ICS) Architecture based on field experience, deployments, and feedback, highlighting essential security aspects for designing an ICS environment with compliance to ISO/IEC TR15443:2018, ISA/ISA99 standards, NIST SP-800-82 Revision 2, and similar guidelines. It offers a high-level overview of the ICS architecture that can serve as an excellent starting point for implementing security measures in any organization's environment.\n",
      "\n",
      "Section Title:\n",
      "1. Industrial Cybersecurity Fundamentals - Part Two\n",
      "Important Texts:\n",
      "- Industrial Control System (ICS)\n",
      "\n",
      "Page Content:\n",
      "Section 1: Industrial Cybersecurity Fundamentals - Part Two\n",
      "I. Recap of First Edition and Introduction to Second Edition\n",
      "   A. Importance of revisiting first edition fundamentals for a comprehensive understanding of ICS cybersecurity\n",
      "II. Modern Look at the Industrial Control System Architecture\n",
      "   A. Exploration of modern principles underlying industrial control systems architecture regardless of vendor or system type\n",
      "III. The Industrial Demilitarized Zone (IDMZ) and its Significance in Security Architectural Designs \n",
      "IV. Securing ICS Architecture with Best Practices for Critical Infrastructure Elements\n",
      "   A. Emphasizing the role of a properly segmented environment, standard interactions through VPNs and firewalls, visibility into system operations without unautayer roles, and documentation for effective change management in an ICS environment.\n",
      "V. High-Level Overview of Proposed Architecture Model Based on IDMZ Design Principles\n",
      "   A. Presentation of a comprehensive high-level Industrial Control System Architecture diagram (Figure 1) depicting the relationship between our proposed architecture model, ISO/IEC TR15443:2018, and other security guidelines.\n",
      "Site Title:\n",
      "  - ['4     Introduction and Recap of First Edition']\n",
      "\n",
      "Headers:\n",
      "  - 1\n",
      "  - Introduction and \n",
      "  - Recap of First \n",
      "  - Edition\n",
      "  - Industrial Cybersecurity - second edition\n",
      "\n",
      "Important Texts:\n",
      "  - Industrial Control System\n",
      "  - ICS\n",
      "  -  Information Technology\n",
      "  - IT\n",
      "  - Operational Technology\n",
      "  - OT\n",
      "  - Defense-in-Depth\n",
      "  - DiD\n",
      "  - Security Information and Event \n",
      "  - Management\n",
      "  - SIEM\n",
      "\n",
      "Picture Descriptions:\n",
      "  - \n",
      "\n",
      "Page Content:\n",
      "  1 Introduction and  Recap of First  Edition Welcome to the second edition of  Industrial Cybersecurity . Over the next 24 chapters, we  will discuss the next logical steps after building a secure  Industrial Control System  ( ICS )  environment and defining a comprehensive set of policies, procedures, and standards,  discussed in detail in the first edition.  We are going to start off this second edition with a brief recap of topics and material  that were covered in the first edition of  Industrial Cybersecurity . This has mainly been  added to get you up to speed with the terminologies, technologies, and principles that are  expanded upon throughout the rest of this book. The remainder of the book concentrates  on security monitoring and verification of the ICS security posture and the various tools,  techniques, and activities involved. 4     Introduction and Recap of First Edition This chapter will be a review of the first edition of this book. We will go over all the topics  and material that were covered in the first edition, which should give you a solid base for  the topics covered in this book. The chapter will conclude with an explanation of what to  expect in the rest of this second-edition book.  In this chapter, we'll cover the following topics: *\t What is an ICS? *\t  Information Technology  ( IT ) and  Operational Technology  ( OT ) convergence and  the associated benefits and risks *\t The comprehensive risk management process  *\t The  Defense-in-Depth  ( DiD ) model  *\t ICS security program development   Industrial Cybersecurity - second edition The way I am positioning the first and second editions of  Industrial Cybersecurity  is with  the first edition focusing on ICS cybersecurity fundamentals and ICS cybersecurity  program design and implementation. The second edition should be a logical addition  by taking these core concepts and expanding upon them with tools, techniques, and  activities that are aimed at verifying, monitoring, checking, improving, and correcting the  overall security posture of the ICS environment. Some topics we will be covering on this  continued journey include the following: *\t Architecture design with security in mind *\t Active and passive security monitoring *\t Industrial threat intelligence *\t Visualizing, correlating, and alerting ( Security Information and Event  Management  ( SIEM )) *\t Incident response activities *\t Security assessments (penetration testing, red/blue team exercises) *\t Threat-hunting exercises As mentioned earlier, this book will expand upon the topics of the first edition, so let's  first recap on what we covered back in 2017.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7349.21 ms\n",
      "llama_print_timings:      sample time =     181.25 ms /   790 runs   (    0.23 ms per token,  4358.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     107.28 ms /   734 tokens (    0.15 ms per token,  6842.04 tokens per second)\n",
      "llama_print_timings:        eval time =    4804.40 ms /   789 runs   (    6.09 ms per token,   164.22 tokens per second)\n",
      "llama_print_timings:       total time =    5791.70 ms /  1523 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Note that we won't cover everything here;   rather, it is a summary and overview of some major concepts with an aim to get you up-to-speed again for this second-edition book .\n",
      "Output=**Introduction and Recap of First Edition - Industrial Cybersecurity Second Edition**\n",
      "\n",
      "The second edition of \"Industrial Cybersecurity\" serves as a continuation from the foundational work laid out in its first iteration. This textbook is structured to guide readers through an expansive exploration of industrial cybersecurity, with particular focus on enhancing security monitoring and verification within Industrial Control Systems (ICS) environments. The initial chapter offers a comprehensive recap of the first edition's coverage, setting the stage for deeper dives into emerging topics in this dynamic field.\n",
      "\n",
      "**Key Topics Overviewed:**\n",
      "- **What is an ICS?** Introduction to Industrial Control Systems and their significance in industrial environments.\n",
      "- **IT (Information Technology) and OT (Operational Technology) Convergence:** Understanding the fusion of IT and OT, including benefits and associated risks.\n",
      "- **Comprehensive Risk Management Process:** An overview of risk management strategies within ICS contexts.\n",
      "- **Defense-in-Depth (DiD):** Examination of DiD as a robust security approach to protect industrial systems from various threats.\n",
      "- **ICS Security Program Development:** Methodologies for designing and implementing effective cybersecurity programs tailored to ICS.\n",
      "\n",
      "The second edition builds upon these fundamentals, delving into advanced strategies and tools critical to maintaining a secure operational landscape. The chapters that follow will cover:\n",
      "- **Architecture Design with Security in Mind:** Crafting industrial system architectures that inherently consider security measures.\n",
      "- **Security Monitoring Techniques (Active & Passive):** Exploring various monitoring approaches to detect and respond to cybersecurity incidents effectively.\n",
      "- **Industrial Threat Intelligence:** Gaining insights into potential threats and vulnerabilities specific to industrial environments.\n",
      "- **Visualizing, Correlating, and Alerting with SIEM (Security Information and Event Management):** Utilizing SIEM systems for better threat detection through data visualization and correlation.\n",
      "- **Incident Response Activities:** Strategies and best practices for managing cybersecurity incidents within ICS settings.\n",
      "- **Security Assessments & Threat Hunting:** Conducting penetration testing, red/blue team exercises, and threat hunting to uncover hidden vulnerabilities or malicious activities.\n",
      "\n",
      "This edition aims to provide an invaluable resource for professionals involved in securing industrial environments against cyber threats. By revisiting core concepts from the first edition and integrating them with new methodologies and technologies, it equips readers with the knowledge required to not only understand but effectively enhance their ICS's security posture.\n",
      "\n",
      "**Page Content Summary:** The content offers a blend of theoretical foundations established in the first edition, augmented by practical approaches for evaluating and improving industrial cybersecurity measures. It emphasizes real-world applications, preparing readers to tackle modern challenges in ICS security with confidence.\n",
      "\n",
      "**Picture Descriptions:** (Note: As no specific pictures are provided, this section remains unfilled.)\n",
      "\n",
      "By embarking on the journey through \"Industrial Cybersecurity - second edition,\" readers will gain a deepened understanding of securing industrial environments in an increasingly digital and interconnected world.\n",
      "Site Title:\n",
      "  - ['4     Introduction and Recap of First Edition', 'Recap of the first edition     5']\n",
      "\n",
      "Headers:\n",
      "  - Industrial Cybersecurity - second edition\n",
      "  - Recap of the first edition\n",
      "  - What is an ICS?\n",
      "\n",
      "Important Texts:\n",
      "  -  Information Technology\n",
      "  - IT\n",
      "  - Operational Technology\n",
      "  - OT\n",
      "  - Defense-in-Depth\n",
      "  - DiD\n",
      "  - Security Information and Event \n",
      "  - Management\n",
      "  - SIEM\n",
      "\n",
      "Picture Descriptions:\n",
      "  - Figure 1.1\n",
      "\n",
      "Page Content:\n",
      "  4     Introduction and Recap of First Edition This chapter will be a review of the first edition of this book. We will go over all the topics  and material that were covered in the first edition, which should give you a solid base for  the topics covered in this book. The chapter will conclude with an explanation of what to  expect in the rest of this second-edition book.  In this chapter, we'll cover the following topics: *\t What is an ICS? *\t  Information Technology  ( IT ) and  Operational Technology  ( OT ) convergence and  the associated benefits and risks *\t The comprehensive risk management process  *\t The  Defense-in-Depth  ( DiD ) model  *\t ICS security program development   Industrial Cybersecurity - second edition The way I am positioning the first and second editions of  Industrial Cybersecurity  is with  the first edition focusing on ICS cybersecurity fundamentals and ICS cybersecurity  program design and implementation. The second edition should be a logical addition  by taking these core concepts and expanding upon them with tools, techniques, and  activities that are aimed at verifying, monitoring, checking, improving, and correcting the  overall security posture of the ICS environment. Some topics we will be covering on this  continued journey include the following: *\t Architecture design with security in mind *\t Active and passive security monitoring *\t Industrial threat intelligence *\t Visualizing, correlating, and alerting ( Security Information and Event  Management  ( SIEM )) *\t Incident response activities *\t Security assessments (penetration testing, red/blue team exercises) *\t Threat-hunting exercises As mentioned earlier, this book will expand upon the topics of the first edition, so let's  first recap on what we covered back in 2017. Recap of the first edition     5 Recap of the first edition If you have not yet read the first edition of  Industrial Cybersecurity , now would be the time  to do so. It covers in detail how to get from zero to hero on implementing an industrial  cybersecurity program, to define a secure ICS environment and network architecture that  fits your organization's needs and requirements. Reading the first edition is not a requirement though, as the first four chapters of this  book will recap on relevant topics and get you on track to follow along and understand the  material presented in this second edition. Without further ado, let's start our journey with a recap of ICS (cybersecurity) principles  and practices. What is an ICS? The traffic lights on your way to work if you go by car; the collision avoidance system if  you take the train or metro; the delivery of electricity that powers the light you use to \n",
      " read this book; the processing and packaging that went into creating the jug of milk in  your fridge or the coffee grind for that cup of Joe that fuels your day... What all these  things have in common is the ICS driving the measurements, decisions, corrections,  and other miscellaneous actions that result in the end products and services we take for  granted each day. Strictly speaking, an ICS is a collection of equipment, devices, and communication  methods that, when combined for the foundational system, perform a specific task, \n",
      " deliver a service, or create a particular product.  Figure 1.1  shows an ICS architecture,  spanning the various layers of functionality as described in the Purdue model \n",
      " (explained in a later section).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[118], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m summarize_chain \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent_of_pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: x} \u001b[38;5;241m|\u001b[39m prompt \u001b[38;5;241m|\u001b[39m llm \u001b[38;5;241m|\u001b[39m StrOutputParser()\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# # Summarize the text chunks\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m text_summaries \u001b[38;5;241m=\u001b[39m \u001b[43msummarize_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_concurrency\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m summary \u001b[38;5;129;01min\u001b[39;00m text_summaries:\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mprint\u001b[39m(summary)\n",
      "File \u001b[0;32m~/git/llm_test/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:2547\u001b[0m, in \u001b[0;36mRunnableSequence.batch\u001b[0;34m(self, inputs, config, return_exceptions, **kwargs)\u001b[0m\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2546\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[0;32m-> 2547\u001b[0m             inputs \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2548\u001b[0m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2549\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m   2550\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;66;43;03m# each step a child run of the corresponding root run\u001b[39;49;00m\n\u001b[1;32m   2551\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2552\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2553\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2554\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2555\u001b[0m \u001b[43m                \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2556\u001b[0m \u001b[43m                \u001b[49m\u001b[43mreturn_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2557\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2558\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2560\u001b[0m \u001b[38;5;66;03m# finish the root runs\u001b[39;00m\n\u001b[1;32m   2561\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/git/llm_test/.venv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:347\u001b[0m, in \u001b[0;36mBaseLLM.batch\u001b[0;34m(self, inputs, config, return_exceptions, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m batches \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    343\u001b[0m     inputs[i : i \u001b[38;5;241m+\u001b[39m max_concurrency]\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(inputs), max_concurrency)\n\u001b[1;32m    345\u001b[0m ]\n\u001b[1;32m    346\u001b[0m config \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_concurrency\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m} \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m config]  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    348\u001b[0m     output\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batches)\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[1;32m    351\u001b[0m         batch,\n\u001b[1;32m    352\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig[i \u001b[38;5;241m*\u001b[39m max_concurrency : (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m max_concurrency],\n\u001b[1;32m    353\u001b[0m         return_exceptions\u001b[38;5;241m=\u001b[39mreturn_exceptions,\n\u001b[1;32m    354\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    355\u001b[0m     )\n\u001b[1;32m    356\u001b[0m ]\n",
      "File \u001b[0;32m~/git/llm_test/.venv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:350\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    342\u001b[0m batches \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    343\u001b[0m     inputs[i : i \u001b[38;5;241m+\u001b[39m max_concurrency]\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(inputs), max_concurrency)\n\u001b[1;32m    345\u001b[0m ]\n\u001b[1;32m    346\u001b[0m config \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_concurrency\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m} \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m config]  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    348\u001b[0m     output\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batches)\n\u001b[0;32m--> 350\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_concurrency\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_concurrency\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m ]\n",
      "File \u001b[0;32m~/git/llm_test/.venv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:327\u001b[0m, in \u001b[0;36mBaseLLM.batch\u001b[0;34m(self, inputs, config, return_exceptions, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_concurrency \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m         llm_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [g[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m llm_result\u001b[38;5;241m.\u001b[39mgenerations]\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/git/llm_test/.venv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:633\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    627\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    631\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    632\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/llm_test/.venv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:803\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    789\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    790\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    791\u001b[0m             dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    801\u001b[0m         )\n\u001b[1;32m    802\u001b[0m     ]\n\u001b[0;32m--> 803\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/git/llm_test/.venv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:670\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[1;32m    669\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 670\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    671\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/git/llm_test/.venv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:657\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    649\u001b[0m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    654\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    656\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 657\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    661\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    665\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    666\u001b[0m         )\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    668\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/git/llm_test/.venv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:1317\u001b[0m, in \u001b[0;36mLLM._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1314\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m   1316\u001b[0m     text \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1317\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1318\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m   1319\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(prompt, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1320\u001b[0m     )\n\u001b[1;32m   1321\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([Generation(text\u001b[38;5;241m=\u001b[39mtext)])\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m~/git/llm_test/.venv/lib/python3.10/site-packages/langchain_community/llms/llamacpp.py:288\u001b[0m, in \u001b[0;36mLlamaCpp._call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstreaming:\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;66;03m# If streaming is enabled, we use the stream\u001b[39;00m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# method that yields as they are generated\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# and return the combined strings from the first choices's text:\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     combined_text_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream(\n\u001b[1;32m    289\u001b[0m         prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m    290\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    291\u001b[0m         run_manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[1;32m    292\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    293\u001b[0m     ):\n\u001b[1;32m    294\u001b[0m         combined_text_output \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m chunk\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m combined_text_output\n",
      "File \u001b[0;32m~/git/llm_test/.venv/lib/python3.10/site-packages/langchain_community/llms/llamacpp.py:341\u001b[0m, in \u001b[0;36mLlamaCpp._stream\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_parameters(stop), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m    340\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient(prompt\u001b[38;5;241m=\u001b[39mprompt, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 341\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[1;32m    342\u001b[0m     logprobs \u001b[38;5;241m=\u001b[39m part[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    343\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m GenerationChunk(\n\u001b[1;32m    344\u001b[0m         text\u001b[38;5;241m=\u001b[39mpart[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    345\u001b[0m         generation_info\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs},\n\u001b[1;32m    346\u001b[0m     )\n",
      "File \u001b[0;32m~/git/llm_test/.venv/lib/python3.10/site-packages/llama_cpp/llama.py:1095\u001b[0m, in \u001b[0;36mLlama._create_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1093\u001b[0m finish_reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1094\u001b[0m multibyte_fix \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1095\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m   1096\u001b[0m     prompt_tokens,\n\u001b[1;32m   1097\u001b[0m     top_k\u001b[38;5;241m=\u001b[39mtop_k,\n\u001b[1;32m   1098\u001b[0m     top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[1;32m   1099\u001b[0m     min_p\u001b[38;5;241m=\u001b[39mmin_p,\n\u001b[1;32m   1100\u001b[0m     typical_p\u001b[38;5;241m=\u001b[39mtypical_p,\n\u001b[1;32m   1101\u001b[0m     temp\u001b[38;5;241m=\u001b[39mtemperature,\n\u001b[1;32m   1102\u001b[0m     tfs_z\u001b[38;5;241m=\u001b[39mtfs_z,\n\u001b[1;32m   1103\u001b[0m     mirostat_mode\u001b[38;5;241m=\u001b[39mmirostat_mode,\n\u001b[1;32m   1104\u001b[0m     mirostat_tau\u001b[38;5;241m=\u001b[39mmirostat_tau,\n\u001b[1;32m   1105\u001b[0m     mirostat_eta\u001b[38;5;241m=\u001b[39mmirostat_eta,\n\u001b[1;32m   1106\u001b[0m     frequency_penalty\u001b[38;5;241m=\u001b[39mfrequency_penalty,\n\u001b[1;32m   1107\u001b[0m     presence_penalty\u001b[38;5;241m=\u001b[39mpresence_penalty,\n\u001b[1;32m   1108\u001b[0m     repeat_penalty\u001b[38;5;241m=\u001b[39mrepeat_penalty,\n\u001b[1;32m   1109\u001b[0m     stopping_criteria\u001b[38;5;241m=\u001b[39mstopping_criteria,\n\u001b[1;32m   1110\u001b[0m     logits_processor\u001b[38;5;241m=\u001b[39mlogits_processor,\n\u001b[1;32m   1111\u001b[0m     grammar\u001b[38;5;241m=\u001b[39mgrammar,\n\u001b[1;32m   1112\u001b[0m ):\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m llama_cpp\u001b[38;5;241m.\u001b[39mllama_token_is_eog(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mmodel, token):\n",
      "File \u001b[0;32m~/git/llm_test/.venv/lib/python3.10/site-packages/llama_cpp/llama.py:723\u001b[0m, in \u001b[0;36mLlama.generate\u001b[0;34m(self, tokens, top_k, top_p, min_p, typical_p, temp, repeat_penalty, reset, frequency_penalty, presence_penalty, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, penalize_nl, logits_processor, stopping_criteria, grammar)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;66;03m# Eval and sample\u001b[39;00m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 723\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    724\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m sample_idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_tokens:\n\u001b[1;32m    725\u001b[0m         token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample(\n\u001b[1;32m    726\u001b[0m             top_k\u001b[38;5;241m=\u001b[39mtop_k,\n\u001b[1;32m    727\u001b[0m             top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    741\u001b[0m             idx\u001b[38;5;241m=\u001b[39msample_idx,\n\u001b[1;32m    742\u001b[0m         )\n",
      "File \u001b[0;32m~/git/llm_test/.venv/lib/python3.10/site-packages/llama_cpp/llama.py:573\u001b[0m, in \u001b[0;36mLlama.eval\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    571\u001b[0m     rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    572\u001b[0m     cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_vocab\n\u001b[0;32m--> 573\u001b[0m     logits \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mctypeslib\u001b[38;5;241m.\u001b[39mas_array(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, shape\u001b[38;5;241m=\u001b[39m(rows \u001b[38;5;241m*\u001b[39m cols, ))\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscores[n_past \u001b[38;5;241m+\u001b[39m n_tokens \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, :]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[: :] \u001b[38;5;241m=\u001b[39m logits\n\u001b[1;32m    575\u001b[0m \u001b[38;5;66;03m# Update n_tokens\u001b[39;00m\n",
      "File \u001b[0;32m~/git/llm_test/.venv/lib/python3.10/site-packages/llama_cpp/_internals.py:330\u001b[0m, in \u001b[0;36m_LlamaContext.get_logits\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_logits\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mllama_cpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllama_get_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Create a document object\n",
    "doc = fitz.open(BOOK_PDF)\n",
    "#Extract the table of contents\n",
    "toc_df = extract_toc_as_df(BOOK_PDF)\n",
    "\n",
    "prompt_text = \"\"\"You are an assistant tasked with summarizing texts. \\ \n",
    "Give a concise summary of the text. Text chunk: {element} \"\"\"\n",
    "\n",
    "for index, row in toc_df.iterrows():\n",
    "    # all the pages until the the row containing the word \"Chapter\" or \"Section\" in the title\n",
    "    if \"Chapter\" in row['Title'] or \"Section\" in row['Title']:\n",
    "        #Keep all the rows from the index to the end\n",
    "        toc_df = toc_df.iloc[index:]\n",
    "        break\n",
    "\n",
    "toc_df['End Page'] = None\n",
    "toc_df = toc_df.sort_values(by='Page').reset_index(drop=True)\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(PROMPT)\n",
    "\n",
    "#Create text splitter to split the text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=4050,    # 4050 tokens is the maximum number of tokens that can be processed in a single run\n",
    "    chunk_overlap=128,\n",
    ")\n",
    "for index, row in toc_df.iterrows():\n",
    "#Iterate only over the first 10 chapters\n",
    "    if index > 10:\n",
    "        break\n",
    "    # Get the start and end page for the current chapter\n",
    "    start_page = row['Page']\n",
    "    if index < len(toc_df)-1:\n",
    "        end_page = toc_df.loc[index+1, 'Page']\n",
    "    else:\n",
    "        end_page = doc.page_count - 1\n",
    "    # # Extract the content of the chapter\n",
    "    content_of_pdf = extract_pdf_content(BOOK_PDF, start_page, end_page)\n",
    "    #Split the text into chunks\n",
    "    texts = text_splitter.split_text(content_of_pdf)\n",
    "    for text in texts:\n",
    "        print(text)\n",
    "\n",
    "    # # Create a prompt from the template\n",
    "    prompt = prompt_template\n",
    "\n",
    "    # # Create a summarization chain\n",
    "    summarize_chain = {\"content_of_pdf\": lambda x: x} | prompt | llm | StrOutputParser()\n",
    "\n",
    "    # # Summarize the text chunks\n",
    "    text_summaries = summarize_chain.batch(texts, {\"max_concurrency\": 50})\n",
    "    for summary in text_summaries:\n",
    "        print(summary)\n",
    "\n",
    "\n",
    "    # # Display the summaries\n",
    "    # for summary in text_summaries:\n",
    "    #     print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a document object\n",
    "doc = fitz.open(BOOK_PDF)\n",
    "\n",
    "content_of_pdf = \"\"\n",
    "block_dict = {}\n",
    "\n",
    "\n",
    "#Iterate over all pages in the documents\n",
    "for i in range(doc.page_count):\n",
    "#for i in range(0,100):\n",
    "  page = doc.load_page(i)\n",
    "  file_dict = page.get_text('dict') # Get the page dictionary\n",
    "  block = file_dict['blocks'] # Get the block information\n",
    "  block_dict[i] = block\n",
    "  # read text and print it\n",
    "  text = page.get_text()\n",
    "  #Add the text to a string to be used in the prompt\n",
    "  content_of_pdf = content_of_pdf + text\n",
    "\n",
    "  ### IMAGES ###\n",
    "  # Extract all the images on the page and save the images\n",
    "  for i in page.get_images(full=True):\n",
    "    xref = i[0]\n",
    "    base_image = doc.extract_image(xref)\n",
    "    image_bytes = base_image[\"image\"]\n",
    "    image = fitz.Pixmap(doc, xref)\n",
    "    with open(f'{PATH}/image_{xref}.png', 'wb') as f:\n",
    "      f.write(image.tobytes())\n",
    "\n",
    "  ## TABLES ##\n",
    "  # Extract all the tables on the page and save the tables\n",
    "  tabs = page.find_tables()  # detect the tables\n",
    "  for i,tab in enumerate(tabs):  # iterate over all tables\n",
    "      print(f\"Table {i} column names: {tab.header.names}, external: {tab.header.external}\")\n",
    "      tab = tabs[i]\n",
    "      df = tab.to_pandas()\n",
    "      #Add the table to a string to be used in the prompt\n",
    "      content_of_pdf += df.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a function out of that\n",
    "spans = pd.DataFrame(columns=['xmin', 'ymin', 'xmax', 'ymax', 'text', 'tag'])\n",
    "rows = []\n",
    "for page_num, blocks in block_dict.items():\n",
    "    for block in blocks:\n",
    "        if block['type'] == 0:\n",
    "            for line in block['lines']:\n",
    "                for span in line['spans']:\n",
    "                    xmin, ymin, xmax, ymax = list(span['bbox'])\n",
    "                    font_size = span['size']\n",
    "                    text = unidecode(span['text'])\n",
    "                    span_font = span['font']\n",
    "                    is_bold = False\n",
    "                    if \"bold\" in span_font.lower():\n",
    "                        is_bold = True\n",
    "                    if text.replace(\" \",\"\") !=  \"\":\n",
    "                        rows.append((xmin, ymin, xmax, ymax, text, is_bold, span_font, font_size, page_num))\n",
    "                        span_df = pd.DataFrame(rows, columns=['xmin','ymin','xmax','ymax', 'text','is_bold','span_font', 'font_size', 'page_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find text with table of content in span_df\n",
    "toc = span_df[span_df['text'].str.contains(\"table of content\", case=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#About 30 tokens\n",
    "prompt_text = \"\"\"You are an assistant tasked with summarizing texts. \\ \n",
    "Give a concise summary of the text. Text chunk: {element} \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = WORKSPACE_DIC + \"/Phi/Phi3/Phi-3-mini-4k-instruct-q4.gguf\"\n",
    "llm = LlamaCpp(\n",
    "    model_path= model_path,\n",
    "    n_gpu_layers=-1,\n",
    "    n_batch=4096,\n",
    "    n_ctx=4096,\n",
    "    temperature=1,\n",
    "    top_p=1,\n",
    "    max_tokens = 5000,\n",
    "    #callback_manager=callback_manager,\n",
    "    verbose=True,  # Verbose is required to pass to the callback manager\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(PROMPT)\n",
    "\n",
    "#Create text splitter to split the text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=4050,    # 4050 tokens is the maximum number of tokens that can be processed in a single run\n",
    "    chunk_overlap=128,\n",
    ")\n",
    "\n",
    "# Split the text into chunks\n",
    "texts = text_splitter.split_text(content_of_pdf)\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_text)\n",
    "\n",
    "summarize_chain = {\"element\": lambda x: x} | prompt | llm | StrOutputParser()\n",
    "\n",
    "text_summaries = summarize_chain.batch(texts, {\"max_concurrency\": 50})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the summaries to a file\n",
    "with open('summaries.txt', 'w') as f:\n",
    "    for item in text_summaries:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the summaries from the file\n",
    "with open('summaries.txt', 'r') as f:\n",
    "    text_summaries = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = SentenceTransformerEmbeddings(model_name= \"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "db = Chroma.from_texts(text_summaries, embedding_function)\n",
    "\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "\n",
    "print(retriever)\n",
    "\n",
    "template2 = \"\"\"Answer the question based only on the following context, which can include text and tables:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "template = \"\"\"Create multiple choice question in one of the following format:\n",
    "Question: Which two options are the best reasons to use an IPV4 private IP space? (Choose two.)\n",
    "A. to enable intra-enterprise communication\n",
    "B. to implement NAT\n",
    "C. to connect applications\n",
    "D. to conserve global address space\n",
    "E. to manage routing overhead\n",
    "Answer: AD\n",
    "\n",
    "Question: The corporate security policy requires multiple elements to be matched in an authorization policy. Which elements can be combined to meet the requirement?\n",
    "A. Device registration status and device activation status\n",
    "B. Network access device and time condition\n",
    "C. User credentials and server certificate\n",
    "D. Built-in profile and custom profile\n",
    "Answer: B\n",
    "\n",
    "using the following context:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "#prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = db.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain.invoke(\"\"\"Create multiple choice question in one in the following format out of the provided context\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(llm_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
