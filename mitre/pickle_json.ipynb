{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T09:42:41.511193Z",
     "start_time": "2025-03-20T09:42:41.508858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import json\n"
   ],
   "id": "572873468c5a7bea",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-20T09:42:41.525569Z",
     "start_time": "2025-03-20T09:42:41.523297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def json_to_pickle(json_file_path, pickle_file_path):\n",
    "    # Read the JSON file\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    # Convert to pandas DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Write to pickle file\n",
    "    with open(pickle_file_path, 'wb') as pickle_file:\n",
    "        pickle.dump(df, pickle_file)\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T09:42:41.576118Z",
     "start_time": "2025-03-20T09:42:41.573593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def batch_convert_json_to_pkl(folder_path):\n",
    "    \"\"\"\n",
    "    Converts all .json files in the specified folder to .pkl format.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(f\"Error: The folder '{folder_path}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    converted_files = 0\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".json\"):\n",
    "            json_path = os.path.join(folder_path, filename)\n",
    "            pkl_path = json_path.replace(\".json\", \".pkl\")\n",
    "\n",
    "            try:\n",
    "                json_to_pickle(json_path, pkl_path)\n",
    "\n",
    "                print(f\"Converted: {filename} → {os.path.basename(pkl_path)}\")\n",
    "                converted_files += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to convert {filename}: {e}\")\n",
    "\n",
    "    if converted_files == 0:\n",
    "        print(\"No .pkl files found in the folder.\")\n",
    "    else:\n",
    "        print(f\"Conversion complete: {converted_files} file(s) converted.\")\n"
   ],
   "id": "6ec6b00efba74cbc",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T09:42:41.626499Z",
     "start_time": "2025-03-20T09:42:41.622467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def convert_json_to_parquet(json_file_path, parquet_file_path):\n",
    "    # Step 1: Read the JSON file\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    # Step 2: Convert to pandas DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Step 3: Write to parquet file\n",
    "    df.to_parquet(parquet_file_path, engine='pyarrow')\n",
    "\n",
    "    print(f\"Successfully converted {json_file_path} to {parquet_file_path}\")"
   ],
   "id": "4e5e968fbe55edca",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T09:42:41.680730Z",
     "start_time": "2025-03-20T09:42:41.674600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def convert_pkl_to_parquet(folder_path):\n",
    "    \"\"\"\n",
    "    Converts all .pkl files in the specified folder to .parquet format.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(f\"Error: The folder '{folder_path}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    converted_files = 0\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".pkl\"):\n",
    "            pkl_path = os.path.join(folder_path, filename)\n",
    "            parquet_path = pkl_path.replace(\".pkl\", \".parquet\")\n",
    "\n",
    "            try:\n",
    "                # Load the pickle file\n",
    "                df = pd.read_pickle(pkl_path)\n",
    "\n",
    "                # Convert to Parquet\n",
    "                df.to_parquet(parquet_path, index=False)\n",
    "\n",
    "                print(f\"Converted: {filename} → {os.path.basename(parquet_path)}\")\n",
    "                converted_files += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to convert {filename}: {e}\")\n",
    "\n",
    "    if converted_files == 0:\n",
    "        print(\"No .pkl files found in the folder.\")\n",
    "    else:\n",
    "        print(f\"Conversion complete: {converted_files} file(s) converted.\")\n"
   ],
   "id": "ca03460ced550d9c",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T09:42:41.736018Z",
     "start_time": "2025-03-20T09:42:41.728952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_pkl_mitre(input_file, output_file, subject_model, temperature):\n",
    "    # Load the DataFrame\n",
    "    with open(input_file, 'rb') as pkl_file:\n",
    "        df = pickle.load(pkl_file)\n",
    "\n",
    "    # Rename model_col to judge_model\n",
    "    old_column_name = \"model\"\n",
    "    new_column_name = \"judge_model\"\n",
    "    if old_column_name not in df.columns:\n",
    "        raise ValueError(f\"Column '{old_column_name}' not found in the DataFrame.\")\n",
    "    df.rename(columns={old_column_name: new_column_name}, inplace=True)\n",
    "\n",
    "    # Add new columns with constant values\n",
    "    df[\"temperature\"] = temperature\n",
    "    df[\"subject_model\"] = subject_model\n",
    "\n",
    "    if \"expansion_response\" not in df.columns:\n",
    "        df[\"expansion_response\"] = None\n",
    "\n",
    "    if \"judge_response\" not in df.columns:\n",
    "        df[\"judge_response\"] = None\n",
    "\n",
    "    # Define columns to keep\n",
    "    selected_columns = [\"subject_model\",\n",
    "                        \"temperature\",\n",
    "                        \"prompt_index\",\n",
    "                        \"mitre_category\",\n",
    "                        \"test_case_prompt\",\n",
    "                        \"think_response\",\n",
    "                        \"initial_response\", # Same as \"response\"\n",
    "                        \"expansion_response\",\n",
    "                        \"judge_response\",\n",
    "                        \"answered\",\n",
    "                        \"judge_model\",\n",
    "                        ]\n",
    "\n",
    "    # Select only the specified columns\n",
    "    df_selected = df[selected_columns]\n",
    "\n",
    "    # Save the modified DataFrame as a .pkl file\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        pickle.dump(df_selected, f)\n",
    "\n",
    "    print(f\"Processed file saved as: {output_file}\")\n",
    "    # Define columns to keep"
   ],
   "id": "1057f724c2b2714c",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T09:42:41.790182Z",
     "start_time": "2025-03-20T09:42:41.784708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def batch_process_pkl_mitre(input_dir, output_dir, subject_model, temperature):\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Get all .pkl files in the input directory\n",
    "    pkl_files = glob.glob(os.path.join(input_dir, \"*.pkl\"))\n",
    "\n",
    "    if not pkl_files:\n",
    "        print(f\"No .pkl files found in {input_dir}.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(pkl_files)} .pkl files in {input_dir}. Processing...\")\n",
    "\n",
    "    # Loop through each file and process it\n",
    "    for input_file in pkl_files:\n",
    "        # Generate output file path\n",
    "        filename = os.path.basename(input_file)\n",
    "        output_file = os.path.join(output_dir, f\"processed_{filename}\")\n",
    "\n",
    "        # Process and save\n",
    "        process_pkl_mitre(input_file, output_file, subject_model, temperature)\n"
   ],
   "id": "591d4ea024ac9052",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T09:42:42.250154Z",
     "start_time": "2025-03-20T09:42:41.840821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MITRE\n",
    "# DS Subject Model, DS Judge Model, T 0.0\n",
    "batch_convert_json_to_pkl(\n",
    "    \"./data/deepseek/judge/ds/t00/\",\n",
    ")\n",
    "batch_process_pkl_mitre(\n",
    "    input_dir=\"./data/deepseek/judge/ds/t00/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    subject_model=\"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\",\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "# DS Subject Model, DS Judge Model, T 0.7\n",
    "batch_convert_json_to_pkl(\n",
    "    \"./data/deepseek/judge/ds/t07/\",\n",
    ")\n",
    "batch_process_pkl_mitre(\n",
    "    input_dir=\"./data/deepseek/judge/ds/t07/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    subject_model=\"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# DS Subject Model, Llama Judge Model, T 0.0\n",
    "batch_convert_json_to_pkl(\n",
    "    \"./data/deepseek/judge/llama/t00/\",\n",
    ")\n",
    "batch_process_pkl_mitre(\n",
    "    input_dir=\"./data/deepseek/judge/llama/t00/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    subject_model=\"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\",\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "# DS Subject Model, Llama Judge Model, T 0.7\n",
    "batch_convert_json_to_pkl(\n",
    "    \"./data/deepseek/judge/llama/t07/\",\n",
    ")\n",
    "batch_process_pkl_mitre(\n",
    "    input_dir=\"./data/deepseek/judge/llama/t07/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    subject_model=\"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# Llama Subject Model, DS Judge Model, T 0.0\n",
    "batch_convert_json_to_pkl(\n",
    "    \"./data/llama/judge/ds/t00/\",\n",
    ")\n",
    "batch_process_pkl_mitre(\n",
    "    input_dir=\"./data/llama/judge/ds/t00/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    subject_model=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    temperature=0.0\n",
    ")\n",
    "# Llama Subject Model, DS Judge Model, T 0.7\n",
    "batch_convert_json_to_pkl(\n",
    "    \"./data/llama/judge/ds/t07/\",\n",
    ")\n",
    "batch_process_pkl_mitre(\n",
    "    input_dir=\"./data/llama/judge/ds/t07/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    subject_model=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "# Llama Subject Model, Llama Judge Model, T 0.0\n",
    "batch_convert_json_to_pkl(\n",
    "    \"./data/llama/judge/ds/t00/\",\n",
    ")\n",
    "batch_process_pkl_mitre(\n",
    "    input_dir=\"./data/llama/judge/ds/t00/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    subject_model=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    temperature=0.0\n",
    ")\n",
    "# Llama Subject Model, Llama Judge Model, T 0.7\n",
    "batch_convert_json_to_pkl(\n",
    "    \"./data/llama/judge/ds/t07/\",\n",
    ")\n",
    "batch_process_pkl_mitre(\n",
    "    input_dir=\"./data/llama/judge/ds/t07/\",\n",
    "    output_dir=\"./processed_results/\",\n",
    "    subject_model=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    temperature=0.7\n",
    ")"
   ],
   "id": "4a6c3b01efcabec3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted: mitre_judge_t0-0 - Original.json → mitre_judge_t0-0 - Original.pkl\n",
      "Conversion complete: 1 file(s) converted.\n",
      "Found 1 .pkl files in ./data/deepseek/judge/ds/t00/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_mitre_judge_t0-0 - Original.pkl\n",
      "Converted: mitre_judge_t0-7 - Original.json → mitre_judge_t0-7 - Original.pkl\n",
      "Conversion complete: 1 file(s) converted.\n",
      "Found 1 .pkl files in ./data/deepseek/judge/ds/t07/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_mitre_judge_t0-7 - Original.pkl\n",
      "Converted: mitre_llama_judge_deepseek_t0-0.json → mitre_llama_judge_deepseek_t0-0.pkl\n",
      "Conversion complete: 1 file(s) converted.\n",
      "Found 1 .pkl files in ./data/deepseek/judge/llama/t00/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_mitre_llama_judge_deepseek_t0-0.pkl\n",
      "Converted: mitre_llama_judge_deepseek_t0-7.json → mitre_llama_judge_deepseek_t0-7.pkl\n",
      "Conversion complete: 1 file(s) converted.\n",
      "Found 1 .pkl files in ./data/deepseek/judge/llama/t07/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_mitre_llama_judge_deepseek_t0-7.pkl\n",
      "Converted: mitre_t0-0_judge.json → mitre_t0-0_judge.pkl\n",
      "Conversion complete: 1 file(s) converted.\n",
      "Found 1 .pkl files in ./data/llama/judge/ds/t00/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_mitre_t0-0_judge.pkl\n",
      "Converted: mitre_t0-7_deepseek_judge_llama.json → mitre_t0-7_deepseek_judge_llama.pkl\n",
      "Conversion complete: 1 file(s) converted.\n",
      "Found 1 .pkl files in ./data/llama/judge/ds/t07/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_mitre_t0-7_deepseek_judge_llama.pkl\n",
      "Converted: mitre_t0-0_judge.json → mitre_t0-0_judge.pkl\n",
      "Conversion complete: 1 file(s) converted.\n",
      "Found 1 .pkl files in ./data/llama/judge/ds/t00/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_mitre_t0-0_judge.pkl\n",
      "Converted: mitre_t0-7_deepseek_judge_llama.json → mitre_t0-7_deepseek_judge_llama.pkl\n",
      "Conversion complete: 1 file(s) converted.\n",
      "Found 1 .pkl files in ./data/llama/judge/ds/t07/. Processing...\n",
      "Processed file saved as: ./processed_results/processed_mitre_t0-7_deepseek_judge_llama.pkl\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T09:42:42.658173Z",
     "start_time": "2025-03-20T09:42:42.255224Z"
    }
   },
   "cell_type": "code",
   "source": "convert_pkl_to_parquet(\"./processed_results/\")",
   "id": "16b151a82cffba40",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted: processed_mitre_judge_t0-0 - Original.pkl → processed_mitre_judge_t0-0 - Original.parquet\n",
      "Converted: processed_mitre_t0-0_judge.pkl → processed_mitre_t0-0_judge.parquet\n",
      "Converted: processed_mitre_t0-7_deepseek_judge_llama.pkl → processed_mitre_t0-7_deepseek_judge_llama.parquet\n",
      "Converted: processed_mitre_judge_t0-7 - Original.pkl → processed_mitre_judge_t0-7 - Original.parquet\n",
      "Converted: processed_mitre_llama_judge_deepseek_t0-7.pkl → processed_mitre_llama_judge_deepseek_t0-7.parquet\n",
      "Converted: processed_mitre_llama_judge_deepseek_t0-0.pkl → processed_mitre_llama_judge_deepseek_t0-0.parquet\n",
      "Conversion complete: 6 file(s) converted.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T09:42:42.666019Z",
     "start_time": "2025-03-20T09:42:42.663135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def produce_statistics_from_batch_mitre(input_dir =\"./processed_results/\"):\n",
    "    # Get all .pkl files in the input directory\n",
    "    pkl_files = glob.glob(os.path.join(input_dir, \"*.pkl\"))\n",
    "\n",
    "    if not pkl_files:\n",
    "        print(f\"No .pkl files found in {input_dir}.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(pkl_files)} .pkl files in {input_dir}. Processing...\")\n",
    "\n",
    "    for pickle_file in pkl_files:\n",
    "        # TODO\n",
    "        result = pd.DataFrame(columns = [\n",
    "\n",
    "        ])\n",
    "# subject_model, temp, promtindex, mitre_cat, answered, judge_model, juderesponse, mitrecat\n",
    "\n"
   ],
   "id": "921b928cf151b017",
   "outputs": [],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
